{
  "articles": [
    {
      "path": "about.html",
      "title": "About",
      "author": [],
      "contents": "\nRohan Alexander is an assistant professor at the University of Toronto, Canada, jointly appointed in Information and Statistical Sciences. He is also a faculty affiliate at the Schwartz Reisman Institute for Technology and Society. He holds a PhD in Economics from the Australian National University where he was supervised by John Tang (chair), Martine Mariotti, Tim Hatton, and Zach Ward.\nHe is interested in using statistical models to try to understand the world. And particularly how we get the data that go into those models; whose data are systematically missing; how we clean, prepare, and tidy data before they are modelled; the effects of all this on the implications of our models; and how we can reproducibly share the totality of this process. This research interest has a few different applications. One of those is natural language processing (NLP), where he is interested in understanding the effects of bringing together large, biased datasets and enormous models, and how this can be improved. Another is Multilevel Regression with Post-stratification (MRP), where he examines the effects of trying to establish a correspondence between two datasets.\nHe tries to develop students in his research group that are skilled not only in using statistical methods across various disciplines, but also appreciate their limitations, and think deeply about their broader contexts of their work.\nExamples of his recent academic work include: ‘heapsofpapers’, ‘Detecting Hate Speech with GPT-3’, and ‘On consistency scores in text data with an implementation in R’.\nHis teaching notes are available: Telling Stories With Data. He enjoys teaching and aims to help students from a wide range of backgrounds learn how to use data to tell convincing stories. In Information he has taught ‘Experimental Design’ and lead reading courses in ‘Ethics and Data Science’, ‘Information Management in Interdisciplinary Research’ and ‘Reproducible Data Science’. In Statistical Sciences he has taught ‘Surveys, Sampling, and Observational Data’ and lead a reading course in ‘Natural Language Processing’. He is a RStudio Certified Tidyverse Trainer.\nHe co-organizes the weekly Toronto Data Workshop, which is more fun than it sounds. All welcome! Sign up here.\n\n\n\nHe is married to Monica Alexander and they have a 2-year-old. He probably spends too much money on books, and certainly too much time at libraries (in a pre-COVID world). You can see some of the books that he recommends here. If you have any book recommendations of your own, then he’d love to hear them.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:21-04:00"
    },
    {
      "path": "academic.html",
      "title": "Academic",
      "author": [],
      "contents": "\nPapers\nAnnie Collins and Rohan Alexander, 2021, ‘Reproducibility of COVID-19 pre-prints’, arXiv, 22 July, https://arxiv.org/abs/2107.10724.\nRohan Alexander, Samantha-Jo Caetano, Haoluan Chen, Michael Chong, Annie Collins, Shirley Deng, Isaac Ehrlich, Paul Hodgetts, Yena Joo, Marija Pejcinovska, Mariam Walaa, and Matthew Wankiewicz, 2021, ‘An Introduction to DoSStoolkit’, arXiv, 19 May, https://arxiv.org/abs/2105.09347.\nKe-Li Chiu and Rohan Alexander, 2021, ‘Detecting Hate Speech with GPT-3’, arXiv, 23 March, https://arxiv.org/abs/2103.12407.\nKe-Li Chiu and Rohan Alexander, 2021, ‘On consistency scores in text data with an implementation in R’, arXiv, 13 January, https://arxiv.org/abs/2101.05225.\nPaul A. Hodgetts and Rohan Alexander, 2020, ‘cesR: An R package for the Canadian Election Study’, SocArXiv, 3 September, https://osf.io/preprints/socarxiv/a29h8/.\nRohan Alexander and Zach Ward, 2018, ‘Age at Arrival and Assimilation During the Age of Mass Migration’, The Journal of Economic History, 78(3), 904-937. Working paper version.\nSoftware\nRohan Alexander and A Mahfouz, 2021, heapsofpapers, https://rohanalexander.github.io/heapsofpapers/.\nDatasets\n\n\n\nAustralianPoliticians is an R package that consists of a collection of datasets related to Australian politicians. The datasets are up-to-date as of 30 November 2019. You can install the package from GitHub.\nAustralianElections is an R package that consists of a collection of datasets related to Australian elections. The datasets are up-to-date as of 10 September 2019. You can install the package from GitHub.\nPresentations\nUpcoming\n17 December 2021, University of Toronto Statistics and MachIne LEarning (SMILE) Journal Club.\n16 December 2021, Young Irish Statisticians.\n19 October 2021, Trinity College High Table.\nPast\nIntroduction to Andrew Gelman\n17 September 2021, University of Toronto, Data Sciences Institute launch.\nIntroduction to R\n22 December 2020, University of Toronto, Global Society for Genetics and Genome Biology.\nTurning Our World Into Data\n7 July 2021, Harvard Biostatistics Data Science in Action Summer Camp.\nForecasting Parliamentary Elections\n10 December 2019, Monash University, Department of Econometrics & Business Statistics, Melbourne.\n9 December 2019, Australian Society for Quantitative Political Science Conference, Melbourne.\n2 December 2019, Australian National University, Cake for Comments, Canberra.\n20 November 2019, POP Politics Workshop, Canberra.\n17 October 2018, University of Toronto, Political Behaviour Group, Toronto.\nA Word-Count Based Classifier of Politicians in the Australian Federal Parliament (1901–2018)\n4 September 2019, European Consortium for Political Research, General Conference, Wroclaw.\n22 June 2019, European Political Science Association, Annual Conference, Belfast.\n18 June 2019, Quantitative Text Analysis Workshop, Dublin.\nThe Effect of Elections and Prime Ministers on Discussion in the Australian Federal Parliament (1901—2018)\n11 January 2019, Political Methodology Specialist Group, Annual Conference, Warwick.\n11 December 2018, Max Planck Institute for Demographic Research, Rostock.\n22 November 2018, University of Toronto, Political Behaviour Group, Toronto.\n25 October 2018, Australian National University, Research School of Economics, Canberra.\n25 October 2018, Parliamentary Library, Parliament of Australia, Canberra.\n24 October 2018, Australian National University, School of Politics and International Relations, Canberra.\nExploring Australia’s Hansard (1901–2017)\n(Poster) 7-9 September, 2018 Economic History Association Meeting, Montreal.\nA Surnames-Based Analysis of Tasmanian Social Mobility (1803–2015)\n20 May 2016, UC Berkeley, Economic History Lunch, Berkeley.\n2 May 2016, Australian National University, Research School of Economics, Canberra.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:21-04:00"
    },
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-10-13T20:59:22-04:00"
    },
    {
      "path": "book.html",
      "title": "Book",
      "author": [],
      "contents": "\nMy book Telling Stories With Data was accepted for publication by CRC Press in May 2021. It is currently under development, and I’d appreciate any feedback.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:22-04:00"
    },
    {
      "path": "bookshelf.html",
      "title": "Bookshelf",
      "description": "Inspired by Patrick Collison's [version](https://patrickcollison.com/bookshelf), this is an incomplete (so far) list of the books that Monica and I own in Toronto. We've been a bit more liberal than Patrick and included a section on books that we've read and would like to own. If you have recommendations, then please [get in touch](mailto:rohan.alexander@utoronto.ca). We usually only buy books that we like, but starred books are ones either Monica or I especially like. \n",
      "author": [],
      "contents": "\n\nContents\nAcademic\nNon-fiction\nFiction\nCookbooks\nWant to buy\nBest books that I read in:\n\nAcademic\nBryant, John, and Junni L. Zhang, ‘Bayesian Demographic Estimation and Forecasting’.\nChan, Ngai Hang, ‘Time Series’.\nClark, Greg, ‘The Son Also Rises’.\nDuflo, Esther, ‘Expérience, science et lutte contre la pauvreté’. Monica ‘borrowed’ this from the Berkeley Demography library before Duflo won the Nobel and now we’re not giving it back.\nFoster, Ghani, Jarmin, Kreuter, Lane, ‘Big Data and Social Science’.\nFrancois Chollet with JJ Allaire, ‘Deep Learning with R’.\n⭐Friedman H, Jerome, Robert Tibshirani, and Trevor Hastie, ‘Elements of Statistical Learning’.\n⭐Gelman, Andrew and Jennifer Hill, ‘Data Analysis Using Regression and Multilevel Hierarchical Models’. Ah, the money-maker! Thank you Gelman and Hill. I haven’t properly studied this book, just dipped in and out as needed, but Monica’s probably read it more than enough for both of us.\nGelman, Andrew, Jennifer Hill and Aki Vehtari, ‘Regression and Other Stories’. Very disappointing follow-up. Hopefully they just go through their earlier book to update and tidy, and change all the code to Tidyverse and Stan.\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari and Donald Rubin, ‘Bayesian Data Analysis’. Known as the old-testament in our household.\nGirosi, Federico and Gary King, ‘Demographic Forecasting’.\nHealy, Kieran, ‘Data Visualization’.\nImai, Kosuke, ‘Quantitative Social Science’.\n⭐McElreath, Richard, ‘Statistical Rethinking’. Known as the new-testament in our household.\nMcLean, Ian, ‘Why Australia Prospered’.\nNeuman, Lawrence W, ‘Social Research Methods’.\nPetty, William, John Graunt and Charles Henry Hull, ‘The Economic Writings of Sir William Petty: Together with the observations upon the bills of mortality, more probably by Captain John Graunt’.\n⭐Pitman, Jim, ‘Probability’. Monica loves this book. We own multiple copies.\nPreston, Samuel, Patrick Heuveline and Michel Guillot, ‘Demography’.\nSalganik, Matthew, ‘Bit by Bit: Social Research in the Digital Age’.\nSmith, David and Nathan Keyfitz, ‘Mathematical Demography’.\nStewart, James, ‘Calculus’.\nTaddy, Matt, ‘Business Data Science’.\nWachter, Ken, ‘Essential Demographic Methods’.\nWakerly, Dannis, William Mengenhall, Richard Scheaffer, ‘Mathematical Statistics with Applications’.\n⭐Wickham, Hadley, and Grolemund, Garrett, ‘R for Data Science’. Some people convert to Catholicism when they get married, I converted to R. But my knowledge was piecemeal and going through this book addressed that.\n⭐Witten, Daniela, Gareth James, Robert Tibshirani, and Trevor Hastie, ‘Introduction to Statistical Learning’. Going through this with Peter taught me a lot including: 1) if you want to learn something then buy a physical copy of a textbook, get a partner and commit to weekly chapter reviews; 2) learn statistics from statisticians; and 3) statistics is awesome and I want to learn more. I always thought that I was terrible at it because econometrics never came easily to me, but now I realise that maybe the econometrics-approach isn’t for me, but the statistics one is.\nWu, Changbao and Mary Thompson, ‘Sampling Theory and Practice’.\nNon-fiction\n‘150 Years of Stats Canada!’.\nAchatz, Grant and Nick Kokonas, ‘Life, on the Line’.\n⭐Agassi, Andre, ‘Open’. Tennis is incidental to the aspects that make this book great, so try it even if you don’t particularly like the sport. I can’t remember who recommended it – seems like a Nick Crocker type of book?\nAslett, Don, ‘Is There Life After Housework’. Got given this at the Museum of Clean in Pocatello, Idaho. The museum was surprisingly good!\nCarson, Anne, ‘Autobiography of Red’. Present from Dad.\nClemens, Mark, ‘The Mountain’. Present from Dad.\nClinton, Bill, ‘My Life’.\nCrabb, Annabel, ‘Stop At Nothing’. This Turnbull bloke sounds like he’d be a great prime minister.\nDennison, CJ, ‘Yesterday’s Hobart Today’. Present from Helen.\nEdwards, John, ‘Keating: The Inside Story’.\nElliot, Francis and James Hanning, ‘Cameron’. I haven’t yet come across a good David Cameron biography, but this one was interesting. Focused on pre-parliament period.\nGaskell, Elizabeth, ‘The Life of Charlotte Brontë’.\n⭐Halberstam, David, ‘The Best and the Brightest’. I read Plato’s Republic at an impressionable age and so I used to think that if we could just put the smart people in charge then the ‘right’ decisions would be made. This book cured me of that.\nHolden, Anthony, ‘King Charles III’.\nHumphrey, Luke, ‘Hansons Half-Marathon Method’.\nHumphrey, Luke, ‘Hansons Marathon Method’. Bought this; followed this; ran my best marathon.\nJohnson, E, Robert and Janet L Byron, ‘Berkeley Walks’.\nKelly, Paul, ‘Triumph and Demise’. Present from Dad.\nKudelka, ‘Hobart’.\nLawrence, TE, ‘Seven Pillars of Wisdom’. ‘Borrowed’ from Dad. .\nLepore, Jill, ‘If Then’. I’ve never been so disappointed by a book. So much potential.\nLevitt, Steven and Stephen Dubner, ‘Freakonomics’.\nLove, David, ‘Unfinished Business’.\nMarr, David, ‘Political Animal’.\nMcNamee, Thomas, ‘Alice Waters and Chez Panisse’.\nMears, Ashley, ‘Very Important People’.\nMegalogenis, George, ‘The Longest Decade’.\nMitchell, M. Waldrop, ‘The Dream Machine’.\nMoore, Charles, ‘Margaret Thatcher’. Present from Dad.\nNT News, ‘What a Croc: Legendary Front Pages From the NT News’. Present from Mark.\nObama, Barack, ‘A Promised Land’.\nObama, Barack, ‘Audacity of Hope’.\nPetzold, Charles, ‘Code: The Hidden Language of Computer Hardware and Software’.\nSchlesinger, Arthur, ‘A Thousand Days’.\nSimmons, Bill, ‘The Book of Basketball’.\nSorenson, Ted, ‘Kennedy’.\nStephanopoulos, George, ‘All Too Human’. I thought that politics was romantic until I read this book when I was 20.\nTrump, Donald and Tony Schwartz, ‘The Art of the Deal’. This book is terrible. Read that NYT article about how he really made his money instead.\nTucker, Ross and Jonathan Dugas, ‘Runner’s World: The Runner’s Body’.\n⭐Vanhoenacker, Mark, ‘Skyfaring’. Read this on your next flight.\n⭐Vaughan, Diane, ‘The Challenger Launch Decision’. One of the greatest non-fiction books ever.\nWormser, Baron, ‘The Road Washes Out in Spring’. Stayed at the author’s house, so bought some of his books and particularly liked this one about how his family lived off the grid in New England. Liked it even better after living in Amherst for a while.\nZ, Jay, ‘Decoded’.\nFiction\nAesop, ‘Fables’.\nAmis, Kingsley, ‘Lucky Jim’.\nAmis, Kingsley, ‘The Crime of the Century’.\nBronte, Anne, ‘Agnes Grey’.\nBronte, Anne, ‘The Tenant of Wildfell Hall’.\nBronte, Charlotte, ‘Jane Eyre’.\nBronte, Charlotte, ‘Shirley’.\nBronte, Charlotte, ‘The Professor’.\nBronte, Charlotte, ‘Villette’.\nBronte, Emily, ‘Wuthering Heights’.\nCamus, Albert, ‘Le Chute’.\nChaucer, Geoffrey, ‘The Canterbury Tales’.\nChristie, Agatha, ‘Approximately 1,000,000 different titles’.\nCrichton, Michael, ‘The Andromeda Strain’.\nDavies, Robertson, ‘The Rebel Angels’.\nDeWitt, Helen, ‘Lightning Rods’.\nDeWitt, Helen, ‘Some Trick’.\n⭐DeWitt, Helen, ‘The Last Samurai’. Nothing to do with the Tom Cruise movie.\nDickens, Charles, ‘Oliver Twist’.\nDoyle, Arthur Conan, ‘Various titles’.\nEliot, George, ‘Middlemarch’.\nEugenides, Jeffrey, ‘Middlesex’.\nFitzgerald, Scott, ‘Tender is the Night’.\nFlanagan, Richard, ‘The Sound of One Hand Clapping’. Present from Helen.\nFleming, Ian, ‘Moonraker’.\nFleming, Ian, ‘On Her Majesty’s Secret Service’.\nGalsworthy, ‘The Silver Spoon and Passers By’.\nGalsworthy, ‘The White Monkey and A Silent Wooing’.\nGalsworthy, John, ‘The Man of Property’.\nGalsworthy, John, ‘End of the Chapter’.\nGalsworthy, John, ‘Swan Song’.\nGalsworthy, John, ‘The Forsyth Saga’.\nGrisham, John, ‘The Pelican Brief’.\nHardy, Thomas, ‘Tess of the D’Urbervilles’.\nHaruf, Kent, ‘Plainsong’.\nIshiguro, Kazuo, ‘The Unconsoled’.\nle Carré, John, ‘A Perfect Spy’. Dad likes le Carré so I buy them when there’s a nice edition.\nMelchor, Fernanda, ‘Hurricane Season’.\nOndaatje, Michael, ‘The English Patient’.\nPotok, Chaim, ‘The Chosen’.\nRowling, K, J, ‘Harry Potter and the Half-Blood Prince’.\nRushdie, Salman, ‘The Moor’s Last Sigh’.\nSchulz, Charles, ‘Snoopy and the Red Baron’.\nSchulz, Charles, ‘Very Funny, Charlie Brown’.\nSeth, Vikram, ‘The Golden Gate’.\nShakespeare, William, ‘Complete Works’.\nSimson, Graeme, ‘The Rosie Project’.\nThackeray, William, ‘Vanity Fair’.\nTolstoy, Leo, ‘War and Peace’.\n⭐Waugh, Evelyn, ‘Brideshead Revisited’.\nWaugh, Evelyn, ‘Officers and Gentlemen’.\nWinton, Tim, ‘Cloudstreet’. All Australians have a copy of this. I think it’s in the constitution.\nWinton, Tim, ‘Island Home’. Present from Helen. There may be a theme emerging.\nWinton, Tim, ‘The Shepherd’s Hut’. Present from Helen.\nCookbooks\nAlexander, Stephanie, ‘The Cook’s Companion’. Again, all Australians own this.\nCountry Women’s Association of Tasmania, ‘The 21st Birthday Cookery Book’. My understanding, based on Helen, is that all Tasmanian women own this.\nEvans, Matthew, Nick Haddow and Ross O’Meara, ‘The Gourmet Farmer Goes Fishing’. Present from Helen.\nGrossi, Guy, ‘Italian’. Present from Angela.\nKeller, Thomas, ‘Bouchon Bakery’.\nOliver, Jamie, ‘Jamie’s 30-Minute Meals’.\nPant, Pushpesh, ‘India’.\nRedzepi, Rene and David Zilber, ‘The Noma Guide to Fermentation’.\nWomen’s Weekly, ‘Children’s Birthday Cake Book’.\nWant to buy\nCarreyrou, John, ‘Bad Blood: Secrets and Lies in a Silicon Valley Startup’. About Theranos, a company that faked blood test results.\nChozick, Amy, ‘Chasing Hillary’. Extended 2016 Clinton campaign diary. Many (most?) campaign dairies are terrible but this is worthwhile reading in and of itself and the interaction with ‘Devil’s Bargain’ was especially good. See notes for ‘Devil’s Bargain’.\nGreen, Joshua, ‘Devil’s Bargain’. About Bannon and his relationship with Trump. Worthwhile reading in and of itself, but the interaction with ‘Chasing Hillary’ was especially good. Neither is quantitative, but both help to understand 2016 e.g. how could the Comey reopening have a statistical effect? Green shows Bannon spent years creating specific mainstream doubts re Clinton. Chozick shows how/why Clinton campaign decisions accentuated them. I’m as keen on quant political analysis as anyone (shout out to @petitpoll if you want Australian polling!), but the snippets (and there was not much unfortunately) about each campaign’s quant groups made me wonder if we have a cohort issue ATM. Specifically, do those in charge of political campaigns (or for that matter many businesses) know enough quant to know it’s important, but not enough to appreciate, and hence be able to compensate for, it’s weaknesses?\nIgnatieff, Michael, ‘Fire and Ashes: Success and Failure in Politics’. Changed the way that I thought about politics. Gave my copy to Amir.\nPetzinger, Thomas, ‘Hard Landing’. About the deregulation of the US airline market.\nPrice A, David, ‘The Pixar Touch’. Incredible details about their overnight success, 23 years in the making.\nThiel, Peter, ‘Zero to One’. Maybe it’s the jet-lag, but is this a business book that’s actually not terrible? A few weak chapters, but enough interesting ones to outweigh them.\nYanighara, Hanya, ‘A Little Life’. Recommended by Lauren.\nBest books that I read in:\n2019\nHahahahaha, the baby was born in 2019.\n\n2018:\nCarreyrou, John, ‘Bad Blood’.\nGreen, Joshua, ‘Devil’s Bargain’.\nChozick, Amy, ‘Chasing Hillary’.\nPetzinger, Thomas, ‘Hard Landing’.\nAgassi, Andre, ‘Open’.\nDeWitt, Helen, ‘Some Trick’.\nWaldrop, Mitchell M, ‘The Dream Machine’.\nPrice, David A, ‘The Pixar Touch’.\n\n",
      "last_modified": "2021-10-13T20:59:23-04:00"
    },
    {
      "path": "canadian_election_2021_forecasting.html",
      "title": "Forecasting the 2021 Canadian Election",
      "description": "Supported by the Canadian Election Study, CANSSI Ontario, Faculty of Information, and Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nOverview\nApproaches\nPoll of polls\nPrediction markets\nEconomic fundamentals\nKitchen sink\nMultilevel regression with post-stratification\n\nFAQ\nContact\n\nOverview\nThe 2021 Canadian Election will be held on 20 September. The Canadian Election Study, CANSSI Ontario, Faculty of Information, and Department of Statistical Sciences are calling for your best forecast for the winner of each of the 338 ridings. The three submissions will be invited to present their work at a special meeting of the Toronto Data Workshop to be held in on 1 October.\nWe are interested in exciting approaches that blend Canadian political understanding, statistical modelling, and data in innovative ways. We have provided some examples below, but ultimately, the approach is up to you. We are interested in who you think will win each riding, and the reasoning that underpins your approach. The full methodology must be public and reproducible to be considered.\nBefore the first poll closes in the eastern states, please submit a link to a GitHub repository, or Dropbox folder, that contains your data, model, and a brief write up of your approach. For ease of comparison, please also include the following CSV with your riding-specific forecasts.\nTo submit your forecast, please fill out this form.\nThe three invited groups will be:\nThe student team with the greatest number of seats correctly forecast.\nThe undergraduate team with the greatest number of seats correctly forecast (or the second closest team if the undergraduate team wins).\nThe team with the most innovative and exciting approach.\nEach team may only submit one forecast. A forecast looks like (options are: LPC, CPC, BQ, NDP, GPC, Other):\nriding_code\nforecast_winner\n10001\nLPC\n10002\nCPC\n10003\nBQ\n10004\nNDP\n10005\nGPC\n10006\nOther\n…\n…\nWe recommend working as part of a team, but you are welcome to work individually as well.\nApproaches\nPoll of polls\n538-style poll-of-polls are popular and a useful background is provided by Jackman (2005). One Canadian implementation is Éric Grenier’s Poll Tracker: https://newsinteractives.cbc.ca/elections/poll-tracker/canada/.\nPoll of polls models are typically national or provincial due to data availability. But in the methodology section of his website (scroll to the bottom of the page), Grenier discusses how riding-specific estimates can be created:\n\nThe seat projection model uses a proportional swing method based on the difference between the results of the last election and current polls. For example, if a party managed 20 per cent in Quebec in the 2019 federal election and is now polling at 40 per cent in Quebec, the party’s 2019 election results in each riding in Quebec are doubled. This swing is applied to every party in each riding.\n\nOne way to implement this would be to get a list of the ridings and the vote share in 2019, and to then apply Grenier’s provincial-specific swings to that. Some riding-specific polling is also available and this could be used to augment such a model. Additional complications could include incumbency status and features of the local candidate, which Stevens et al. (2019) finds could be important in something like 10 per cent of contests.\nAlternatively, you could construct your own poll-of-polls model. Polling data is available.\nPrediction markets\nWolfers and Zitzewitz (2004) provide an overview of the role of prediction markets and argue they ‘are typically fairly accurate, and that they outperform most moderately sophisticated benchmarks.’ The UBC Sauder School of Business has implemented a prediction market for the 2021 election: https://predictionmarkets.ca. This provides the essential basis of a model.\nOne way to implement a riding-specific approach would be to look at the relationship between the 2019 prediction market - https://predictionmarkets.ca/CA19.php - and the actual election results.\nEconomic fundamentals\nBélanger and Godbout (2010) implement ‘a classic politico-economic model.’ Their baseline model considers vote share as a function of unemployment, popularity of the governing party, and the tenure of that governing party. To implement that on a riding-specific basis:\nVarious employment-related measures are available on a riding basis from the Canada Revenue Agency.\nThe overall popularity of the governing party could be based on any high-quality recent poll.\nThe tenure of the Liberal is known.\nAs our focus is riding-specific, this model could also be augmented to include the party of the incumbent in the riding.\nMongrain (2019) implements a similar model for the 2019 Canadian election and considers additional variables.\nKitchen sink\n338Canada combines all of the above along with demographics to produce estimates on a riding-specific basis. Some information about methodology is available: https://338canada.blogspot.com/2018/11/welcome-to-338canada.html#metho. The essentials are similar to the Grenier uniform swing approach, with some differences due to demographics and star candidates.\nMultilevel regression with post-stratification\nMultilevel regression with post-stratification (MRP) is one way to forecast an election. It trains a model on a survey, and then applies that trained model to another dataset. It can be used to generate estimates for all 338 ridings, however the trade-off is increased uncertainty. Some notes about MRP with worked examples and supporting literature are available here: https://www.tellingstorieswithdata.com/mrp.html.\nIf you are interested in implementing a MRP model, then please use the 2019 CES data for the ‘survey.’ Stephenson et al. (2021) provides important background. We will provide access to the following 2021 CES data - age-group, gender, highest education - after the election is finished that you can use to re-run your model and see what your model would have forecast. We are not releasing the real 2021 CES data before the election because we do not want there to be any potential concern that the CES is affecting the election in any way.\nSome post-stratification data is available here.\nFAQ\nHow can I complicate the model? One way is to consider different functional specifications. Another way is to add additional layers to the model, for instance finding extra information about each riding (hint: maybe past vote and incumbency!) and adding that to your model. Often the best forecasts are made by teams that combine an understanding of politics with statistics.\nCan I work as part of a team? Yes, that is recommended.\nContact\nFor any questions or comments, please contact Rohan Alexander: rohan.alexander@utoronto.ca.\n\n\n\nBélanger, Éric, and Jean-François Godbout. 2010. “Forecasting Canadian Federal Elections.” PS: Political Science &Amp; Politics 43 (4): 691–99. https://doi.org/10.1017/S1049096510001113.\n\n\nJackman, Simon. 2005. “Pooling the Polls over an Election Campaign.” Australian Journal of Political Science 40 (4): 499–517.\n\n\nMongrain, Philippe. 2019. “2019 Canadian Federal Election – Forecasts for the Incumbent Party.” https://www.chairedemocratie.com/2019/10/22/2019-canadian-federal-election-forecasts-for-the-incumbent-party/.\n\n\nStephenson, Laura B, Allison Harell, Daniel Rubenson, and Peter John Loewen. 2021. “Measuring Preferences and Behaviours in the 2019 Canadian Election Study.” Canadian Journal of Political Science/Revue Canadienne de Science Politique 54 (1): 118–24.\n\n\nStevens, Benjamin Allen, Md Mujahedul Islam, Roosmarijn de Geus, Jonah Goldberg, John R McAndrews, Alex Mierke-Zatwarnicki, Peter John Loewen, and Daniel Rubenson. 2019. “Local Candidate Effects in Canadian Elections.” Canadian Journal of Political Science/Revue Canadienne de Science Politique 52 (1): 83–96.\n\n\nWolfers, Justin, and Eric Zitzewitz. 2004. “Prediction Markets.” Journal of Economic Perspectives 18 (2): 107–26. https://doi.org/10.1257/0895330041371321.\n\n\n\n\n",
      "last_modified": "2021-10-13T20:59:24-04:00"
    },
    {
      "path": "doss_toolkit-hiring.html",
      "title": "DoSS Toolkit - Call for applications",
      "author": [],
      "contents": "\nU of T students - please search the job id - 171201 Research Assistant - under oncampus jobs and associated job posting. For their support of this call we thank: the PIE Fund, and especially Bethany White and Radu Craiu from the Department of Statistical Sciences (DoSS).\nCall for applications\n10 October 2020\nAre you an undergraduate or graduate student at the Univeristy of Toronto? Would you like to work with Sam-Jo Caetano and Rohan Alexander to help put together a toolkit for applied statistics? It’s focused on R essentials such as ggplot, tidyverse, GitHub, and all their friends.\nIf so, please send an email to rohan.alexander@utoronto.ca with the subject line ‘DoSS toolkit application’. Please attach one PDF that contains both a cover letter and a CV. As part of your cover letter, please include a link to a GitHub repo showing off some code that you’ve written, or if you don’t have that, a blogpost you’ve written that is of a statistical/quantitative/technical nature.\nApplications will be reviewed on a rolling basis, but the final deadline to apply is the end of Wednesday, 21 October 2020.\nThe normal RA hourly rate and conditions will apply.\nApplications from people that have been under-represented in statistical sciences are particularly encouraged.\nBy way of background, we are looking to employ a small team of undergraduate and graduate students to help build a set of instructional material about R that will be used across DoSS starting in Winter (and hopefully soon after that, the broader university and community). This will build on work already done by a bunch of DoSS folks including Bethany White and Nathan Taback, and of course build on and complement the first-year courses.\nYou will help put together written material, videos, and assessment. You will be credited as a contributor to what will be a public-facing resource. You will have a chance to develop your R, teaching, and communication skills, as well as gain experience working in a small team.\nWe expect you to have some familiarity with R (i.e. have used it for a course or two), but you do NOT need to be an R expert. Indeed some successful applications may be in their first term with R.\nThe majority of the work will occur in early/mid November, but your appointment will run from November through to January to help deal with any lingering minor issues. The total time commitment would vary from 20 to 60 hours, depending on your circumstances and availability. The work is flexible and can be done at a time that suits you. Given we are in a pandemic, the work will be conducted remotely. Most day-to-day management will occur through Slack and GitHub.\nWe hope you apply!\nRohan and Sam\n\n\n\n",
      "last_modified": "2021-10-13T20:59:24-04:00"
    },
    {
      "path": "foundations_of_the_data_sciences.html",
      "title": "Foundations of the data sciences",
      "description": "The data sciences have a common concern: How can others be confident that our statistical approaches have been brought to bear on appropriate datasets? This course focuses on the 'data' of the data sciences. It develops in students an appreciation for the many ways in which dealing with a dataset can get out-of-hand, and establishes approaches to ensure data science is conducted in ways that engenders trusted findings.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nPre-requisites\nTextbook\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nWeekly quizzes\nTutorial\nProfessional conduct\nPaper #1\nPaper #2\nPaper #3\nFinal Paper\n\n\nPreamble\nOverview\nThe course will be an enormous amount of work and cause you some amount of stress. This is unfortunate, but there’s little way around it. All I can tell you is that having done this course, it’ll be easier in the future.\nThe purpose of this course is to develop students who appreciate, and can iterate on, the foundations of the data sciences.\nThis course will require students to:\nactively read and consider a large amount of literature;\nactively learn the statistical programming language R and apply it to real-world conditions;\ngather, clean, and prepare their own datasets; and\ndevelop killer statistics skills.\nEssentially this course provides students with everything that they need to know to be able to do the most exciting thing in the world: use data to tell convincing stories.\nFAQ\nCan I audit this course? Sure, but it’s pointless, because the only way to learn this stuff is to do the work.\nWhat is a tutorial? You write a paper. Then you send it to your tutor. The next day you have a meeting, ‘tutorial’, where you discuss it with them.\nWhy is there so much assessment? The only way to learn is to actually do the work, and students only do the work when they are assessed. It’s unfortunate, but there’s no way around it.\nPre-requisites\nTelling Stories with Data, Chapter 1: Telling Stories with Data\nTextbook\nAlexander, 2022, Telling Stories with Data, CRC Press, https://www.tellingstorieswithdata.com.\nContent\nWeek 1\n‘Drinking from a fire hose’.\nContent:\nSeveral end-to-end worked examples, and develop essential skills in R.\n\nWeek 2\n‘Science-ing’.\nContent:\nEstablish a workflow for data sciences, including R Markdown, R Projects, Git and GitHub.\nPut in place a framework for writing papers.\n\nWeek 3\n‘Communicating’.\nContent:\nHow to effectively use graphs, tables, and maps.\nHow to make a website and use Shiny.\n\nWeek 4\n‘Gathering data’.\nContent:\nUsing APIs, scraping, OCR, semi-structured datasets, and text.\n\nWeek 5\n‘Hunting data’.\nContent:\nExperiments, sampling and surveys, and A/B testing.\n\nWeek 6\n‘Cleaning data’.\nContent:\nWorkflow for cleaning data.\nEffective naming, checks, and testing.\n\nWeek 7\n‘Store, retrieve, disseminate and protect’.\nContent:\nR packages for data, and documentation including datasheets.\n\nWeek 8\n‘Share, but not too much’.\nContent:\nPersonally identifying information, hashing and salting, GDPR and HIPPA, simulated data, and differential privacy.\n\nWeek 9\n‘Whoops, I forgot EDA’.\nContent:\nComing to terms with a dataset and understanding what is in it.\n\nWeek 10\n‘IJALM - It’s Just A Linear Model’.\nContent:\nSimple linear regression, multiple linear regression, logistic regression, Poisson regression.\n\nWeek 11\n‘Lorem ipsum’.\nContent:\nDealing with text-scale datasets and trying to make sense of them using statistical approaches.\n\nWeek 12\n‘Deployment’\nContent:\nR packages for models, Shiny, and Plumber and model APIs\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nWeekly quiz\n10\nWeekly before the lecture\nTutorial\n10\nWeekly before the lecture\nProfessional conduct\n1\nAnytime during the teaching term\nPaper 1\n25\nEnd of Week 3\nPaper 2\n25\nEnd of Week 6\nPaper 3\n25\nEnd of Week 9\nFinal Paper (initial submission)\n1\nEnd of Week 12\nFinal Paper (peer review)\n3\nThree days after that\nFinal Paper\n25\nTen days after that\nWeekly quizzes\nDue date: Weekly before the lecture.\nWeight: 10 per cent (only best eight out of twelve count.)\nTask: Please complete a weekly quiz in Quercus.\nQuestions: The questions that form the quiz are drawn from those in the Quiz sections of Telling Stories with Data.\nTutorial\nDue date: Weekly before the lecture.\nWeight: 10 per cent (only best five out of twelve count.)\nTask: Please complete a tutorial question and submit it via Quercus.\nQuestions: Tutorial questions are drawn from those in the Tutorials sections of Telling Stories with Data.\nProfessional conduct\nDue date: Anytime during the teaching term.\nWeight: 1 per cent\nTask: We (optionally) use Slack to interact in this class. At some point during the teaching term, please use Slack to answer another student’s question or otherwise similarly be generally helpful in a professional manner. When you do that, please share the comment into the ‘Professional conduct’ channel and @ me (hover on the message, click share message, type in the channel ‘profession_conduct’, add a message that @‘s me, and click ’share’). You’ll get the full mark just for one helpful interaction. (If you are opting out of using Slack - which is entirely fine - then instead, at some point in the term send me an email with a link that is relevant to the course materials and that I should add to the course notes. Please be clear that this is your ‘professional conduct’ submission by stating that in the subject line.)\nPaper #1\nDue date: End of Week 3.\nWeight: 25 per cent (for Papers #1-#3 the best two of three count).\nTask: ‘Mandatory minimums’\nPaper #2\nDue date: End of Week 6.\nWeight: 25 per cent (for Papers #1-#3 the best two of three counts).\nPaper #3\nDue date: End of Week 9.\nWeight: 25 per cent (for Papers #1-#3 the best two of three counts).\nFinal Paper\nDue dates:\nInitial submission: End of Week 12.\nPeer review: Three days after that.\nFinal Paper: Ten days after that.\n\nWeight: 29 per cent (4 per cent of this is for initial submission and peer review conducted a week before).\nInitial submission: 1 per cent\nPeer review: 3 per cent\nFinal Paper: 25 per cent\n\n\n\n\n",
      "last_modified": "2021-10-13T20:59:25-04:00"
    },
    {
      "path": "group.html",
      "title": "Research Group",
      "author": [],
      "contents": "\n\nContents\nOverview\nPeople\nFaculty affiliates\nIndustry affiliates\nStudents\n\n\n\n\n\nThanks to Paul Hodgetts for the fantastic logo.\nOverview\nMy research group exists to:\nconduct research at the intersection of information and statistical sciences;\nbring together researchers and practitioners from various academic disciplines and industry; and\nprovide high-quality training opportunities for students.\nWe organize the Toronto Data Workshop, which everyone is welcome to attend - sign up here. We also maintain an internal reading group and presentation schedule.\nPeople\nFaculty affiliates\nKelly Lyons.\nSamantha-Jo Caetano.\nIndustry affiliates\nSharla Gelfand.\nHareem Naveed.\nStudents\nStudents are equal partners, have considerable autonomy, are given co-authorship, and are paid. They take ownership of their project and contribute critically to its success.\n\n\n\nCurrent\nAmy Farrow is a Master of Information student at the University of Toronto.\nAnnie Collins is an undergraduate student at the University of Toronto specializing in applied mathematics and statistics with a minor in history and philosophy of science. Annie worked on ‘An Introduction to DoSStoolkit’ and ‘Reproducibility of COVID-19 pre-prints’.\nDan Xu is a doctoral student in the Faculty of Information at the University of Toronto. His research focus is on misinformation propagation in politics.\nKe-Li Chiu is a Master of Information student at the University of Toronto interested in natural language processing. Ke-Li worked on: ‘On consistency scores in text data with an implementation in R’ and ‘Detecting Hate Speech with GPT-3’.\nPaul Hodgetts is a Master of Information student at the University of Toronto. Paul put together cesR, which is an R package that makes it easier to gather and use the Canadian Election Study surveys from 1965 through to 2019, described here: https://osf.io/preprints/socarxiv/a29h8/. Work in progress involves estimates of stateless populations.\nPast\nA Mahfouz worked with me as a Master of Information student at the University of Toronto with a background in geography. Their prior work has been largely concerned with data pipelines. A contributed to many projects including: 1) heapsofpapers which is an R package that makes it easier to respectfully download files from the internet. 2) ‘Discussions of bias in AI/ML research’: In this paper we gather a sample of recent AI/ML research and use natural language processing to understand the extent to which bias, in an ethical rather than statistical sense, is considered. 3) ‘Communicating geographically-based Bayesian models’: In this paper we introduce a method to communicate the geographic results of Bayesian models.\nDiego Mamanche Castellanos worked with me as a Master of Information student at the University of Toronto, to which he brought more than six years of experience in financial companies. Diego focused on the paper, ‘Understanding OCR in the context of a broader statistical workflow’.\nHidaya Ismail worked with me as a Master of Information student at the University of Toronto. Hidaya focused on extracting and organising data from websites, in particular TikTok.\nYian Wang worked with me as an undergraduate student studying for an Honours Bachelor of Science degree with majors in statistics and economics and a minor in mathematics. Yian is interested in surveys and current work involves understanding the effect of COVID shutdowns on the restaurant industry.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:25-04:00"
    },
    {
      "path": "history_of_the_data_sciences.html",
      "title": "History of the data sciences",
      "description": "The data sciences have a long and robust history.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nTextbooks\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nTutorial papers\nFinal Paper\n\n\nPreamble\nOverview\nFAQ\nTextbooks\nStigler, S, 1986, The History of Statistics: The Measurement of Uncertainty before 1900, Harvard University Press.\nFriendly, M, and Wainer, H, 2021, A History of Data Visualization and Graphic Communication, Harvard University Press.\nSheynin, 2017, Theory of Probability. A Historical Essay, https://arxiv.org/abs/1802.09966,\nContent\nWeek 1\nOverview\nContent:\nStephen E. Fienberg, 1992, ‘A Brief History of Statistics in Three and One-Half Chapters: A Review Essay’, Statistical Science.\nM. G. Kendall, 1960, ‘Studies in the History of Probability and Statistics. Where Shall the History of Statistics Begin?’, Biometrika.\nStigler, 1986, Chs 1-2.\n\nWeek 2\n1700s and earlier\nContent:\nStigler, 1986, Chs 3-4\nSheynin, 2017, Chs 1-7.\n\nWeek 3\nEarly 1800s\nContent:\nStigler, 1986, Chs 5-6.\nSheynin, 2017, Chs 8-9.\n\nWeek 4\nLate 1800s\nContent:\nStigler, 1986, Chs 7-8.\nSheynin, 2017, Chs 10-11.\n\nWeek 5\nLate 1800s and early 1900s\nContent:\nStigler, 1986, Chs 9-10.\nDavid Freedman, 1999, ‘From association to causation: some remarks on the history of statistics’.\n\nWeek 6\nEarly 1900s\nStephen M. Stigler, 1996, ‘The History of Statistics in 1933’, Statistical Science\nSheynin, 2017, Chs 12-15.\nWeek 7\nSpecial topic: Data visualization\nContent:\nFriendly and Wainer, 2021, Chs 1-6 and 9.\n\nWeek 8\nSpecial topic: Computers\nContent:\nWilliam D. Nordhaus, ‘An Economic History of Computing’.\n\nWeek 9\nSpecial topic: Bayesian methods\nContent:\nStephen E. Fienberg, 2006, ‘When Did Bayesian Inference Become “Bayesian”?’, Bayesian Analysis.\nThomas Hoskyns Leonard, 2014, ‘A personal history of Bayesian statistics’, WIREs Computational Statistics.\n\nWeek 10\nSpecial topic: Whither statistics? The rise of data science\nContent:\nLeo Breiman, 2001, ‘Statistical Modeling: The Two Cultures’, Statistical Sciences.\nDavid J. Hand, 2015, ‘Statistics and computing: the genesis of data science’, Statistics and Computing.\n\nWeek 11\nSpecial topic: Overlooked contributors\nContent:\nMargo Anderson, 1992, ‘The History of Women and the History of Statistics’, Journal of Women’s History\nKatie Hafner, 2021, ‘Arianna Rosenbluth Dies at 93; Pioneering Figure in Data Science’, New York Times.\n\nWeek 12\nSpecial topic: Reckoning with the past\nContent:\nHow to consider our history?\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nTutorial\n60\nFortnightly before the lecture\nFinal Paper\n40\nTen days after that\nTutorial papers\nDue date: Fortnightly before the lecture.\nWeight: Each is worth 10 per cent.\nTask: Write a paper of 2-6 pages on a topic covered in the preceding two weeks. These will be circulated and discussed in class.\nFinal Paper\nDue dates: Final day of exam block.\nWeight: 40 per cent.\nTask: Write an original paper on a topic covered in the class.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:26-04:00"
    },
    {
      "path": "index.html",
      "title": "Rohan Alexander",
      "author": [],
      "contents": "\n\n          \n          \n          Rohan Alexander\n          \n          \n          Home\n          Academic\n          Group\n          Teaching\n          Toronto Data Workshop\n          Blog\n          \n          \n          Other\n           \n          ▾\n          \n          \n          Bookshelf\n          2021 Toronto Workshop on Reproducibility\n          \n          \n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Rohan Alexander\n            \n            \n              \n                \n                    \n                      \n                        Twitter\n                      \n                    \n                  \n                                    \n                    \n                      \n                        GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                        CV\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Email\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            8 October 2021: A competition that organized where undergraduates forecast the 2021 Canadian Election was featured on the departmental website: ‘Undergraduate students “pick up the gauntlet” to predict the 2021 federal election’.\n            I am an assistant professor at the University of Toronto in Information and Statistical Sciences. I am also the assistant director of CANSSI Ontario, a senior fellow at Massey College, and a faculty affiliate at the Schwartz Reisman Institute for Technology and Society. I hold a PhD in Economics from the Australian National University where I focused on economic history and was supervised by John Tang (chair), Martine Mariotti, Tim Hatton, and Zach Ward.\n            My book on foundational data skills, tentatively titled Telling Stories With Data, was accepted for publication by CRC Press in May 2021. And I am co-editor (alongside Lauren Kennedy and Andrew Gelman) of a book tentatively titled Multilevel Regression and Poststratification: A Practical Guide and New Developments, which was accepted for publication by Cambridge University Press in July 2021.\n            I use statistical models to try to understand the world. I am particularly interested in: how we get the data that go into those models; whose data are systematically missing; how we clean, prepare, and tidy data before they are modelled; the effects of all this on the implications of our models; and how we can reproducibly share the totality of this process. This research interest has a few different applications. One of those is Natural Language Processing (NLP), where I am interested in understanding the effects of bringing together large, biased datasets and enormous models, and how this can be improved. Another is Multilevel Regression with Post-stratification (MRP), where I examine the effects of trying to establish a correspondence between two datasets.\n            Students in my research group develop skills not only in using statistical methods in reproducible ways across various disciplines, but also appreciate their limitations, and think deeply about the broader context of their work. Some recent papers include: ‘Reproducibility of COVID-19 pre-prints’, ‘heapsofpapers’, ‘Detecting Hate Speech with GPT-3’, and ‘On consistency scores in text data with an implementation in R’.\n            I enjoy teaching and aim to help students from a wide range of backgrounds learn how to use data to tell convincing stories. In the Faculty of Information, I have taught ‘Experimental Design’ and lead reading courses in ‘Ethics and Data Science’, ‘Information Management in Interdisciplinary Research’ and ‘Reproducible Data Science’. In Statistical Sciences I have taught ‘Surveys, Sampling, and Observational Data’ and lead a reading course in ‘Natural Language Processing’. I am a RStudio Certified Tidyverse Trainer and an associate editor of the Journal of Statistics and Data Science Education.\n            I co-organize the weekly Toronto Data Workshop. All welcome! Sign up here.\n            \n            \n            \n            I am married to Monica Alexander, and we have two young children. I probably spend too much money on books, and certainly too much time at libraries (in a pre-COVID world). You can see some of the books that I recommend here. If you have any book recommendations of your own, then I’d love to hear them.\n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Rohan Alexander\n            \n            \n              \n                \n                                    \n                    \n                      Twitter\n                    \n                  \n                                    \n                    \n                      GitHub\n                    \n                  \n                                    \n                    \n                      CV\n                    \n                  \n                                    \n                    \n                      Email\n                    \n                  \n                                  \n              \n            \n            \n              8 October 2021: A competition that organized where undergraduates forecast the 2021 Canadian Election was featured on the departmental website: ‘Undergraduate students “pick up the gauntlet” to predict the 2021 federal election’.\n              I am an assistant professor at the University of Toronto in Information and Statistical Sciences. I am also the assistant director of CANSSI Ontario, a senior fellow at Massey College, and a faculty affiliate at the Schwartz Reisman Institute for Technology and Society. I hold a PhD in Economics from the Australian National University where I focused on economic history and was supervised by John Tang (chair), Martine Mariotti, Tim Hatton, and Zach Ward.\n              My book on foundational data skills, tentatively titled Telling Stories With Data, was accepted for publication by CRC Press in May 2021. And I am co-editor (alongside Lauren Kennedy and Andrew Gelman) of a book tentatively titled Multilevel Regression and Poststratification: A Practical Guide and New Developments, which was accepted for publication by Cambridge University Press in July 2021.\n              I use statistical models to try to understand the world. I am particularly interested in: how we get the data that go into those models; whose data are systematically missing; how we clean, prepare, and tidy data before they are modelled; the effects of all this on the implications of our models; and how we can reproducibly share the totality of this process. This research interest has a few different applications. One of those is Natural Language Processing (NLP), where I am interested in understanding the effects of bringing together large, biased datasets and enormous models, and how this can be improved. Another is Multilevel Regression with Post-stratification (MRP), where I examine the effects of trying to establish a correspondence between two datasets.\n              Students in my research group develop skills not only in using statistical methods in reproducible ways across various disciplines, but also appreciate their limitations, and think deeply about the broader context of their work. Some recent papers include: ‘Reproducibility of COVID-19 pre-prints’, ‘heapsofpapers’, ‘Detecting Hate Speech with GPT-3’, and ‘On consistency scores in text data with an implementation in R’.\n              I enjoy teaching and aim to help students from a wide range of backgrounds learn how to use data to tell convincing stories. In the Faculty of Information, I have taught ‘Experimental Design’ and lead reading courses in ‘Ethics and Data Science’, ‘Information Management in Interdisciplinary Research’ and ‘Reproducible Data Science’. In Statistical Sciences I have taught ‘Surveys, Sampling, and Observational Data’ and lead a reading course in ‘Natural Language Processing’. I am a RStudio Certified Tidyverse Trainer and an associate editor of the Journal of Statistics and Data Science Education.\n              I co-organize the weekly Toronto Data Workshop. All welcome! Sign up here.\n              \n              \n              \n              I am married to Monica Alexander, and we have two young children. I probably spend too much money on books, and certainly too much time at libraries (in a pre-COVID world). You can see some of the books that I recommend here. If you have any book recommendations of your own, then I’d love to hear them.\n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2021-10-13T20:59:26-04:00"
    },
    {
      "path": "inf2178.html",
      "title": "INF2178: Experimental Design",
      "description": "INF2178 is a masters-level course at the University of Toronto's Faculty of Information.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nHow to succeed\nHow we’ll work\nAdvice from past students\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nReading Week\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nWeekly quizzes\nProfessional conduct\nPaper #1\nPaper #2\nPaper #3\nFinal Paper\n\n\nPreamble\nOverview\nExperimental design has a long and robust tradition within traditional applications such as agriculture, medicine, physics, and chemistry. It allows us to speak of causality with confidence. Typically, these are situations in which control groups can be established, randomization is appropriate, and ethical concerns can be assuaged. Unfortunately, such a set-up is rarely possible in the full extent of the modern applications where we want to understand causality.\n\n\n\nSource: https://xkcd.com/2400/\nThis course covers the traditional approaches and statistical methods, but focuses on what to do when traditional experimental design methods cannot be implemented or are not appropriate (i.e. what feels like most of the time these days). We cover experiments in their modern guise especially the concerns that we might have when we can run them; but also methods that can provide some causal understanding even when we cannot conduct traditional experiments. Importantly, these approaches do not rely on ‘big data’ or fancy statistics, but instead on thoroughly interrogating the data that are available to get understanding through as simple means as possible.\nThis is a hands-on course in which you will conduct research projects using real-world data. This means that you will: obtain and clean relevant datasets; develop your own research questions; use the statistical techniques that you are introduced to in class to answer those questions; and finally communicate your results in a meaningful way. This course is designed around approaches that are used extensively in academia, government, and industry. Furthermore, it includes many aspects, such as data cleaning and preparation, that are critical, but rarely taught.\nThis course is different to many other courses at the University of Toronto. At the end of this course, you will have a portfolio of work that you could show off to a potential employer. You will have developed the skills to work successfully as an applied statistician or data scientist. And you will know how to fill gaps in your knowledge yourself. A lot of scholarships and jobs these days ask for GitHub and blog links etc to show off a portfolio of your work. This is the class that gives you a chance to develop these. It’s very important to having something that shows off what you can do, and that needs to go beyond what is done in a normal class.\n\nHow to succeed\nIn this course you will work in a self-directed, open-ended manner. Identify relevant areas of interest and then learn the skills that you need to explore those areas.\nTo successfully complete this course, you should expect to spend a large portion of your time reading and writing (both code and text). Deeply engage with the materials. Find a small study group and keep each other motivated and focused. At the start of the week, read the course notes, all compulsory materials and some recommended materials based on your interest. After doing that, but before the ‘lecture’ time you should complete the weekly quiz. During ‘lectures’ I’ll live-code, discuss materials in the course notes, talk about an experiment, and you’ll have a chance to discuss the materials with me.\nYou need to be more active in your learning in this course than others - read the notes and related materials - and then go out there and teach yourself more and apply it. You will not be spoon-fed in this course. Each week try to write reproducible, understandable, R code surrounded by beautifully crafted text that motivates, backgrounds, explains, discusses and criticizes. Make steady progress toward the assessment.\nThis is not a ‘bird course’. Typically, after the term is finished, students say that the course is difficult but rewarding. The TAs and I are always available to answer any questions. Please come to office hours!\nHow we’ll work\nThis webpage will provide almost all the guiding materials that you need and links to the relevant parts of the notes. The course notes are available here: https://www.tellingstorieswithdata.com. Those contain notes and other material that you could go over. There is a course Slack for discussion. We’ll use Quercus really only for assessment submission and grading. I expect you to work professionally, and so we’ll try to use professional tools to the extent possible.\nA rough weekly flow for the course would be something like:\nRead the week’s course notes.\nRead/watch/listen to the compulsory materials.\nComplete the weekly quiz.\nAttend the lecture.\nAttend the lab.\nMake progress on a paper.\nAdvice from past students\nSuccessful past students have the following advice (completely unedited by me):\n‘Read the rubrics and treat INF2178 as a storytelling with data course rather than INF1344 part 2. Let the point distribution rubric guide what parts of the paper to focus on/expand. And pay attention to the “telling stories” part of the site URL. The point of the papers isn’t to chuck every statistical method and cool R trick you know in there, it’s to practice building data-driven arguments that different audiences might actually care about. Last, the piece of advice I wish I had followed for the class: keep a log of things that you find confusing/cool/useful.’\n‘Allocate as much time as you realistically can to projects. It all takes longer than expected (particularly debugging) so be a friend to your future self and don’t leave work to the last minute. Really.’\n‘Read the paper rubrics very carefully! The papers will always take longer than you think they will so try to start early and put enough time before submitting to make sure you sort out any issues with formatting and knitting your pdf because there will almost always be issues (especially if you’re doing it for the first time). Write the papers with an external audience in mind, not just as a school paper that only Rohan will read. Consider the papers to be personal projects that your peers and potential employers will be reading, and try to write something you feel could be published. Also, comment your code and thank yourself later :)’\n‘Do the readings even though there are a lot and don’t be afraid to ask questions no matter how stupid you think they are (unless the answer can easily be found, ie “is assignment 1 group or solo”). Also, Rohan is not as intimidating as he initially seems. Also, if you did poorly on assignment 1, don’t drop the class. There’s still so much to learn and the chance of making it up with the other two assignments.’\n‘You’re going to have to practice solving your own code problems, reviewing and keeping track of detailed assignment requirements, critical thinking about data, and editing your own work. It will take more time than you think.’’\n‘1) Try to keep up week to week as best as possible; watching the lectures is more rewarding that way because you have some understanding, especially if you watch asynchronously and can’t just ask the professor questions. Sometimes that means even skimming what readings you can if time is tight, otherwise you may feel quite lost. 2) R documentation is your best friend when you don’t wholly understand the examples in the course notes, or you’re looking for other viable solutions. Stack Overflow is also a great help, but don’t forget to cite everything you’ve taken from there so you remember where it came from when wondering, “How does this even work? It works, but how?” 3) Sometimes, your code will infuriate you. Take breaks. Step away for a half hour, do something else entirely for a while, or even come back tomorrow. Don’t beat yourself up too much over it. You can also ask for assistance in the course Slack, because odds are someone else has already encountered this issue and arrived at a solution. 4) Trust Rohan and his process. It’s going to rely on your efforts to learn on your own -and it’s going to feel like a harsh bootcamp- but you’ll learn to make friends with data and coding. 5) Practice the examples on your own before class. 6) Don’t be afraid or intimidated by other’s who seem to know more than you. 7) Attend Toronto Data Workshop whenever you can. 8) Form a study group early on’\n‘Don’t stop at just the assignment prompt. Have fun with your topic and see how you can take it further’\nAcknowledgements\nThanks to the following who helped develop this course: Monica Alexander, Kelly Lyons, Sharla Gelfand, Faria Khandaker, Hidaya Ismail, A Mahfouz, Paul Hodgetts, Thomas Rosenthal.\nContent\nEach week you should go through the course notes and all compulsory materials. During the lecture I will live-code various aspects. I will also discuss a case study, typically a paper. During the lab, a TA will either lead small group discussions or similarly lead other work. The lecture will be recorded and posted here, but again, it’s not enough to just watch that - you need to read and write yourself.\nWeek 1\n‘Drinking from a fire hose’.\nContent: Drinking from a fire hose, R Essentials.\nCase Study: Fisher’s Lady Tasting Tea.\nLab: Go through first four modules of DoSS Toolkit and discuss any issues with the TA.\nWeek 2\n‘Science-ing’.\nContent: Workflow, Static communication.\nCase Study: Tuskegee Syphilis Study.\nLab: Go through modules five to eight of DoSS Toolkit and discuss any issues with the TA.\nWeek 3\n‘Why, if ever I did fall off—which there’s no chance of—but if I did–’.\nContent: Experiments, and treatment effects.\nCase Study: The Oregon Health Insurance Experiment in the United States.\nSpecial guest: Greg Wilson on how to run a meeting.\nLab:\nPlease pretend that you work as a junior analyst for a large consulting firm. Further, pretend that your consulting firm has taken a contract to put together a facial recognition model for the Canada Border Services Agency’s Inland Enforcement branch. Write five or six points with regard to your thoughts on this matter. What would you do and why? Then split into small groups and compare your points with others. Do you think the model would end up being implemented?\nWith the help of the TA, please conduct ‘face-to-face’ surveys (via Zoom). For this exercise, you will be randomly split into groups of two. You have two minutes in each group and will then be swapped to another group. One person is to survey the other person asking the following questions: i) ‘What is your gender?’, ii) ‘What is your age?’, iii) ‘What is your marital status?’, iv) ‘What is your income?’, v) ‘If an election were held today who would you vote for?’. After one person is done, then switch roles. When you are the questioner you should record all responses using a small CSV (but not the person’s name please). When you are the respondent you are welcome to not respond. You will cycle through this multiple times. At the end, please write a small reflection about: 1) as a respondent, how you felt answering these questions and the implications that you think this feeling may have for how survey questions are answered more generally; and 2) as a questioner, how difficult it was to code responses and the implications this may have for the dataset that we analyse.\n\nWeek 4\n‘Gathering data’.\nContent: Gathering data.\nCase Study: Student Coaching: How Far Can Technology Go?\nLab:\nPlease pretend you work for Netflix and you want to know more about why people subscribe (or don’t!) when prices change. Please design an experiment, discuss its key features and how you would implement it. Please pay special attention to sampling issues. Then simulate an outcome.\nFollowing the guidance of the TA, please scrape some data and discuss some ethical considerations around the dataset that you created. You may like to write a short blog post discussing the difference between data being public but scattered, and a consolidated dataset being public with reference to Kirkegaard and Bjerrekær, 2016, and Politou, Alepis, and Patsakis, 2018 (if you do that please do email a link to me out of interest).\n\nWeek 5\n‘Whoops, I forgot EDA’.\nContent: Exploratory Data Analysis.\nCase Study: Civic honesty around the globe\nLab:\nPretend that you work for Loblaws as a data scientist and it is late March 2020. As part of normal monitoring, you have noticed that purchases of flour and pasta have increased substantially. You had been planning to increase the price of these items in April as part of a trial, but now your manager is not sure whether it is appropriate to conduct the trial. Please write five or six points with regard to your thoughts on this matter. What would you do and why?\nAnalyse the Toronto AirBNB dataset with guidance from the TA.\n\nReading Week\n\n\n\nWeek 6\n‘IJALM - It’s Just A Linear Model’.\nContent: Linear and logistic regression and tidymodels\nCase Study: Upworthy A/B tests of headlines.\nSpecial guest: Kathy Ge on experiments at Uber.\nLab recording:\nFollowing the guidance of the TA, please use Blogdown to create a simple website and then design and execute a simple A/B test for your website using Netlify.\n\nWeek 7\n‘Celestial Navigation’.\nContent: Simulation, power, RCTs, A/B testing.\nCase Study: Please pick one chapter from Catherine D’Ignazio and Lauren F. Klein, Data Feminism, that is of interest to you and read it (freely available: https://data-feminism.mitpress.mit.edu).\nLab:\nFollowing the guidance of the TA, please make a Shiny app that bundles a little data and some code and post it to shinyapps.com.\n\nWeek 8\n‘Such a shame they’ll never meet’.\nContent: Matching and difference in differences.\nCase Study: Funding of Clinical Trials and Reported Drug Efficacy\nSpecial guest: Emily Riederer on observational causal inference.\nSpecial guest: Tamar Oostrom on funding of clinical trials.\nLab:\nFollowing the guidance of the TA, please look at McClelland, Alexander, 2019, ‘“Lock This Whore Up”: Legal Violence and Flows of Information Precipitating Personal Violence against People Criminalised for HIV-Related Crimes in Canada’, European Journal of Risk Regulation, 10 (1), pp. 132-147.\nThen look at Policing the Pandemic - https://www.policingthepandemic.ca/. Look into how they gathered their dataset and what it took to put this together. What is in the dataset and why? What is missing and why? How could this affect the results? How might similar biases enter into other datasets that you have used or read about?\nPut together a brief model. You may like to write a short blog post about the biases and influences that are in this dataset (if you do that please do email a link to me out of interest).\n\nWeek 9\n‘Why does it always rain on me?’.\nContent: Regression discontinuity and instrumental variables.\nCase Study:\nJames H. Ware, 1989, ‘Investigating Therapies of Potentially Great Benefit: ECMO’, Statistical Science, available here.\nDonald A. Berry, 1989, ‘Comment: Ethics and ECMO’, Statistical Science, available here.\n\nLab:\nFollowing the guidance of the TA, please make an R package that bundles a little data and some code and add it to your GitHub. Don’t forget to include at least one test.\n\nWeek 10\n‘Post Hoc, Ergo Propter Hoc’.\nContent: DAGs, bias, and paradoxes.\nCase Study: Joshua Kalla and David Broockman, 2016, ‘Campaign Contributions Facilitate Access to Congressional Officials: A Randomized Field Experiment’\nLab:\nFollowing the guidance of the TA, please look back on the case studies that we’ve covered so far. Please break up into small groups and create DAGs for each. Then write some notes about the potential for confounding, selection bias and measurement bias. Pick one person in your group to make a brief 2-minute presentation about what you did.\n\nWeek 11\n‘But it works on my machine’.\nContent: Shiny, cloud, and deploying.\nCase Study: Alexander, M., Wildeman, C., Roehrkasse, A., and Rudlang-Perman, K., 2020, ‘Forecasting child welfare outcomes in the United States’, Shiny app; Technical model summary.\nLab:\nFollowing the guidance of the TA, and thinking about what we covered in lectures, please read, compare, and discuss:\nBendavid, E., Mulaney, B., Sood, N., Shah, S., Ling, E., Bromley-Dulfano, R., …, and Tversky, D, 2020, ‘COVID-19 Antibody Seroprevalence in Santa Clara County, California’, MedRxiv, https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf.\nGelman, Andrew, 2020, ‘Concerns with that Stanford study of coronavirus prevalence’, Statistical Modeling, Causal Inference, and Social Science, 19 April, https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/.\nEisen, Michael B., and Robert Tibshirani, 2020, ‘How to Identify Flawed Research Before It Becomes Dangerous’, New York Times, 20 July, https://www.nytimes.com/2020/07/20/opinion/coronavirus-preprints.html.\nGelman, Andrew and Bob Carpenter, 2020, ‘Bayesian analysis of tests with unknown specificity and sensitivity’, 8 July, http://www.stat.columbia.edu/~gelman/research/published/specificity.pdf.\n\n\nWeek 12\n‘Lorem ipsum’.\nContent: Text-as-data.\nCase Study: Kevin Munger, Patrick Egan, Jonathan Nagler, Jonathan Ronen, and Joshua A. Tucker, 2017, ‘Political Knowledge and Misinformation in the Era of Social Media: Evidence From the 2015 UK Election’.\nLab:\nPlease form small groups and discuss, ‘to what extent do quantitative methods merely project forward the past, and what implications does this have for our conduct as practitioners and consumers?’\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nWeekly quiz\n20\nWeekly before the lecture\nProfessional conduct\n1\nAnytime during the teaching term\nPaper 1\n25\nEnd of Week 3\nPaper 2\n25\nEnd of Week 6\nPaper 3\n25\nEnd of Week 9\nFinal Paper (initial submission)\n1\nEnd of Week 12\nFinal Paper (peer review)\n3\nThree days after that\nFinal Paper\n25\nTen days after that\nWeekly quizzes\nDue date: Weekly before the lecture.\nWeight: 20 per cent (no quiz in Week 1 or Week 12 and only best eight out of ten count.)\nTask: Please complete a weekly quiz in Quercus.\nQuestions: The questions that form the quiz are drawn from those in the course notes.\nProfessional conduct\nDue date: Anytime during the teaching term.\nWeight: 1 per cent\nTask: We (optionally) use Slack to interact in this class. At some point during the teaching term, please use Slack to answer another student’s question or otherwise similarly be generally helpful in a professional manner. When you do that, please share the comment into the ‘Professional conduct’ channel and @ me (hover on the message, click share message, type in the channel ‘profession_conduct’, add a message that @‘s me, and click ’share’). You’ll get the full mark just for one helpful interaction. (If you are opting out of using Slack - which is entirely fine - then instead, at some point in the term send me an email with a link that is relevant to the course materials and that I should add to the course notes. Please be clear that this is your ‘professional conduct’ submission by stating that in the subject line.)\nPaper #1\nDue date: End of Week 3.\nWeight: 25 per cent (for Papers #1-#3 the best two of three count).\nTask: ‘Mandatory minimums’\nPaper #2\nDue date: End of Week 6.\nWeight: 25 per cent (for Papers #1-#3 the best two of three counts).\nTask: ‘These numbers mean dial it up’\nPaper #3\nDue date: End of Week 9.\nWeight: 25 per cent (for Papers #1-#3 the best two of three counts).\nTask: ‘The Short List’.\nFinal Paper\nDue dates:\nInitial submission: End of Week 12.\nPeer review: Three days after that.\nFinal Paper: Ten days after that.\n\nWeight: 29 per cent (4 per cent of this is for initial submission and peer review conducted a week before).\nInitial submission: 1 per cent\nPeer review: 3 per cent\nFinal Paper: 25 per cent\n\nTask: ‘Two Cathedrals’\n\n\n\n",
      "last_modified": "2021-10-13T20:59:26-04:00"
    },
    {
      "path": "professional.html",
      "title": "Professional",
      "author": [],
      "contents": "\nProfessional experience\n\nPetit Poll\nMay 2016 – Current\nThis is a joint project with Monica Alexander. Petit Poll combines non-representative polling data with a hierarchical Bayesian model to cheaply deliver meaningful Australian political polling. I am responsible for survey design and analysis, as well as marketing and communication.\nWe polled the 2016 Australian Federal election and got a (statistically) reasonable result. In terms of seats we were five off. Four of those were just a result of our small sample size: there were the three that turned unexpectedly in Tasmania; and the one in South Australia that went to the Nick Xenophon team. If we had more data from those areas then the model would have had a better chance, but when there’s not much data the prior has a big impact.\nGrosvenor Public Sector Advisory\nConsultant, April 2017 – February 2019\nI consulted at Grosvenor on a casual basis to complete a specific project for the European Commission relating to public procurement. This involved: identifying data sources; preparing for and supporting data acquisition; conducting data quality confirmation; helping with survey design and validation; and some minor managerial responsibilities.\nThe Centre for International Economics\nEconomist, January 2012 – August 2013; August 2015 – November 2015\nThe CIE is a privately-owned economic consultancy. I contributed to reports for public- and private-sector clients as part of a small team. Topics included: valuing public sector outputs; housing sector taxation; the global meat market; wheat price elasticities; variations to modern awards; migration; and labor markets.\nGoCampaign\nCo-founder and Director, July 2011 – May 2015\nAs a co-founder and director of GoCampaign (later GoCatalyze), a data analysis tool, I was responsible for the creation and development of a business along with Andrew Barnes, Chris Eigeland and Chris Hood. There were many aspects to this including creating marketing material and websites; making pitch decks; customer on-boarding and service; presenting; market testing; and some minor managerial responsibilities. GoCatalyze completed the ANZ Innovyz START accelerator program in 2013 and won the iAward Data Category in 2014. GoCatalyze is now part of GO1.\nReserve Bank of Australia\nCadet/Analyst/Senior Analyst, February 2009 – December 2011\nI researched topics related to banknotes, for example an econometric analysis of banknote demand during the 2007-08 financial crisis. I was also responsible for creating and analysing counterfeit banknote datasets, and gave banknote-related presentations to the public.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:27-04:00"
    },
    {
      "path": "reading_course-ethics.html",
      "title": "Reading Course: Ethics and Data Science",
      "description": "This is a reading course focused on the intersection of ethics and data science.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nAcknowledgements\n\nContent\nWeek 1 - General\nWeek 2 - Data and consent\nWeek 3 - Women and gender\nWeek 4 - Race\nWeek 5 - Natural Language Processing\nWeek 6 - AI Ethics\nWeek 7 - Privacy\nWeek 8 - Images/video with particular reference to facial recognition\nWeek 9 - Corporate Surveillance\nWeek 10 - Privacy and surveillance in Canada and other countries\nWeek 11 - Algorithmic decision-making\nWeek 12 - History of ethical concerns broadly, and domain-specific ethical practices\n\nAssessment\nFour ethical and technical blog posts (30 per cent)\nPaper 1 (30 per cent)\nPaper 2 (40 per cent)\n\n\nPreamble\nOverview\nThe purpose of this reading course is to develop students who can:\nengage in thoughtful, ethical, critique of data science, its antecedents, current state, and likely evolution; and\nwork productively to implement existing data science methods, as well as contribute to the creation of novel methods or applications.\nEach week students will read relevant papers and books, engage with them through discussion with each other and the instructor, learn related technical skills, and bring this together through on-going assessment. All students are expected to be prepared for each week’s discussion through completing the readings and technical requirements. A specific student will act as the lead for each week.\nThe course outline is available here.\nFAQ\nCan I audit this course? It’s a reading course so the concept of auditing doesn’t make sense. There are no lectures, we have weekly discussions. You’re welcome to come along to the discussions if you’d like but please do the readings first.\nAcknowledgements\nThanks to the following who helped develop this course: A Mahfouz, Assel Kushkeyeva, Irene Duah-Kessie, Ke-li Chiu, Paul Hodgetts, and Thomas Rosenthal.\nContent\nWeek 1 - General\n\nEthical\nCore:\nCantwell Smith, Brian, 2019, The Promise of AI, MIT Press, Chapters 10-12.\nHealy, Kieran, 2020, ‘The Kitchen Counter Observatory’, 21 May, https://kieranhealy.org/blog/archives/2020/05/21/the-kitchen-counter-observatory/.\nKeyes, Os, 2019, ‘Counting the Countless’, Real Life, 8 April, https://reallifemag.com/counting-the-countless/.\nO’Neil, Cathy, 2016, Weapons of Math Destruction, Crown Books, Chapters 1, 3, and 4.\nAdditional (pick two):\nGreen, Ben, 2018, ‘Data Science as Political Action: Grounding Data Science in a Politics of Justice’, arXiv, 1811.03435, https://arxiv.org/abs/1811.03435.\nIrving, Geoffrey, and Amanda Askell, 2019, ‘AI Safety Needs Social Scientists’, Distill, 19 February, https://distill.pub/2019/safety-needs-social-scientists/.\nLeslie, David, 2020, ‘Tackling COVID-19 through Responsible AI Innovation: Five Steps in the Right Direction’, Harvard Data Science Review, 5 June, https://hdsr.mitpress.mit.edu/pub/as1p81um.\nSuresh, Harini, and John V. Guttag, 2019, ‘A Framework for Understanding Unintended Consequences of Machine Learning’, arXiv, 1901.10002, https://arxiv.org/abs/1901.10002.\nRaji, Inioluwa Deborah, 2020, ‘The Discomfort of Death Counts: Mourning through the Distorted Lens of Reported COVID-19 Death Data’, Patterns, https://doi.org/10.1016/j.patter.2020.100066\nTechnical\nReview ‘Essentials’ from Telling Stories With Data, if necessary.\nWeek 2 - Data and consent\n\nEthical\nCore:\nBoykis, Vicki, 2019, ‘Neural nets are just people all the way down’, 16 October, https://vicki.substack.com/p/neural-nets-are-just-people-all-the.\nCrawford, Kate, and Vladan Joler, 2018, ‘Anatomy of an AI System: The Amazon Echo As An Anatomical Map of Human Labor, Data and Planetary Resources’, AI Now Institute and Share Lab, 7 September, https://anatomyof.ai.\nCrawford, Kate, 2020, ‘Kate Crawford: Anatomy of AI’, Lecture, University of New South Wales, 28 January, https://youtu.be/uM7gqPnmDDc.\nKitchin, Rob, 2014, The data revolution: Big data, open data, data infrastructures and their consequences, Sage, Introduction, Chapters 8, and 10. (Access via U of T library).\nAdditional (pick two):\nBergis Jules, Ed Summers and Vernon Mitchell, 2018, ‘Documenting The Now: Ethical Considerations for Archiving Social Media Content Generated by Contemporary Social Movements: Challenges, Opportunities, and Recommendations’, White Paper, DocNow, https://www.docnow.io/docs/docnow-whitepaper-2018.pdf.\nBoyd, Danah, and Kate Crawford, 2012, ‘Critical Questions for Big Data’, Information, Communication & Society, 15(55), 662-679, https://www.microsoft.com/en-us/research/wp-content/uploads/2012/05/CriticalQuestionsForBigDataICS.pdf.\nDenton, Emily, Alex Hanna, Razvan Amironesei, Andrew Smart, Hilary Nicole, Morgan Klaus Scheuerman, 2020, ‘Bringing the People Back In: Contesting Benchmark Machine Learning Datasets’, arXiv, 14 July, https://arxiv.org/abs/2007.07399.\nEubanks, Virginia, 2019, ‘Automating Inequality: How high-tech tools profile, police and punish the poor’, Lecture, University of Toronto, 12 March, https://www.youtube.com/watch?v=g1ZZZ1QLXOI.\nLemov, Rebecca, 2016, ‘Big data is people!’, Aeon, 16 June, https://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human.\nOffice of Oversight and Investigations Majority Staff, 2013, ‘A Review of the Data Broker Industry: Collection, Use, and Sale of Consumer Data for Marketing Purposes’, Staff Report for Chairman Rockefeller, 18 December, United States Senate, Committee on Commerce, Science and Transportation, https://www.commerce.senate.gov/services/files/0d2b3642-6221-4888-a631-08f2f255b577.\nRadin, Joanna, 2017, ‘“Digital Natives”: How Medical and Indigenous Histories Matter for Big Data’, Osiris, 32 (1), 43-64, https://www.journals.uchicago.edu/doi/pdf/10.1086/693853.\nSnowberg, Erik and Leeat Yariv, 2018, ‘Testing The Waters: Behavior Across Participant Pools’, NBER Working Paper, No. 24781, http://www.nber.org/papers/w24781.\nTechnical\nReview ‘Hunt, gather and farm’ from Telling Stories With Data, if necessary.\nWeek 3 - Women and gender\nEthical\nCore:\nD’Ignazio, Catherine, and Lauren F. Klein, 2020, Data Feminism, MIT Press.\nGebru, Timnit, 2020, ‘Race and Gender’, The Oxford Handbook of Ethics of AI, Chapter 13, Oxford University Press.\nAdditional (pick two):\nBorgerson, Janet L., 2007, ‘On the Harmony of Feminist Ethics and Business Ethics’, Business and Society Review, 112 (4):477-509.\nD’Ignazio, Catherine, and Lauren F. Klein, ‘Feminist data visualization’, Workshop on Visualization for the Digital Humanities (VIS4DH), Baltimore. IEEE. 2016.\nHill, Kashmir, 2017, ‘What Happens When You Tell the Internet You’re Pregnant’, Jezebel, 27 July, https://jezebel.com/what-happens-when-you-tell-the-internet-youre-pregnant-1794398989.\nKeyes, Os, 2018, ‘The misgendering machines: Trans/HCI implications of automatic gender recognition’, Proceedings of the ACM on Human-Computer Interaction, 2(CSCW), 1-22, https://dl.acm.org/doi/pdf/10.1145/3274357.\nQuintin, Cooper, 2017, ‘Pregnancy Panopticon’, DEFCON 25, https://www.eff.org/files/2017/07/27/the_pregnancy_panopticon.pdf.\nWoods, Heather Suzanne, 2018, ‘Asking more of Siri and Alexa: feminine persona in service of surveillance capitalism’, Critical Studies in Media Communication, 35.4, pp. 334-349.\nTechnical\nReview the essentials of Bayesian models by going through McElreath, 2020, Statistical Rethinking, 2nd Edition, (at least chapters 1, 2, 4, 7, 9, 11, 12, and 13) to address any shortcomings.\nWeek 4 - Race\nTom Davidson, Assistant Professor, Sociology, Rutgers University: https://youtu.be/YDmxMn2Doq0.\nEthical\nCore:\nDavidson, Thomas, Debasmita Bhattacharya, and Ingmar Weber, 2019, ‘Racial bias in hate speech and abusive language detection datasets’, arXiv, https://arxiv.org/abs/1905.12516.\nNoble, Safiya Umoja, 2018, Algorithms of Oppression: How Search Engines Reinforce Racism, NYU Press, Chapter 2.\nAdditional (pick two):\nBuolamwini, Joy and Timnit Gebru, 2018, ‘Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification’, Proceedings of Machine Learning Research Conference on Fairness, Accountability, and Transparency, 81: pp. 1–15, http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf\nKwet, Michael, 2019, ‘Digital colonialism: US empire and the new imperialism in the Global South’, Race & Class 60.4, 3-26.\nScheuerman, M. K., Wade, K., Lustig, C., and Brubaker, J. R., 2020, ‘How We’ve Taught Algorithms to See Identity: Constructing Race and Gender in Image Databases for Facial Analysis’, Proceedings of the ACM on Human-Computer Interaction, 4(CSCW1), 1-35.\nZiad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan, 2019, ‘Dissecting racial bias in an algorithm used to manage the health of populations’, Science, Vol. 366, Issue 6464, pp. 447-453, DOI: 10.1126/science.aax2342, https://science.sciencemag.org/content/366/6464/447/tab-pdf\nTechnical\nPick a project from The Markup’s Show Your Work section (https://themarkup.org/series/show-your-work) and reproduce it, writing your own code. You may pick whatever language you are comfortable in.\nWeek 5 - Natural Language Processing\n\nEthical\nCore:\nBender, Emily M., Angelina McMillan-Major, Timnit Gebru and Shmargaret Shmitchell, 2021, ‘On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?’, https://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf\nHovy, Dirk and Shannon L. Spruit, 2016, ‘The Social Impact of Natural Language Processing’, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 591–598, https://aclweb.org/anthology/P16-2096.pdf.\nPrabhumoye, Shrimai, Elijah Mayfield, and Alan W Black, 2019, ‘Principled Frameworks for Evaluating Ethics in NLP Systems’, Proceedings of the 2019 Workshop on Widening NLP, https://aclweb.org/anthology/W19-3637/.\nAdditional (pick two):\nBolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama and Adam T. Kalai, 2016, ‘Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings’, Advances in Neural Information Processing Systems 29 (NIPS 2016), http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-d.\nChang, Kai-Wei, Vinod Prabhakaran, and Vicente Ordonez, 2019, ‘Bias and Fairness in Natural Language Processing’, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts, https://aclweb.org/anthology/D19-2004/.\nHutchinson, Ben, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster, Yu Zhong, and Stephen Denuyl, 2020, ‘Social Biases in NLP Models as Barriers for Persons with Disabilities’, arXiv, https://arxiv.org/abs/2005.00813.\nSolaiman, Irene, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine Wang, 2019, ‘Release Strategies and the Social Impacts of Language Models’, arXiv, https://arxiv.org/abs/1908.09203.\nTatman, Rachel, 2020, ‘What I Won’t Build’, Widening NLP Workshop 2020, Keynote address, 5 July, https://slideslive.com/38929585/what-i-wont-build and http://www.rctatman.com/talks/what-i-wont-build.\nZhao, Jieyu, Tianlu Wang, Mark Yatskar, Vicente Ordonez and Kai-Wei Chang, 2017, ‘Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints’, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2979–2989, https://aclweb.org/anthology/D17-1323.pdf.\n(Optional/fun/horrifying) Hao, Karen, 2020, ‘The messy, secretive reality behind OpenAI’s bid to save the world’, MIT Review, 17 February, https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/.\nTechnical\nImplement a NLP model via Hugging Face or Spacy, depending on your language preference.\nWeek 6 - AI Ethics\nShion Guha, Assistant Professor, University of Toronto, will join the discussion briefly this week.\nEthical\nCore:\nBrundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn, Seán Ó hÉigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei, 2019, ‘The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation’, arXiv, https://arxiv.org/abs/1802.07228.\nJobin, A., Ienca, M., and Vayena, E, 2019, ‘The global landscape of AI ethics guidelines’, Nature Machine Intelligence, 1(9), pp. 389-399. https://www.nature.com/articles/s42256-019-0088-2.\nAdditional (pick two):\nAustralian Human Rights Commission, 2019, ‘Human Rights and Technology Discussion Paper’, December, https://tech.humanrights.gov.au/sites/default/files/2019-12/TechRights_2019_DiscussionPaper.pdf.\nCrawford, Kate, Amba Kak and Jason Schultz, 2020, ‘Submission to the Australian Human Rights Commission Human Rights & Technology Discussion Paper’, AI Now Institute, New York University, 13 March.\nKaplan, Andreas, Michael Haenlein, 2019, ‘Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence’, Business Horizons, Volume 62, Issue 1, pp. 15-25.\nLeslie, David, 2019, ‘Understanding Artificial Intelligence Ethics and Safety: A guide for the responsible design and implementation of AI systems in the public sector’, Alan Turing Institute.\nLuciano, Floridi, and Cowls Josh, 2019, ‘A Unified Framework of Five Principles for AI in Society’, Harvard Data Science Review, 1 July, https://hdsr.mitpress.mit.edu/pub/l0jsh9d1.\nPaglioni, Vincent, 2015, ‘The Ethics of Intelligent Machines’, Investment Management Consultants Association, https://investmentsandwealth.org/getattachment/f3614756-1e1d-49c7-a201-29dbc22d8fbf/IWM15NovDec-EthicsIntelligentMachines.pdf\nWinfield, Alan F., Katina Michael, Jeremy Pitt, Vanessa Evers, 2019, ‘Machine Ethics: the Design and Governance of Ethical AI and Autonomous Systems’, Proceeding of IEEE, Volume 107, Issue 3, pp. 509-517.\nSam Corbett-Davies and Sharad Goel, 2018, ‘The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning’, 14 August, https://arxiv.org/pdf/1808.00023.pdf.\nInareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, And Aram Galstyan, 2019, ‘A Survey on Bias and Fairness in Machine Learning’, https://arxiv.org/pdf/1908.09635.pdf.\nIrene Y. Chen, Fredrik D. Johansson, David Sontag, 2018, ‘Why Is My Classifier Discriminatory?’, https://arxiv.org/pdf/1805.12002.pdf.\nTechnical\nUse RASA (https://rasa.com/) to build a chatbot, or OpenAI’s GPT-2 or GPT-3 to generate text.\nWeek 7 - Privacy\nJonathan A. Obar, Assistant Professor, Department of Communication Studies, York University, will be invited to join the discussion briefly this week.\nEthical\nCore:\nHyunghoon Cho, Daphne Ippolito, Yun William Yu, 2020, ‘Contact Tracing Mobile Apps for COVID-19: Privacy Considerations and Related Trade-offs’, arXiv, https://arxiv.org/abs/2003.11511.\nObar, Jonathan A. and Oeldorf-Hirsch, Anne, 2018, ‘The Biggest Lie on the Internet: Ignoring the Privacy Policies and Terms of Service Policies of Social Networking Services’ TPRC 44: The 44th Research Conference on Communication, Information and Internet Policy, http://dx.doi.org/10.2139/ssrn.2757465.\nAdditional (pick two):\nBlumberg, Andrew J. and Peter Eskersley, 2009, ‘On Locational Privacy, and How to Avoid Losing it Forever’, https://www.eff.org/wp/locational-privacy.\nde Montjoye, Yves-Alexandre, César A. Hidalgo, Michel Verleysen, and Vincent D. Blondel, 2013, ‘Unique in the Crowd: The privacy bounds of human mobility’, Scientific Reports, vol 3, https://doi.org/10.1038/srep01376.\nObar, Jonathan A., and Anne Oeldorf-Hirsch, 2018, ‘The clickwrap: A political economic mechanism for manufacturing consent on social media’, Social Media+ Society, 4.3, 2056305118784770\nSolove, Daniel J, 2007, ‘“I’ve Got Nothing to Hide” and Other Misunderstandings of Privacy’, San Diego Law Review, Vol. 44, p. 745-772.\nZimmeck, Sebastian, Story, Peter, Smullen, Daniel, Ravichander, Abhilasha, Wang, Ziqi, Reidenberg, Joel, Cameron Russell, N., & Sadeh, Norman, 2019, ‘MAPS: Scaling Privacy Compliance Analysis to a Million Apps’, Proceedings on Privacy Enhancing Technologies, Volume 3, pp. 66-86.\nZimmer, Michael, Priya Kumar, Jessica Vitak, Yuting Liao and Katie Chamberlain Kritikos, 2018, “‘There’s nothing really they can do with this information’: unpacking how users manage privacy boundaries for personal fitness information”, Information, Communication & Society, Vol 23, Issue 7, pp. 1020-1037.\nTechnical\nFind or generate a dataset, then implement differential privacy on it. Examine and discuss the results.\nOberski, Daniel, and Frauke Kreuter, 2020, ‘Differential Privacy and Social Science: An Urgent Puzzle’, Harvard Data Science Review, https://doi.org/10.1162/99608f92.63a22079.\nRubinstein, Benjamin I. P. and Francesco Alda, 2017, ‘diffpriv: An R Package for Easy Differential Privacy’, Journal of Machine Learning Research, 18, pp. 1-5.\nWeek 8 - Images/video with particular reference to facial recognition\nJeffrey Knockel, Research Associate, Citizen Lab, University of Toronto, will be invited to join the discussion briefly this week.\nEthical\nCore:\nBuolamwini, Joy, Vicente Ordóñez, Jamie Morgenstern, and Learned-Miller, Erik, 2020, ‘Facial recognition technologies: A primer’, Algorithmic Justice League, 29 May.\nInioluwa Deborah Raji, Timnit Gebru, Margaret Mitchell, Joy Buolamwini, Joonseok Lee, and Emily Denton, 2020, ‘Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing’, In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES ’20). Association for Computing Machinery, New York, NY, USA, 145–151. DOI:https://doi.org/10.1145/3375627.3375820.\nAdditional (pick two):\nHill, Kashmir, 2020, ‘Wrongfully Accused by an Algorithm’, New York Times, 24 June, https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html.\nHill, Kashmir, 2020, ‘The Secretive Company That Might End Privacy as We Know It’, New York Times, 18 January, https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html.\nKnockel, Jeffrey, and Ruohan Xiong, 2019, ‘(Can’t) Picture This 2: An Analysis of WeChat’s Realtime Image Filtering in Chats’, Citizen Lab, 15 July, https://citizenlab.ca/2019/07/cant-picture-this-2-an-analysis-of-wechats-realtime-image-filtering-in-chats/.\nLearned-Miller, Erik, Vicente Ordóñez, Jamie Morgenstern, and Joy Buolamwini, 2020, ‘Facial recognition technologies in the wild: A call for a federal office’, Algorithmic Justice League, 29 May,\nTechnical\nChollet, Francois, and J. J. Allaire, 2018, Deep Learning with R, Chapter 5 ‘Deep learning for computer vision’.\nWeek 9 - Corporate Surveillance\nEthical\nCore:\nZuboff, Shoshana, 2019, The Age of Surveillance Capitalism, and watch related interview: https://www.youtube.com/watch?v=hIXhnWUmMvw\nZuboff, Shoshana, 2019, ‘Written Testimony Submitted to The International Grand Committee on Big Data, Privacy, and Democracy’, 28 May, Ottawa, https://www.ourcommons.ca/Content/Committee/421/ETHI/Brief/BR10573725/br-external/ZuboffShoshana-e.pdf and watch related video https://youtu.be/6N2kJNwGgUg?t=4869.\nAdditional (pick two):\nBennett Cyphers and Gennie Gebhart, “Behind One-Way Mirror: A Deep Dive Into the Technology of Corporate Surveillance”, https://www.eff.org/files/2019/12/11/behind_the_one-way_mirror-a_deep_dive_into_the_technology_of_corporate_surveillance.pdf\nMarczak, Bill and John Scott-Railton, 2020, ‘Move Fast and Roll Your Own Crypto: A Quick Look at the Confidentiality of Zoom Meetings’, Citizen Lab, 3 April, https://citizenlab.ca/2020/04/move-fast-roll-your-own-crypto-a-quick-look-at-the-confidentiality-of-zoom-meetings/.\nParsons, Christopher, Andrew Hilts, and Masashi Crete-Nishihata, 2017, ‘Approaching Access: A comparative analysis of company responses to data access requests in Canada’, Citizen Lab, Research Brief No. 106. Available at: https://citizenlab.ca/wp-content/uploads/2018/02/approaching_access.pdf.\n(Optional/fun) Duhigg, Charles, 2012, ‘How Companies Learn Your Secrets’, New York Times, 19 February, https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\nTechnical\nCreate a datasheet or model card for an open source dataset or model.\nGebru, Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford, 2018, ‘Datasheets for Datasets’, arXiv, https://arxiv.org/abs/1803.09010\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji and Timnit Gebru, 2019, ‘Model Cards for Model Reporting’, FAT ’19: Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 220–229 https://doi.org/10.1145/3287560.3287596.\nWeek 10 - Privacy and surveillance in Canada and other countries\nLisa Austin, Professor, Law, University of Toronto, will be invited to join the discussion briefly this week.\nEthical\nCore:\nKhoo, Cynthia, Kate Robertson, and Ronald Deibert, 2019, ‘Installing Fear: A Canadian Legal and Policy Analysis of Using, Developing, and Selling Smartphone Spyware and Stalkerware Applications,’ Citizen Lab, Research Report No. 120, University of Toronto, June, https://tspace.library.utoronto.ca/bitstream/1807/96321/1/stalkerware-legal.pdf.\nObar, Jonathan A., 2017, ‘Keeping Internet Users in the Know or in the Dark? The Data Privacy Transparency of Canadian Internet Carriers: A Third Report’, IXMaps, https://ixmaps.ca/docs/DataPrivacyTransparencyCanadianCarriers-2017.pdf\nRuan, Lotus, Crete-Nishihata, Masashi, Knockel, Jeffrey, Xiong, Ruohan and Dalek, Jakub, 2020, ‘The Intermingling of State and Private Companies: Analysing Censorship of the 19th National Communist Party Congress on WeChat,’ The China Quarterly, pp. 1–30. doi: 10.1017/S0305741020000491.\nAdditional (pick two):\nAustin, Lisa, and David Lie, 2019, ‘Safe Sharing Sites’, New York University Law Review, Vol. 94, No. 4, pp. 581 - 623.\nKnockel, Jeffrey, Christopher Parsons, Lotus Ruan, Ruohan Xiong, Jedidiah Crandall, and Ron Deibert, 2020, ‘We Chat, They Watch: How International Users Unwittingly Build up WeChat’s Chinese Censorship Apparatus,’ Citizen Lab, Research Report No. 127, University of Toronto, May, https://tspace.library.utoronto.ca/bitstream/1807/101395/1/Report%23127--wechattheywatch-web.pdf.\nObar, Jonathan A., and Brenda McPhail, 2018, ‘Preventing Big Data Discrimination in Canada: Addressing design, consent and sovereignty challenges’, Centre for International Governance Innovation (CIGI), https://www.cigionline.org/articles/preventing-big-data-discrimination-canada-addressing-design-consent-and-sovereignty.\nParsons, Christopher, Adam Molnar, Jakub Dalek, Jeffrey Knockel, Miles Kenyon, Bennett Haselton, Cynthia Khoo, and Ron Deibert, 2019, ‘The Predator in Your Pocket: A Multidisciplinary Assessment of the Stalkerware Application Industry,’ Citizen Lab, Research Report, No. 119, University of Toronto, June, https://tspace.library.utoronto.ca/bitstream/1807/96320/1/stalkerware-holistic.pdf.\nScott, James C., 1998, Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed.\nVarious, ‘GDPR Checklist’, https://gdpr.eu/checklist/.\nVarious, ‘Summary of privacy laws in Canada’, Office of the Privacy Commissioner, https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/02_05_d_15/.\nTechnical\nTBD based on student interest.\nWeek 11 - Algorithmic decision-making\nJamie Duncan, Junior Policy Analyst, Artificial Intelligence Hub, Innovation, Science and Economic Development Canada, will be invited to join the discussion briefly this week.\nEthical\nCore:\nSpiegelhalter, David, 2020, ‘Should We Trust Algorithms?’, Harvard Data Science Review, 31 January, https://doi.org/10.1162/99608f92.cb91a35a.\nMolnar, Petra and Lex Gill, 2018, ‘Bots at the Gate: A Human Rights Analysis of Automated Decision-Making in Canada’s Immigration and Refugee System,’ Citizen Lab and International Human Rights Program, Faculty of Law, University of Toronto, Research Report No. 114, University of Toronto, September, https://citizenlab.ca/wp-content/uploads/2018/09/IHRP-Automated-Systems-Report-Web-V2.pdf.\nAdditional (pick two):\nDe-Arteaga, Maria, Riccardo Fogliato, and Alexandra Chouldechova, ‘A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores’. https://arxiv.org/abs/2002.08035.\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum, 2018, ‘Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions’, arXiv, 1811.07867. https://arxiv.org/abs/1811.07867.\nRudin, Cynthia, Caroline Wang, and Beau Coker, ‘The Age of Secrecy and Unfairness in Recidivism Prediction’, Harvard Data Science Review, https://hdsr.mitpress.mit.edu/pub/7z10o269.\nSuresh, Harini, Natalie Lao, and Ilaria Liccardi, ‘Misplaced Trust: Measuring the Interference of Machine Learning in Human Decision-Making’, https://arxiv.org/pdf/2005.10960.pdf\nThe Joint Council for the Welfare of Immigrants v Secretary of State for the Home Department, 2020, ‘Grounds of Challenge’ and ‘Response’, available: https://www.foxglove.org.uk/news/c6tv7i7om2jze5pxs409k3oo3dyel0 and background here: https://www.theguardian.com/uk-news/2020/aug/04/home-office-to-scrap-racist-algorithm-for-uk-visa-applicants.\nTechnical\nMcElreath says that researchers use point estimates to describe posterior distributions, not to support particular decisions. But this isn’t always viable. Using a post from the Stan Case Study (https://mc-stan.org/users/documentation/case-studies.html) as a guide, please develop a Bayesian hierarchical model in Stan. Please post-process your model to support/recommend a decision, and justify your choices.\nWeek 12 - History of ethical concerns broadly, and domain-specific ethical practices\nEthical (Please pick two areas.)\nMedicine:\nParker, Michael, J A Muir Gray, 2001, ‘What is the role of clinical ethics support in the era of e-medicine?’, Journal of Medical Ethics, 27 suppl I:i33–i35 https://jme.bmj.com/content/medethics/27/suppl_1/i33.full.pdf\nChancellor, S., Baumer, E. P., & De Choudhury, M. (2019). Who is the\" Human\" in Human-Centered Machine Learning: The Case of Predicting Mental Health from Social Media. Proceedings of the ACM on Human-Computer Interaction, 3(CSCW), 1-32. https://doi.org/10.1145/3359249\nVayena, Effy, and Alessandro Blasimme, 2020, ‘The Ethics of AI in Biomedical Research, Medicine and Public Health’, The Oxford Handbook of Ethics of AI, Chapter 37, Oxford University Press.\nEngineering:\nDavis, Michael, 1991, ‘Thinking Like an Engineer: The Place of a Code of Ethics in the Practice of a Profession’, https://www.jstor.org/stable/pdf/2265293.pdf?refreqid=excelsior%3A94aaba1458bc97cf0563cf7d16861188\nMichaelson, Christopher, 2014, ‘The Competition for the Tallest Skyscraper: Implications for Global Ethics and Economics’, CTBUH Journal, Issue IV, https://www.jstor.org/stable/pdf/24192831.pdf?ab_segments=0%252Fbasic_SYC-5187%252Ftest&refreqid=excelsior%3A9bf439c8785e93d009d8e42608e6b425\nMillar, Jason, 2020, ‘Engineering’, The Oxford Handbook of Ethics of AI, Chapter 23, Oxford University Press.\nStatistics:\nWells, Martin, 2020, ‘Statistics’, The Oxford Handbook of Ethics of AI, Chapter 26, Oxford University Press.\nLaw:\nAngwin, Julia, Jeff Larson, Surya Mattu and Lauren Kirchner, 2016, ‘Machine Bias’, ProPublica, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\nEubanks, Virginia, 2014, ‘How Big Data Could Undo Our Civil-Rights Law’, https://prospect.org/justice/big-data-undo-civil-rights-laws/\nSurden, Harry, 2020, ‘Law: Basic Questions’, The Oxford Handbook of Ethics of AI, Chapter 38, Oxford University Press.\nFinances:\nGeslevich Packin, Nizan, Yafit Lev Aretz, 2015, ‘Big Data and Social Netbanks: Are You Ready to Replace Your Bank?’, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2567135\nEducation:\nMayfield, E., Madaio, M., Prabhumoye, S., Gerritsen, D., McLaughlin, B., Dixon-Román, E., & Black, A. W. (2019, August). Equity beyond bias in language technologies for education. In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications (pp. 444-460). https://doi.org/10.1177/2053951720913064\nRubel, A., & Jones, K. M. (2016). Student privacy in learning analytics: An information ethics perspective. The information society, 32(2), 143-159. https://doi.org/10.1080/01972243.2016.1130502\nZeide, Elana, 2020, ‘Education’, The Oxford Handbook of Ethics of AI, Chapter 42, Oxford University Press.\nGeneral non-computational:\nSelbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., & Vertesi, J. (2019, January). Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59-68). https://dl.acm.org/doi/pdf/10.1145/3287560.3287598\nEarlier calls for ethics in computing\nAgre, Philip E., 1997, ‘Towards a critical technical practice: Lessons learned from trying to reform AI’, Social science, technical systems, and cooperative work: Beyond the great divide, Ed. by Geoffrey C. Bowker, Susan Leigh Star, Will Turner, and Les Gasser. Mahwah, NJ: Lawrence Erlbaum Associates, pp. 131–158. URL: https://web.archive.org/web/20040203070641/http://polaris.gseis.ucla.edu/pagre/critical.html.\nFriedman, Batya, and Helen Nissenbaum, 1996, ‘Bias in computer systems’, ACM Trans. Inf. Syst, 14, 3 (July 1996), 330–347. DOI: https://doi.org/10.1145/230538.230561.\nTechnical\nTBD based on student interest.\nAssessment\nFour ethical and technical blog posts (30 per cent)\nOver the course of the term, you are expected to submit four blog posts that each comprise two aspects: 1) ethical and 2) technical. These two aspects should be related to each other. You must submit all four, but only your best three blog posts will count, that is each blog post will account for 10 per cent of your overall mark.\nFor the first aspect (ethical), you are expected to write a moderate length discussion (think a paper of about two to three pages), of a reading, or set of readings, that we have covered over the past two weeks. Strong submissions will not limit themselves to reviewing a reading but will draw in larger issues and detail their own point of view.\nFor the second aspect (technical), you are expected to implement some small related technical aspect of what we have covered in the past two weeks. For instance, if we covered natural language processing then you may critically review a paper, and put together a chat bot.\nTo be clear, these two aspects should be related, tied together, and should be in the one blog post.\nYou should submit your blog post by emailing me a link to the relevant blog post on your website.\nThe proposed specific list of deadlines is:\nBlog post 1: midnight, Sunday 24 January, 2021.\nBlog post 2: midnight, Sunday 7 February, 2021.\nBlog post 3: midnight, Sunday 7 March, 2021.\nBlog post 4: midnight, Sunday 21 March, 2021.\nIn Week 1 we will discuss how these dates fit in with your other commitments and finalise them at that point.\nThe instructor will make the marking guide available at least a week before the submission deadline.\nPaper 1 (30 per cent)\nTask\nPlease gather and clean data on UofT salaries from the Sunshine List. Then conduct a Bayesian statistical analysis of your dataset to discuss the extent to which gender has an effect on salary. Finally please prepare a paper of around 10 pages that discusses your analysis. (Hint: gender is not explicitly part of the Sunshine List, you will need to grapple with what to do.)\nBackground\nYou should make appropriate use of appendices for additional and supporting material, and thoroughly reference your paper, but neither the appendices nor the reference list count toward your page limit. Your paper should have an appropriate title, author, date, abstract, and introduction. It should document and overview your dataset. It should clearly specify your model, and then discuss the results of your analysis and any weaknesses. Your analysis should be fully reproducible, with code and data hosted on a public GitHub repo. Additionally, you should include a thorough discussion of ethical considerations relevant to your analysis. This would likely take at least three pages, but you are welcome to write as much as is needed to make the points you would like to make. Likely the best way to do this is to include a brief overview of the ethical points that you would like to discuss, and then include the rest of the discussion in an appendix. I understand that Bayesian analysis may be new to you. I will assist you with putting together the model, but it is up to you to understand and interpret the output.\nSubmission\nTo submit your paper you should email me a link to a public GitHub repo. That repo should contain your paper in PDF format and all supporting code and data. Please send this email by midnight, Sunday, 14 February, 2021. Please do not make any changes to the repo after this. I will make the marking guide available at least a week before the submission deadline.\nPaper 2 (40 per cent)\nTask\nIn consultation with me, please identify an appropriate research question and data source that, like the requirement for Paper 1, combines both ethical and technical aspects. Please prepare a paper that represents your best attempt to answer this question and shows off your ability to engage in thoughtful, ethical, critique. The paper should be as long as necessary, although all extraneous material should be included in appendices. The expectation is that this paper should make an original contribution, that could be published in an academic journal.\nBackground\nPlease see the background provided for Paper 1, as this applies for Paper 2 as well.\nSubmission\nYou must send the email with the GitHub link to me by midnight, Sunday, 23 April, 2020. Please do not make any changes to the repo after this. I will make the marking guide available at least a week before the submission deadline. No extensions are possible because of deadlines for instructors to submit grades.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:27-04:00"
    },
    {
      "path": "reading_course-nlp.html",
      "title": "Reading Course: 'Natural Language Processing'",
      "author": [],
      "contents": "\n\nContents\nOverview\nContent\nAssessment\n\nOverview\nThe purpose of this reading course is to develop students who can:\nengage in thoughtful, ethical, critique of Natural Language Processing (NLP);\nwork productively to implement existing NLP methods; and\nuse NLP to contribute to our understanding of the world.\nStudents are expected to develop:\nan understanding of NLP and its place in the world;\nexceptional written and verbal communication skills; and\ncontribute in some small way to our understanding of something related to NLP.\nContent\nWeek 1: Essentials I\nSilge, Julia & David Robinson, 2020, Text Mining with R, Chapters 1-4: https://www.tidytextmining.com.\nHovy, Dirk and Shannon L. Spruit, 2016, ‘The Social Impact of Natural Language Processing’, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 591–598,https://aclweb.org/anthology/P16-2096.pdf.\nPrabhumoye, Shrimai, Elijah Mayfield, and Alan W Black, 2019, ‘Principled Frameworks for Evaluating Ethics in NLP Systems’, Proceedings of the 2019 Workshop on Widening NLP, https://aclweb.org/anthology/W19-3637/.\n\nWeek 2: Essentials II\nSilge, Julia & David Robinson, 2020, Text Mining with R, Chapters 5-7: https://www.tidytextmining.com.\nBolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama and Adam T. Kalai, 2016, ‘Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings’, Advances in Neural Information Processing Systems, 29 (NIPS 2016), http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-d.\nChang, Kai-Wei, Vinod Prabhakaran, and Vicente Ordonez, 2019, ‘Bias and Fairness in Natural Language Processing’, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts, https://aclweb.org/anthology/D19-2004/.\n\nWeek 3: Essentials III\nSilge, Julia & David Robinson, 2020, Text Mining with R, Chapters 8-9: https://www.tidytextmining.com.\nHutchinson, Ben, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster, Yu Zhong, and Stephen Denuyl, 2020, ‘Social Biases in NLP Models as Barriers forPersons with Disabilities’, arXiv, https://arxiv.org/abs/2005.00813.\n\nWeek 4: NLP intermediate I\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine Learning for Text Analysis in R, Chapters 1-3, https://smltar.com.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language Processing, 3rd ed., Chapter 3, https://web.stanford.edu/~jurafsky/slp3/.\nSolaiman, Irene, Miles Brundage, Jack Clark, Amanda Askell, ArielHerbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, SarahKreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine Wang, 2019, ‘Release Strategies and the Social Impacts of Language Models’,arXiv, https://arxiv.org/abs/1908.09203.\n\nWeek 5: NLP intermediate II\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine Learning for Text Analysis in R, Chapters 4-6, https://smltar.com.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language Processing, 3rd ed., Chapters 4 and 5, https://web.stanford.edu/~jurafsky/slp3/.\nTatman, Rachel, 2020, ‘What I Won’t Build’, Widening NLP Workshop 2020, Keynote address, 5 July, https://slideslive.com/38929585/what-i-wont-build and http://www.rctatman.com/talks/what-i-wont-build.\n\nWeek 6: NLP intermediate III\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine Learning for Text Analysis in R, Chapters 7-9, https://smltar.com.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language Processing, 3rd ed., Chapters 6 and 7, https://web.stanford.edu/~jurafsky/slp3/.\nZhao, Jieyu, Tianlu Wang, Mark Yatskar, Vicente Ordonez and Kai-Wei Chang,2017, ‘Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints’, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2979–2989, https://aclweb.org/anthology/D17-1323.pdf.\n\nWeek 7: Deep learning I\nFrançois Chollet with J. J. Allaire, 2018, Deep Learning with R, Chapters 1-4.\n\nWeek 8: Deep learning II\nFrançois Chollet with J. J. Allaire, 2018, Deep Learning with R, Chapters 6.\nBender, Emily M. and Koller, Alexander, 2020, ‘Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data’, *Proceedings of the 58th Annual Meeting of the\n\nWeek 9: Deep learning III\nAnna Rogers, Isabelle Augenstein, 2020, ‘What Can We Do to Improve Peer Review in NLP?’, arXiv, 8 October, https://arxiv.org/abs/2010.03863.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language Processing, 3rd ed., Chapters 8 and 9, https://web.stanford.edu/~jurafsky/slp3/. Association for Computational Linguistics*, pp. 5185–5198, https://www.aclweb.org/anthology/2020.acl-main.463\n\nWeek 10: Transformers I\nAlammar, Jay, 2018, ‘The Illustrated Transformer’, http://jalammar.github.io/illustrated-transformer/.\nManning, Vaswani and Huang, 2019, ‘Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 – Transformers and Self-Attention’, https://www.youtube.com/watch?v=5vcj8kSwBCY&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=14&ab_channel=stanfordonline.\nUszkoreit, Jakob, 2017, ‘Transformer: A Novel Neural Network Architecture for Language Understanding’, Google AI Blog, 31 August, https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\nWeek 11: Transformers II\nAlammar, Jay, 2020, ‘How GPT3 Works - Visualizations and Animations’, 27 July, https://jalammar.github.io/how-gpt3-works-visualizations-animations/\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin, 2017, ‘Attention Is All You Need’, arXiv, http://arxiv.org/abs/1706.03762.\nJacob Devlin and Ming-Wei Chang, 2018, ‘Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing’, 2 November, Google AI Blog, https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 2018, ‘BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding’, arXiv, https://arxiv.org/abs/1810.04805.\nRush, Alexander, 2018, ‘The Annotated Transformer’, https://nlp.seas.harvard.edu/2018/04/03/attention.html\n\nWeek 12: Transformers III\nTom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei, 2020, ‘Language Models are Few-Shot Learners’, arXiv, https://arxiv.org/abs/2005.14165\n(Fun/horrifying) Hao, Karen, 2020, ‘The messy, secretive reality behind OpenAI’s bid to save the world’, MIT Review, 17 February, https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/.\n\nAssessment\nLearning Diary (15 per cent)\nDate: Each week you will read relevant papers and books, engaging with them by writing notes and completing exercises. You will use GitHub to manage these notes and exercises and email a link to me at the end of each week.\n\nPresentation I (15 per cent)\nDate: Roughly end of Week 4 (exact date determined by lab presentation cycle - it’ll be the end of a month and you’ll have at least a month’s notice).\nRequirement: 10-15-minute presentation on what you’ve learned from Silge & Robinson.\n\nPresentation II (15 per cent)\nDate: Roughly end of Week 8, as above.\nRequirement: 10-15-minute presentation on an aspect of ethics, society, and NLP.\n\nPresentation III (15 per cent)\nDate: Roughly end of Week 12, as above.\nRequirement: 10-15-minute presentation on Hvitfeldt & Silge.\n\nFinal Paper (40 per cent)\nToward the mid-term break we will have a meeting to discuss the topic of your final paper. It will be due on the last day of the exam period. This will be marked by me and reviewed by another DoSS professor.\n\n",
      "last_modified": "2021-10-13T20:59:28-04:00"
    },
    {
      "path": "reproducibility.html",
      "title": "Toronto Workshop on Reproducibility",
      "description": "A two-day workshop focusing on reproducibility in data-centric analysis. Thursday and Friday 25-26 February 2021. Free and hosted via Zoom. All welcome! Register [here](https://forms.gle/txLw43Q7UsXjzQys8).\n",
      "author": [],
      "contents": "\n\nContents\nSupporters\nOverview\nSchedule\nPresenter biographies and abstracts\nCode of conduct\n\nSupporters\nWe gratefully acknowledge the support of the Faculty of Information and the Department of Statistical Sciences at the University of Toronto, and CANSSI Ontario; in particular Dean Wendy Duff, Chair Radu Craiu, and Professor Lisa Strug for their support.\n\n\n\nOverview\nThe Faculty of Information and the Department of Statistical Sciences at the University of Toronto are excited to host a two-day conference bringing together academic and industry participants on the critical issue of reproducibility in applied statistics and related areas. The conference is free and will be hosted online on Thursday and Friday 25-26 February 2021. Everyone is welcome, you don’t need to be affiliated with a university, and you can register here.\nThe conference has three broad areas of focus:\nEvaluating reproducibility: Systematically looking at the extent of reproducibility of a paper or even in a whole field is important to understand where weaknesses exist. Does, say, economics fall flat while demography shines? How should we approach these reproductions? What aspects contribute to the extent of reproducibility.\nPractices of reproducibility: We need new tools and approaches that encourage us to think more deeply about reproducibility and integrate it into everyday practice.\nTeaching reproducibility: While it is probably too late for most of us, how can we ensure that today’s students don’t repeat our mistakes? What are some case studies that show promise? How can we ensure this doesn’t happen again?\nWe intend to record the presentations and will add links here after the conference. Again, the conference is free and online via Zoom, everyone is welcome - you don’t need to be affiliated with a university. If you would like to attend, then please sign up here.\nSchedule\nThursday, 25 February, 2021\nTime\nSpeaker\nFocus\nRecording\n9:00-9:10am\nRohan Alexander, University of Toronto\nWelcome\n-\n9:10-9:20am\nRadu Craiu, University of Toronto\nOpening remarks\nhttps://youtu.be/JGGVEgMBURU\n9:20-9:30am\nWendy Duff, University of Toronto\nOpening remarks\nhttps://youtu.be/Z3aWU1A0FCw\n9:30-10:25am\nMine Çetinkaya-Rundel, University of Edinburgh\nKeynote - Teaching\nhttps://youtu.be/ANH2tv2vkew\n10:30-11:30am\nRiana Minocher, Max Planck Institute for Evolutionary Anthropology\nKeynote - Evaluating\nhttps://youtu.be/O3t8TwWeli0\n11:30-11:55am\nTiffany Timbers, University of British Columbia\nTeaching\nhttps://youtu.be/mh93W8XimOg\nNoon-12:25pm\nTyler Girard, University of Western Ontario\nTeaching\nhttps://youtu.be/k3qgmUAjIvA\n12:30-12:55pm\nShiro Kuriwaki, Harvard University\nPractices\nhttps://youtu.be/-J-eiPnmoNE\n1:00-1:25pm\nMeghan Hoyer, Washington Post & Larry Fenn AP\nPractices\nhttps://youtu.be/FFwMfNk83rc\n1:30-1:55pm\nTom Barton, Royal Holloway, University of London\nEvaluating\nhttps://youtu.be/YTdhcSDqFNQ\n2:00-2:25pm\nBreak\n-\n-\n2:30-2:55pm\nMauricio Vargas, Catholic University of Chile & Nicolas Didier Arizona State University\nEvaluating\nhttps://youtu.be/VpTavLYEMgg\n3:00-3:25pm\nJake Bowers, University of Illinois & The Policy Lab\nPractices\nhttps://youtu.be/3N0YwJIbbHg\n3:30-3:55pm\nAmber Simpson, Queens University\nPractices\nhttps://youtu.be/uUfrcB6aynQ\n4:00-4:25pm\nGarret Christensen, US FDIC\nEvaluating\nhttps://youtu.be/595KkVKJ29w\n4:30-4:55pm\nYanbo Tang, University of Toronto\nPractices\nhttps://youtu.be/0x6gOkldOvk\n5:00-5:25pm\nLauren Kennedy, Monash University\nPractices\nhttps://youtu.be/HhfogRbgbA4\n5:30-6:00pm\nLisa Strug, University of Toronto & CANSSI Ontario\nClosing remarks\nhttps://youtu.be/B_9puTSp3f8\nFriday, 26 February, 2021\nTime\nSpeaker\nFocus\nRecording\n8:00-8:30am\nNick Radcliffe and Pei Shan Yu, Global Open Finance Centre of Excellence & University of Edinburgh\nPractices\nhttps://youtu.be/pWEc8XoIIKE\n8:30-9:00am\nJulia Schulte-Cloos, LMU Munich\nPractices\n-\n9:00-9:25am\nSimeon Carstens, Tweag/IO\nPractices\nhttps://youtu.be/fpoFzDvrJAA\n9:30-9:55am\nBreak\n-\n-\n10:00-10:55am\nEva Vivalt, University of Toronto\nKeynote - Practices\nhttps://youtu.be/0WZUzf2oSGY\n11:00-11:25am\nAndrés Cruz, Pontificia Universidad Católica de Chile\nPractices\nhttps://youtu.be/HjdPDEACxmA\n11:30-11:55am\nEmily Riederer, Capital One\nPractices\nhttps://youtu.be/BknQ0ZNkMNY\nNoon-12:25pm\nFlorencia D’Andrea, National Institute of Agricultural Technology\nPractices\nhttps://youtu.be/9FVUIPfBeXw\n12:30-12:55pm\nJohn Blischak, Freelance scientific software developer\nPractices\nhttps://youtu.be/RrcaGukYDyE\n1:00-1:25pm\nShemra Rizzo, Genentech\nPractices\nhttps://youtu.be/rEYtB3CG76Q\n1:30-2:25pm\nBreak\n-\n-\n2:30-2:55pm\nWijdan Tariq, University of Toronto\nEvaluating\n-\n3:00-3:25pm\nSharla Gelfand, Freelance R Developer\nPractices\nhttps://youtu.be/G5Nm-GpmrLw\n3:30-3:55pm\nRyan Briggs, University of Guelph\nPractices\nhttps://youtu.be/_dgGbxItiB4\n4:00-4:25pm\nMonica Alexander, University of Toronto\nPractices\nhttps://youtu.be/yvM2C6aZ94k\n4:30-4:55pm\nAnnie Collins, University of Toronto\nPractices\nhttps://youtu.be/u4ibhN_nWyI\n5:00-5:25pm\nNancy Reid, University of Toronto\nPractices\nhttps://youtu.be/sIsOPuZOQL4\n5:30-6:00pm\nRohan Alexander, University of Toronto\nClosing remarks\nhttps://youtu.be/7LttFNOI6p8\nAll times are Toronto / US east coast. 9am in Toronto 🇨🇦 is:\n- 7:30pm in Bangalore 🇮🇳;\n- 3pm in Berlin 🥨;\n- 2pm in London 💂;\n- 11am in Santiago 🇨🇱;\n- 6am in Vancouver 🎿; and\n- 1am in Melbourne 🦘.\nPresenter biographies and abstracts\nKeynotes:\nEva Vivalt\nBio: Eva Vivalt is an Assistant Professor in the Department of Economics at the University of Toronto. Her main research interests are in cash transfers, reducing barriers to evidence-based decision-making, and global priorities research.\nAbstract: An overview of the role of forecasting and a new platform for making them.\n\nMine Çetinkaya-Rundel\nBio: Mine Çetinkaya-Rundel is a Senior Lecturer in Statistics and Data Science in the School of Maths at University of Edinburgh, and currently on leave as Associate Professor of the Practice in the Department of Statistical Science at Duke University as well as a Professional Educator and Data Scientist at RStudio. She is the author of three open source statistics textbooks and is an instructor for Coursera. She is the chair-elect of the Statistical Education Section of the American Statistical Association. Her work focuses on innovation in statistics pedagogy, with an emphasis on student-centered learning, computation, reproducible research, and open-source education.\nAbstract: In the beginning was R Markdown. In this talk I will give a brief review of teaching statistics and data analysis through the lens of reproducibility with R Markdown, and how to use this tool effectively in teaching to maintain reproducibility as the scope of your students’ projects and their experience grow.\n\nRiana Minocher\nBio: Riana Minocher is a doctoral student at the Max Planck Institute for Evolutionary Anthropology in Leipzig. She is an evolutionary biologist with broad interests. She has worked on a range of projects on human and non-human primate behaviour and ecology. She is particularly interested in the evolutionary processes that create and shape diversity between and within groups. Through her PhD research, she is keen on exploring the dynamics of cultural transmission and learning in human populations, to better understand the diverse patterns of behaviour we observe.\nAbstract: Interest in improving reproducibility, replicability and transparency of research has increased substantially across scientific fields over the last few decades. We surveyed 560 empirical, quantitative publications published between 1955 and 2018, to estimate the rate of reproducibility for research on social learning, a large subfield of behavioural ecology. We found supporting materials were available for less than 30% of publications during this period. The availability of data declines exponentially with time since publication, with a half-life of about six years, and this “data decay rate” varies systematically with both study design and study species. Conditional on materials being available, we estimate that a reasonable researcher could expect to successfully reproduce about 80% of published results, based on our evaluating a subset of 40 publications. Taken together, this indicates an overall success rate of 24% for both acquiring materials and recovering published results, with non-reproducibility of results primarily due to unavailable, incomplete, or poorly-documented data. We provide recommendations to improve the reproducibility of research on the ecology and evolution of social behaviour.\n\nInvited presentations:\nAmber Simpson\nBio: Amber Simpson is the Canada Research Chair in Biomedical Computing and Informatics and Associate Professor in the School of Computing (Faculty of Arts and Science) and Department of Biomedical and Molecular Sciences (Faculty of Health Sciences). She specializes in biomedical data science and computer-aided surgery. Her research group is focused on developing novel computational strategies for improving human health. She joined the Queen’s University faculty in 2019, after four years as faculty at Memorial Sloan Kettering Cancer Center in New York and three years as a Research Assistant Professor in Biomedical Engineering at Vanderbilt University in Nashville. She is an American Association of Cancer Research award winner and the holder of multiple National Institutes of Health grants. She received her PhD in Computer Science from Queen’s University.\nAbstract: The development of predictive and prognostic biomarkers is a major area of investigation in cancer research. Our lab specializes in the development of quantitative imaging markers for personalized treatment of cancer. Progress in developing these novel markers is limited by a lack of optimization, standardization, and validation, all critical barriers to clinical use. This talk will describe our work in the repeatability and reproducibility of imaging biomarkers.\n\nAndrés Cruz\nBio: Andrés Cruz is an adjunct instructor at Pontificia Universidad Católica de Chile, where he teaches computational social science. He holds a BA and MA in Political Science, and is the co-editor of “R for Political Data Science: A Practical Guide” (CRC Press, 2020), an R manual for social science students and practitioners.\nAbstract: inexact is an RStudio addin to supervise fuzzy joins. Merging data sets is a simple procedure in most statistical software packages. However, applied researchers frequently face problems when dealing with data in which ID variables are not properly standardized. For instance, politicians’ names can be spelled differently in multiple sources (press reports, official documents, etc.), causing regular merging methods to fail. The most common approach to fix this issue when working with small and medium data sets is manually fixing the problematic values before merging. However, this solution is time-consuming and not reproducible. An RStudio addin called “inexact” was created to help with this. The package draws from approximate string matching algorithms, which quantify the distance between two given strings. When merging data sets with non-standardized ID variables, inexact users benefit from automatic match suggestions, while also being able to override the automatic choices when needed, using a user-friendly graphical user interface (GUI). The output is simply code to perform the corrected merging procedure, which registers the employed algorithm and any corrections made by the user, ensuring reproducibility. A development version of inexact is available on GitHub.\n\nAnnie Collins\nBio: Annie Collins is an undergraduate student in the Department of Mathematics specializing in applied mathematics and statistics with a minor in history and philosophy of science. In her free time, she focusses her efforts on student governance, promoting women’s representation in STEM, and working with data in the non-profit and charitable sector.\nAbstract: We create a dataset of all the pre-prints published on medRxiv between 28 January 2020 and 31 January 2021. We extract the text from these pre-prints and parse them looking for keyword markers signalling the availability of the data and code underpinning the pre-print. We are unable to find markers of either open data or open code for 81 per cent of the pre-prints in our sample. Our paper demonstrates the need to have authors categorize the degree of openness of their pre-print as part of the medRxiv submissions process, and more broadly, the need to better integrate open science training into a wide range of fields\n\nEmily Riederer\nBio: Emily Riederer is a Senior Analytics Manager at Capital One. Her team focuses on reimagining our analytical infrastructure by building data products, elevating business analysis with novel data sources and statistical methods, and providing consultation and training to our partner teams.\nAbstract: Complex software systems make performance guarantees through documentation and unit tests, and they communicate these to users with conscientious interface design. However, published data tables exist in a gray area; they are static enough not to be considered a ‘service’ or ‘software’, yet too raw to earn attentive user interface design. This ambiguity creates a disconnect between data producers and consumers and poses a risk for analytical correctness and reproducibility. In this talk, I will explain how controlled vocabularies can be used to form contracts between data producers and data consumers. Explicitly embedding meaning in each component of variable names is a low-tech and low-friction approach which builds a shared understanding of how each field in the dataset is intended to work. Doing so can offload the burden of data producers by facilitating automated data validation and metadata management. At the same time, data consumers benefit by a reduction in the cognitive load to remember names, a deeper understanding of variable encoding, and opportunities to more efficiently analyze the resulting dataset. After discussing the theory of controlled vocabulary column-naming and related workflows, I will illustrate these ideas with a demonstration of the convo R package, which aids in the creation, upkeep, and application of controlled vocabularies. This talk is based on my related blog post and R package.\n\nFlorencia D’Andrea\nBio: Florencia D’Andrea is a post-doc at the Argentine National Institute of Agricultural Technology where she develops computer tools to assess the risk of pesticide applications for aquatic ecosystems. She holds a PhD in Biological Sciences from the University of Buenos Aires, Argentina, and is part of the ReproHack core-team and the R-Ladies global team. She believes that code and data should also be recognized as valuable products of scientific work.\nAbstract: Choose your own adventure to a reproducible scientific article: learnings from ReproHack “I shared the code and data of my last scientific article, does it mean that it is reproducible?” One might think that having access to the research data and the code used to analyze that data would be enough to reproduce published results, but often this is much more involved. Is reproducibility dependent on the reviewer’s knowledge? What things do we not usually think about can affect reproducibility? Can the choice of how to capture the computational environment influence the experience of the reviewer? In this talk, we are going to think together some of the necessary steps that make someone else able to reproduce a scientific article or project. I will share some thoughts from my experience in ReproHack and show you how reviewing is a great practice to learn about reproducibility. What is ReproHack? Reprohack is a hackathon-style event focused on the reproducibility of research results. These hackathons provide a low-pressure sandbox environment for practicing reproducible research: Authors can practice producing reproducible research and receive friendly feedback and appreciation of their efforts. Participants can practice reviewing, learn about reproducibility best practices as well as common pitfalls from working with real-life materials rather than just dummy. They also get inspired and grow confidence in working more openly themselves. Research Community benefits from: Evaluating what best practice is in practice. More practice in both developing and reviewing materials.\n\nGarret Christensen\nBio: Garret Christensen received his economics PhD from UC Berkeley in 2011. He is an economist with the FDIC. Before that he worked for the Census Bureau, and he was a project scientist with the Berkeley Initiative for Transparency in the Social Sciences and a Data Science Fellow with the Berkeley Institute for Data Science.\nAbstract: Adoption of Open Science Practices is Increasing: Survey Evidence on Attitudes, Norms and Behavior in the Social Sciences. Has there been meaningful movement toward open science practices within the social sciences in recent years? Discussions about changes in practices such as posting data and pre-registering analyses have been marked by controversy—including controversy over the extent to which change has taken place. This study, based on the State of Social Science (3S) Survey, provides the first comprehensive assessment of awareness of, attitudes towards, perceived norms regarding, and adoption of open science practices within a broadly representative sample of scholars from four major social science disciplines: economics, political science, psychology, and sociology. We observe a steep increase in adoption: as of 2017, over 80% of scholars had used at least one such practice, rising from one quarter a decade earlier. Attitudes toward research transparency are on average similar between older and younger scholars, but the pace of change differs by field and methodology. According with theories of normal science and scientific change, the timing of increases in adoption coincides with technological innovations and institutional policies. Patterns are consistent with most scholars underestimating the trend toward open science in their discipline.\n\nJake Bowers\nBio: Jake Bowers is a Senior Scientist at The Policy Lab and a member of the Lab’s data science practice. Jake is Associate Professor of Political Science and Statistics at the University of Illinois Urbana-Champaign. He has served as a Fellow in the Office of Evaluation Sciences in the General Services Administration of the US Federal Government and is Methods Director for the Evidence in Governance and Politics network. Jake holds a PhD in Political Science from the University of California, Berkeley, and a BA in Ethics, Politics and Economics from Yale University.\nAbstract: For evidence-based public policy to grow in impact and importance, practices to enhance scientific credibility should be brought into governmental contexts and also should be modified for those contexts. For example, few analyses of governmental data allow data sharing (in contrast with most scientific studies); and many analyses of governmental administrative data inform high stakes immediate decisions (in contrast with the slow accumulation of scientific knowledge). We make several proposals to adjust scientific norms of reproducibility and pre-registration to the policy context.\n\nJohn Blischak\nBio: John Blischak is a freelance scientific software developer for the life sciences industry. He is the primary author of the R package workflowr and the co-maintainer of the CRAN Task View on Reproducible Research. He received his PhD in Genetics from the University of Chicago.\nAbstract: The workflowr R package helps organize computational research in a way that promotes effective project management, reproducibility, collaboration, and sharing of results. workflowr combines literate programming (knitr and rmarkdown) and version control (Git, via git2r) to generate a website containing time-stamped, versioned, and documented results. Any R user can quickly and easily adopt workflowr, which includes four key features: (1) workflowr automatically creates a directory structure for organizing data, code, and results; (2) workflowr uses the version control system Git to track different versions of the code and results without the user needing to understand Git syntax; (3) to support reproducibility, workflowr automatically includes code version information in webpages displaying results and; (4) workflowr facilitates online Web hosting (e.g. GitHub Pages) to share results. Our goal is that workflowr will make it easier for researchers to organize and communicate reproducible results. Documentation and source code are available.\n\nJulia Schulte-Cloos\nBio: Julia Schulte-Cloos is a Marie Skłodowska-Curie funded research fellow at LMU Munich. She has earned her PhD in Political Science from the European University Institute. Julia is passionate about developing tools and templates for generating reproducible workflows and creating reproducible research outputs with R Markdown.\nAbstract: We present a template package in R that allows users without any prior knowledge of R Markdown to implement reproducible research practices in their scientific workflows. We provide a single Rmd-file that is fully optimized for two different output formats, HTML and PDF. While in the stage of explorative analysis and when focusing on content only, researchers may rely on the ‘draft mode’ of our template that knits to HTML When in the stage of research dissemination and when focusing on the presentation of results, in contrast, researchers may rely on the ‘manuscript mode’ that knits to PDF. Our template outlines the basics for successfully writing a reproducible paper in R Markdown by showing how to include citations, figures, and cross-references. It also provides examples for the use of ggplot2 to include plots, both in static and animated outputs, and it shows how to present the most commonly used tables in scientific research (descriptive statistics and regression tables). Finally, in our template, we discuss some more advanced features of literate programming and helpful tweaks in R Markdown.\n\nLauren Kennedy\nBio: Lauren Kennedy is a lecturer in the Econometrics and Business Statistics department at Monash University. She works on applied statistical problems in the social sciences using primarily Bayesian methodology. Her most recent work is with survey data, particularly the use of model and poststratify methods to make population and subpopulation predictions.\nAbstract: Survey data is challenging to work with. It frequently contains entry errors (either from respondent recollection or interviewer entry) that are difficult to verify and identify. Survey data is often received in a form that is sensible for the software for which entry is intuitive, which does not necessarily follow through to a data structure that is intuitive to work with as an analyst. When we consider the use of tools like multilevel regression and poststratification, our challenges compound. Even if the population data is precleaned before release, measurements and items in the sample need to be mapped to measurements and items in the population. In this talk we discuss case studies of how and where these challenges appear in practice.\n\nLarry Fenn\nBio: Larry Fenn is a data journalist at the Associated Press. His investigative work has covered a broad range of topics, from guns to education to housing policy. Prior to journalism, he was an adjunct lecturer at Hunter College for applied mathematics and statistics.\nAbstract: Please see Meghan Hoyer.\n\nMauricio Vargas Sepúlveda\nBio: Mauricio Vargas Sepúlveda loves working with data and statistical programming, and is constantly learning new skills and tooling in his spare time. He mostly works in R due to its huge number of libraries and emphasis on reproducible analysis.\nAbstract: Evidence-based policymaking has turned into a high priority for governments across the world. The possibility of gaining efficiencies in the public expenditure and linking the policy design to the desired outcomes have been presented as significant advantages for the field of comparative policy. However, the same movement that supports the use of evidence in public policy decision making has brought a great concern about the sources of the supposed evidence. How should policymakers evaluate the evidence? The possibilities are open and depend on the institutional arrangements that support governmental operation and the possibility of properly judging the nature of the evidence. The movement of science reproducibility could enlighten the discussion about the quality of the evidence by providing a structured approach towards the source’s validity based on the possibility of reproducing the logic and analysis proper of scientific communication. This paper attempts to analyze the nature and quality of civil society organizations’ contributions to develop evidence for policymaking process from reproducibility perspective.\n\nMeghan Hoyer\nBio: Meghan Hoyer is Data Director at The Washington Post where she leads data projects and acts as a consulting editor on data-driven stories, graphics and visualizations across the newsroom. Before this she helped lead the AP’s data journalism. Meghan earned a bachelor of science in journalism at Northwestern University and an MFA in creative nonfiction writing at Old Dominion University.\nAbstract: This talk will cover AP DataKit, which is an open-source command-line tool designed to better structure and manage projects, and more generally, talk about creating sane, reproducible workflows.\n\nMonica Alexander\nBio: Monica Alexander is an Assistant Professor in Statistical Sciences and Sociology at the University of Toronto. She received her PhD in Demography from the University of California, Berkeley. Her research interests include statistical demography, mortality and health inequalities, and computational social science.\nAbstract: Sharing code for papers and projects is an important part of reproducible research. However, sometimes sharing code may be difficult, if the researcher feels their code is ‘not good enough’ and may reflect poorly on their broader research skills. This presentation contains some brief reflections from research, consulting, and teaching experiences that have led to overcoming my own barriers to sharing code and to help others do the same.\n\nNancy Reid\nBio: Nancy Reid is Professor of Statistical Sciences at the University of Toronto and Canada Research Chair in Statistical Theory and Applications. Her main area of research is theoretical statistics. This treats the foundations and properties of methods of statistical inference. She is interested in how best to use information in the data to construct inferential statements about quantities of interest. A very simple example of this is the widely quoted ‘margin of error’ in the reporting of polls, another is the ubiquitous ‘p-value’ reported in medical and health studies. Much of her research considers how to ensure that these inferential statements are both accurate and effective at summarizing complex sets of data.\nAbstract: Are p-values contributing to a crisis in replicability and reproducibility? This has been the topic of many dialogues, diatribes, and discussions among statisticians and scientists in recent years. I will share my thoughts on the issues, with emphasis on the role of inferential theory in helping to clarify the arguments.\n\nNick Radcliffe\nBio: Nick Radcliffe is the founder of the data science consulting and software firm, Stochastic Solutions Limited, the Interim Chief Scientist at the Global Open Finance Centre of Excellence, and a Visiting Professor in Maths and Stats at University of Edinburgh, Scotland. His background combines theoretical physics, operations research, machine learning and stochastic optimization. Nick’s current research interests include a focus on test-driven data analysis, (an approach to improving correctness of analytical results that combines ideas from reproducible research and test-driven development) and privacy-respecting analysis. He is the lead author of the open-source Python tdda package, which provides practical tools for testing analytical software and data, and also of the Miró data analysis suite.\nAbstract: The Global Open Finance Centre of Excellence is currently engaged in analysis of the financial impact of COVID-19 on the citizens and businesses of the UK. This research uses non-consented but de-identified financial data on individuals and businesses, on the basis of legitimate interest. All analysis is carried out in a highly locked-down analytical environment known as a Safe Haven. This talk will explain our approach to the challenges of ensuring the correctness and robustness of results in an environment where neither code nor input data can be opened up for review and even outputs need to be subject to disclosure control to reduce further any risks to privacy. Topics will include: testing input data for conformance and lack of personal identifiers using constraints; multiple implementations and verification of equivalence of results; regression tests and reference tests; verification of output artefacts; verification of output disclosure controls; data provenance and audit trails; test-driven data analysis—the underlying philosophy (and library) that we use to underpin this work.\n\nNicolas Didier\nBio: Nicolas Didier is studying for a PhD in Public Administration and Policy at the Arizona State University. During his PhD studies and previous studies, he has worked extensively on developing evidence that addresses policy in labour markets and public expenditure.\nAbstract: Please see Mauricio Vargas Sepúlveda.\n\nRyan Briggs\nBio: Ryan Briggs is a social scientist who studies the political economy of poverty alleviation. Most of his research focuses on the spatial targeting of foreign aid. He is an Assistant Professor in the Guelph Institute of Development Studies and Department of Political Science at the University of Guelph. Before that, he taught at Virginia Tech and American University.\nAbstract: It is hard to do research. One reason for this is that it has a production function where one low quality input (among many high quality inputs) can poison a final result. This talk explains how such ‘o-ring’ production functions work and draws out lessons for applied researchers.\n\nSharla Gelfand\nBio: Sharla Gelfand is a freelance R and Shiny developer specializing in enabling easy access to data and replacing manual, redundant processes with ones that are automated, reproducible, and repeatable. They also co-organize R-Ladies Toronto and the Greater Toronto Area R User Group. They like R (of course), dogs, learning Spanish, playing bass, and punk.\nAbstract: Getting stuck, looking around for a solution, and eventually asking for help is an inevitable and constant aspect of being a programmer. If you’ve ever looked up a question only to find some brave soul getting torn apart on Stack Overflow for not providing a minimum working example, you know it’s also one of the most intimidating parts! A minimum working example, or a reproducible example as it’s more often called in the R world, is one of the best ways to get help with your code - but what exactly is a reproducible example? How do you create one, and do it efficiently? Why is it so scary? This talk will cover what components are needed to make a good reproducible example to maximize your ability to get help (and to help yourself!), strategies for coming up with an example and testing its reproducibility, and why you should care about making one. We will also discuss how to extend the concept of reproducible examples beyond “Help! my code doesn’t work” to other environments where you might want to share code, like teaching and blogging.\n\nShemra Rizzo\nBio: Shemra Rizzo is a senior data scientist in Genentech’s Personalized Healthcare group. Shemra’s role includes research on COVID-19 using electronic health records, and the development of data-driven approaches to evaluate clinical trial eligibility criteria. Shemra obtained her PhD in Biostatistics from UCLA. Before joining Genentech, Shemra was an assistant professor of statistics at UC Riverside, where her research covered topics in mental health, health disparities, and nutrition. In her free time, Shemra enjoys spending time with her family and running.\nAbstract: Real world data for an emerging disease has unique challenges. In this talk, I’ll describe how our group made sense of complex Electronic Health Records (EHR) data for COVID19 early in the pandemic. I will share our experience working towards reliable, replicable and reproducible studies using EHR licensed data.\n\nShiro Kuriwaki\nBio: Shiro Kuriwaki is a PhD Candidate in the Department of Government at Harvard University. His research focuses on democratic representation in American Politics. In an ongoing project, he studies the structure of voter’s choices across levels of government and the political economy of local elections, using cast vote records and surveys. His other projects also help understand the mechanics of representation, including: public opinion and Congress, modern survey statistics and causal inference, and election administration. Prior to and during graduate school, he worked at the Analyst Institute in Washington D.C.\nAbstract: I show how new features of the dataverse R package facilitate reproducibility in empirical, substantive projects. While packages and scripts make our code transparent and portable across forms, the import of large and complex datasets is often a nuisance in project workflows that involve various data cleaning and wrangling tasks. And the GUI for Dataverse can be sometimes tedious to integrate into code-based workflow. Will Beasley and I, along with multiple other contributors, updated the dataverse R package for the first time since 2017 with the goal of spreading its use in empirical workflow. In this iteration, we make it easier to retrieve dataframes of various file format and options for version specification and variable subsetting. I also discuss the latest updates to pyDataverse, a independent implementation in Python which is currently more advanced in its implementation but focused on uploading and creating datasets to dataverse.\n\nSimeon Carstens\nBio: Simeon Carstens is a Data Scientist at Tweag I/O, a software innovation lab and consulting company. Originally a physicist, Simeon did a PhD and postdoc research in computational biology, focusing on Bayesian determination of three-dimensional chromosome structures.\nAbstract: Data analysis often requires a complex software environment containing one or several programming languages, language-specific modules and external dependencies, all in compatible versions. This poses a challenge to reproducibility: what good is a well-designed, tested and documented data analysis pipeline if it is difficult to replicate the software environment required to run it? Standard tools such as Python / R virtual environments solve part of the problem, but do not take into account external and system-level dependencies. Nix is a fully declarative, open-source package manager solving this problem: a program packaged with Nix comes with a complete description of its full dependency tree, down to system libraries. In this presentation, I will give an introduction to Nix, show in a live demo how to set up a fully reproducible software environment and compare Nix to existing solutions such as virtual environments and Docker.\n\nTiffany Timbers\nBio: Tiffany Timbers is an Assistant Professor of Teaching in the Department of Statistics and an Co-Director for the Master of Data Science program (Vancouver Option) at the University of British Columbia. In these roles she teaches and develops curriculum around the responsible application of Data Science to solve real-world problems. One of her favourite courses she teaches is a graduate course on collaborative software development, which focuses on teaching how to create R and Python packages using modern tools and workflows.\nAbstract: In the data science courses at UBC, we define data science as the study and development of reproducible and auditable processes to obtain value (i.e., insight) from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, such as predictive modelling. This fact, along with the highly technical nature of the industry standard reproducibility tools currently employed in data science, present out-of-the gate challenges in teaching reproducibility in the data science classroom. Put simply, students are not as intrinsically motivated to learn this topic, and it is not an easy one for them to learn. What can a data science educator do? Over several iterations of teaching courses focused on reproducible data science tools and workflows, we have found that motivation, direct instruction and practice are key to effectively teach this challenging, yet important subject. In this talk, I will present examples of how we deeply motivate, effectively instruct and provide ample practice opportunities to our Master of Data Science students to effectively engage them in learning about this topic.\n\nTom Barton\nBio: Tom Barton is a PhD student in Politics at Royal Holloway, University of London. His PhD focuses on the impact of Voter Identification laws on political participation and attitudes. More generally his interests include elections, public opinion (particularly social values) and quantitative research methods.\nAbstract: I reproduce Surridge, 2016, ‘Education and liberalism: pursuing the link’, Oxford Review of Education, 42:2, pp. 146-164, using the 1970 British Cohort Study (BCS70), instead using a difference-in-difference regression approach with more waves of data. I find that whilst there is evidence for both socialisation and self-selection models, self-selection dominates the link between social values and university attendance. This is counter to what Surridge (2016) concluded. The need for re-specification was two-fold, first Surridge’s methodology did not fully test for causality and secondly later waves have data have become available since.\n\nTyler Girard\nBio: Tyler Girard is a PhD Candidate in political science at the University of Western Ontario (London, Ontario, Canada). His dissertation research seeks to explain the origins and diffusion of the global financial inclusion agenda by focusing on the role of ambiguous ideas in mobilizing and consolidating transnational coalitions. More generally, his work also explores new approaches to conceptual measurement in international relations.\nAbstract: In what ways can we incorporate reproducible practices in pedagogy for social science courses? I discuss how individual and group exercises centered around the replication of existing datasets and analyses offer a flexible tool for experiential learning. However, maximizing the benefits of such an approach requires customizing the activity to the students and the availability of instructor support. I offer several suggestions for effectively using replication exercises in both undergraduate and graduate level courses.\n\nWijdan Tariq\nBio: Wijdan Tariq is an undergraduate student in the Department of Statistical Sciences at the University of Toronto.\nAbstract: I undertake a narrow replication of Caicedo, 2019, ‘The Mission: Human Capital Transmission, Economic Persistence, and Culture in South America’, Quarterly Journal of Economics, 134:1, pp. 507-556. Caicedo reports of a remarkable, religiously inspired human capital intervention that took place in remote parts of South America 250 years ago and whose positive economic effects, he claims, persist to this day. I replicate some of the paper’s key results using data files that are available on the Harvard Dataverse portal. I discuss some lessons learned in the process of replicating this paper and share some reflections on the state of reproducibility in economics.\n\nYanbo Tang\nBio: Yanbo Tang is a PhD candidate at the University of Toronto in the Department of Statistical Sciences, under the joint supervision of Nancy Reid and Daniel Roy. He is interested in the study and application of methods in higher order asymptotics and statistical inference in the presence of many nuisance parameters. Nowadays, he works under the careful gaze of his pet parrot.\nAbstract: Hypothesis testing results often rely on simple, yet important assumptions about the behavior of the distribution of p-values under the null and alternative. We show that commonly held beliefs regarding the distribution of p-values are misleading when the variance or location of the test statistic are not well-calibrated or when the higher order cumulants of the test statistic are not negligible. We further examine the impact of having these misleading p-values on reproducibility of scientific studies, with some examples focused on GWAS studies. Certain corrected tests are proposed and are shown to perform better than their traditional counterparts in certain settings.\n\nCode of conduct\nCode\nThe organizers of the Toronto Workshop on Reproducibility are dedicated to providing a harassment-free experience for everyone regardless of age, gender, sexual orientation, disability, physical appearance, race, or religion (or lack thereof).\nAll participants (including attendees, speakers, sponsors and volunteers) at the Toronto Workshop on Reproducibility are required to agree to the following code of conduct.\nThe code of conduct applies to all conference activities including talks, panels, workshops, and social events. It extends to conference-specific exchanges on social media, for instance posts tagged with the identifier of the conference (e.g. #TOrepro on Twitter), and replies to such posts.\nOrganizers will enforce this code throughout and expect cooperation in ensuring a safe environment for all.\nExpected Behaviour\nAll conference participants agree to:\nBe considerate in language and actions, and respect the boundaries of fellow participants.\nRefrain from demeaning, discriminatory, or harassing behaviour and language. Please refer to ‘Unacceptable Behaviour’ for more details.\nAlert Rohan Alexander - rohan.alexander@utoronto.ca - or Kelly Lyons - kelly.lyons@utoronto.ca - if you notice someone in distress, or observe violations of this code of conduct, even if they seem inconsequential. Please refer to the section titled ‘What To Do If You Witness or Are Subject To Unacceptable Behaviour’ for more details.\nUnacceptable Behaviour\nBehaviour that is unacceptable includes, but is not limited to:\nStalking\nDeliberate intimidation\nUnwanted photography or recording\nSustained or willful disruption of talks or other events\nUse of sexual or discriminatory imagery, comments, or jokes\nOffensive comments related to age, gender, sexual orientation, disability, race or religion\nInappropriate physical contact, which can include grabbing, or massaging or hugging without consent.\nUnwelcome sexual attention, which can include inappropriate questions of a sexual nature, asking for sexual favours or repeatedly asking for dates or contact information.\nIf you are asked to stop harassing behaviour you should stop immediately, even if your behaviour was meant to be friendly or a joke, it was clearly not taken that way and for the comfort of all conference attendees you should stop.\nAttendees who behave in a manner deemed inappropriate are subject to actions listed under ‘Procedure for Code of Conduct Violations’.\nAdditional Requirements for Conference Contributions\nPresentation slides and posters should not contain offensive or sexualised material. If this material is impossible to avoid given the topic (for example text mining of material from hate sites) the existence of this material should be noted in the abstract and, in the case of oral contributions, at the start of the talk or session.\nProcedure for Code of Conduct Violations\nThe organizing committee reserves the right to determine the appropriate response for all code of conduct violations. Potential responses include:\na formal warning to stop harassing behaviour\nexpulsion from the conference\ncancellation or early termination of talks or other contributions to the program\nWhat To Do If You Witness or Are Subject To Unacceptable Behaviour\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact Rohan Alexander - rohan.alexander@utoronto.ca, or Kelly Lyons - kelly.lyons@utoronto.ca.\nWe will take all good-faith reports of harassment by Toronto Workshop on Reproducibility participants seriously.\nWe reserve the right to reject any report we believe to have been made in bad faith. This includes reports intended to silence legitimate criticism.\nWe will respect confidentiality requests for the purpose of protecting victims of abuse. We will not name harassment victims without their affirmative consent.\nQuestions or concerns about the Code of Conduct can be addressed to rohan.alexander@utoronto.ca.\nAcknowledgements\nParts of the above text are licensed CC BY-SA 4.0. Credit to SRCCON. This code of conduct was based on that developed for useR! 2018 which was a revision of the code of conduct used at previous useR!s and also drew from rOpenSci’s code of conduct.\n\n\n\n\n\n\n",
      "last_modified": "2021-10-13T20:59:29-04:00"
    },
    {
      "path": "sta304.html",
      "title": "Surveys, Sampling, and Observational Data",
      "description": "STA304 is an upper-level undergraduate course at the University of Toronto's Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nHow to succeed\nHow we’ll work\nAdvice from past students\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nWeekly quizzes\nProfessional conduct\nPaper #1\nPaper #2\nPaper #3\nFinal Paper\n\n\nPreamble\n\n\nOverview\n\nThe best thing about being a statistician, is that you get to play in everyone’s backyard.\nJohn Tukey\n\nThe work of applied statisticians, regardless of their specific job title and area of application, is the most important and exciting work in the world right now. The ability to gather data, analyse it, and communicate your understanding of the underlying process is incredibly valuable. In this course you will learn and apply the essentials of this.\nWe focus on surveys, sampling and observational data. The very stuff of statistical science! We will approach these topics from a practical perspective. You will actually run surveys and learn how messy it is to put one together. You will learn how to think about sampling, how to implement it, and why the details matter. You will forecast an election. And you will conduct original research. More generally, you will learn how to obtain and analyse data and use it to make sensible claims about the world.\nTo work as an applied statistician requires you to be able to, as part of a small team:\nGather data in less-than-perfect settings.\nEfficiently prepare and clean data toward some purpose.\nAnalyse it in a reproducible, thorough, modern, and statistically-mature manner.\nCommunicate your analysis to stakeholders including colleagues and clients with and without formal statistical training.\nYou likely have some of these skills already. This course will further develop them. At the end of the course you will have a portfolio of work focused on surveying, sampling, and observational data, that you could show off to a potential employer.\nEach week you will read relevant papers and books, engage with them through discussion with each other, myself, and the TA. You will bring this all together and show off how much you have learnt through practical, on-going, assessment.\nIt is important to recognise that putting together everything that you have learnt to this point in this way will be difficult. It is not possible to cover everything that you will need to know. You should proactively identify and address aspects where you are weak through seeking additional information and resources. This course acts as a guide as to what is important, it does not contain everything that is important.\nThis course is different to many other courses at the University of Toronto. At the end of this course, you will have a portfolio of work that you could show off to a potential employer. You will have developed the skills to work successfully as an applied statistician or data scientist. And you will know how to fill gaps in your knowledge yourself. A lot of scholarships and jobs these days ask for GitHub and blog links etc to show off a portfolio of your work. This is the class that gives you a chance to develop these. It’s very important to having something to show that needs to go beyond what is done in a normal class.\nHow to succeed\nIn this course you will work in a self-directed, open-ended manner. Identify relevant areas of interest and then learn the skills that you need to explore those areas.\nTo successfully complete this course, you should expect to spend a large portion of your time reading and writing (both code and text). Deeply engage with the materials. Find a small study group and keep each other motivated and focused. At the start of the week, read the course notes, all compulsory materials and some recommended materials based on your interest. After doing that, but before the ‘lecture’ time you should complete the weekly quiz. During ‘lectures’ I’ll live-code, discuss materials in the course notes, talk about an experiment, and you’ll have a chance to discuss the materials with me.\nYou need to be more active in your learning in this course than others - read the notes and related materials - and then go out there and teach yourself more and apply it. You will not be spoon-fed in this course. Each week try to write reproducible, understandable, R code surrounded by beautifully crafted text that motivates, backgrounds, explains, discusses and criticizes. Make steady progress toward the assessment.\nThis is not a ‘bird course’. Typically, after the term is finished, students say that the course is difficult but rewarding. The TAs and I are always available to answer any questions. Please come to office hours!\nHow we’ll work\nThis webpage will provide almost all the guiding materials that you need and links to the relevant parts of the notes. The course notes are available here: https://www.tellingstorieswithdata.com. Those contain notes and other material that you could go over. There is a course Slack for discussion. We’ll use Quercus really only for assessment submission and grading. I expect you to work professionally, and so we’ll try to use professional tools to the extent possible.\nA rough weekly flow for the course would be something like:\nRead the week’s course notes.\nRead/watch/listen to the compulsory materials.\nComplete the weekly quiz.\nAttend the lecture.\nAttend the lab.\nMake progress on a paper.\nAdvice from past students\nSuccessful past students have the following advice (completely unedited by me):\n“Start reading and writing on a weekly basis, watch some videos on R and RMD but more importantly learn how to use Google.”\n“It is not a wise idea to take this course if you did not take any other STA 300 level course before.”\n“Start early, find a group of people you trust enough to divide the work up fairly. Let people work to their strengths (people who know R should do the modelling, good writers should write most of the reports, etc.)”\n“Not to worry if you don’t do well on the first problem set—the nature of the course is to build up skills overtime, and it’s meant to be challenging in the beginning. In the end, it is worth it because you learn very valuable applicable skills on how to write professional reports.”\n“Work on your writing and direction following skills.”\n“Look at the rubric. There were times that I lost marks because I didn’t follow the rubric properly. Go to office hours, they are very useful as you can ask your own question and also get answers to questions other people ask and you didn’t think of. Also, do the assignments to the best of your ability. You will lose marks if you don’t put in effort and the only person you’re hurting is yourself.”\n“During lectures, focus more on the why the prof is doing what he’s doing. When he runs certain commands in R, figure out why that sequence of code gives what you want, because it’ll help adapt his code into your assignment code. just remembering what he’s doing in lecture becomes useless really quickly since the thought process matters more. also, start everything early.”\n“Do this course when you really want to learn something and have a lot of time to working on it.”\n“you need to be very skillful in RStudio and latex. Otherwise you would be struggling.”\n“Try to incorporate the feedback given and read a looottttttttt. Also start early on the problem sets because they tend to take a lot of time. Don’t give up!”\n“-Find a good group for problem sets”\n“If the assignments stay the same, I would tell students to approach this class from the perspective of ‘storytelling with statistics’ rather than a statistics course. You need to use R, and Markdown, and have a solid understanding of concepts like regression and sampling, but more importantly you need to be able to interpret results and write about them in a way coherent and professional way.”\n“do your readings”\n“Definitely get ready to write reports”\n“Do not take sta304 with Prof Rohan, it is pretty tough”\n“Start your work a bit earlier, make sure to follow the format expected and the rubric exactly.”\n“Read course material. Figure out WHY this paper/video is being shown to you and what you generally learn from it. Surround yourself with people dedicated to putting in the effort to understand material and who are thorough in their work so you can discuss content and/or work together.”\n“1. Be prepared to work extremely hard (8-11 hours a week). 2. Learn RStudio before course begins–STA130 is ideal preparation. 3. Start problem sets as soon as they are released.”\n“learn to code early and extensively use the office hours with the prof.”\n“This course requires lots of time dedicated and is not an”easy bird course\" but is an incredibly rewarding course if one wants to learn how statistics is applied in the real world.\"\nAcknowledgements\nThank you to the following people for generously providing comments, references, suggestions, and thoughts that directly contributed to this outline: Bethany White, Dan Simpson, Jesse Gronsbell, Kelly Lyons, Lauren Kennedy, and Monica Alexander. Thank you especially to Samantha-Jo Caetano who influenced all aspects of this and co-taught the first version in Fall 2020.\nContent\nEach week you should go through the course notes and all compulsory materials. During the lecture I will live-code various aspects. I will also discuss a case study, typically a paper. During the lab, a TA will either lead small group discussions or similarly lead other work. The lecture will be recorded and posted here, but again, it’s not enough to just watch that - you need to read and write yourself.\nWeek 1\n‘Drinking from a fire hose’.\nContent: Drinking from a fire hose, R Essentials.\nCase Study: Fisher’s Lady Tasting Tea.\nLab: Go through first four modules of DoSS Toolkit and discuss any issues with the TA.\nWeek 2\n‘Science-ing’.\nContent: Workflow, Static communication.\nCase Study: Tuskegee Syphilis Study.\nLab: Go through modules five to eight of DoSS Toolkit and discuss any issues with the TA.\nWeek 3\n‘Why, if ever I did fall off—which there’s no chance of—but if I did–’.\nContent: Experiments, and treatment effects.\nCase Study: The Oregon Health Insurance Experiment in the United States.\nSpecial guest: Greg Wilson on how to run a meeting.\nLab:\nPlease pretend that you work as a junior analyst for a large consulting firm. Further, pretend that your consulting firm has taken a contract to put together a facial recognition model for the Canada Border Services Agency’s Inland Enforcement branch. Write five or six points with regard to your thoughts on this matter. What would you do and why? Then split into small groups and compare your points with others. Do you think the model would end up being implemented?\nWith the help of the TA, please conduct ‘face-to-face’ surveys (via Zoom). For this exercise, you will be randomly split into groups of two. You have two minutes in each group and will then be swapped to another group. One person is to survey the other person asking the following questions: i) ‘What is your gender?’, ii) ‘What is your age?’, iii) ‘What is your marital status?’, iv) ‘What is your income?’, v) ‘If an election were held today who would you vote for?’. After one person is done, then switch roles. When you are the questioner you should record all responses using a small CSV (but not the person’s name please). When you are the respondent you are welcome to not respond. You will cycle through this multiple times. At the end, please write a small reflection about: 1) as a respondent, how you felt answering these questions and the implications that you think this feeling may have for how survey questions are answered more generally; and 2) as a questioner, how difficult it was to code responses and the implications this may have for the dataset that we analyse.\n\nWeek 4\n‘Stratified, systematic, and cluster sampling’\nContent: Stratified, systematic, and cluster sampling\nLab:\nFollowing the guidance of the TA, please read about the Canadian General Social Survey: https://www150.statcan.gc.ca/n1/pub/89f0115x/89f0115x2019001-eng.htm and then:\nDiscuss its key features, strengths, and weaknesses generally.\nLook at the questionnaire - what is good and bad about it?\nHow do they find people to take the survey?\nWhat do they do about non-response?\n\nFollowing the guidance of the TA, please identify a GSS dataset that you are interested in and then:\nLook at a specific question that is asked.\nSimulate the responses that you expect.\nDownload the dataset.\nConduct some exploratory data analysis.\nDiscuss how your expectations compare with reality.\n\n\nWeek 5\n‘Gathering data’.\nContent: Gathering data.\nCase Study: Student Coaching: How Far Can Technology Go?\nLab:\nPlease pretend you work for Netflix and you want to know more about why people subscribe (or don’t!) when prices change. Please design an experiment, discuss its key features and how you would implement it. Please pay special attention to sampling issues. Then simulate an outcome.\nFollowing the guidance of the TA, please scrape some data and discuss some ethical considerations around the dataset that you created. You may like to write a short blog post discussing the difference between data being public but scattered, and a consolidated dataset being public with reference to Kirkegaard and Bjerrekær, 2016, and Politou, Alepis, and Patsakis, 2018 (if you do that please do email a link to me out of interest).\n\nWeek 6\n‘Whoops, I forgot EDA’.\nContent: Exploratory Data Analysis.\nCase Study: Civic honesty around the globe\nLab:\nPretend that you work for Loblaws as a data scientist and it is late March 2020. As part of normal monitoring, you have noticed that purchases of flour and pasta have increased substantially. You had been planning to increase the price of these items in April as part of a trial, but now your manager is not sure whether it is appropriate to conduct the trial. Please write five or six points with regard to your thoughts on this matter. What would you do and why?\nAnalyse the Toronto AirBNB dataset with guidance from the TA.\n\nWeek 7\n‘IJALM - It’s Just A Linear Model’.\nContent: Linear and logistic regression and tidymodels\nCase Study: Upworthy A/B tests of headlines.\nSpecial guest: Kathy Ge on experiments at Uber.\nLab recording:\nFollowing the guidance of the TA, please use Blogdown to create a simple website and then design and execute a simple A/B test for your website using Netlify.\n\nWeek 8\n‘Celestial Navigation’.\nContent: Simulation, power, RCTs, A/B testing.\nCase Study: Please pick one chapter from Catherine D’Ignazio and Lauren F. Klein, Data Feminism, that is of interest to you and read it (freely available: https://data-feminism.mitpress.mit.edu).\nLab:\nFollowing the guidance of the TA, please make a Shiny app that bundles a little data and some code and post it to shinyapps.com.\n\nWeek 9\n‘Multilevel regression with post-stratification’\nLecture: MRP.\nCase Study: Xbox paper\nLab: Use MRP to forecast the 2020 US presidential election.\nWeek 10\n‘Such a shame they’ll never meet’.\nContent: Matching and difference in differences.\nCase Study: Funding of Clinical Trials and Reported Drug Efficacy\nSpecial guest: Emily Riederer on observational causal inference.\nSpecial guest: Tamar Oostrom on funding of clinical trials.\nLab:\nFollowing the guidance of the TA, please look at McClelland, Alexander, 2019, ‘“Lock This Whore Up”: Legal Violence and Flows of Information Precipitating Personal Violence against People Criminalised for HIV-Related Crimes in Canada’, European Journal of Risk Regulation, 10 (1), pp. 132-147.\nThen look at Policing the Pandemic - https://www.policingthepandemic.ca/. Look into how they gathered their dataset and what it took to put this together. What is in the dataset and why? What is missing and why? How could this affect the results? How might similar biases enter into other datasets that you have used or read about?\nPut together a brief model. You may like to write a short blog post about the biases and influences that are in this dataset (if you do that please do email a link to me out of interest).\n\nWeek 11\n‘Why does it always rain on me?’.\nContent: Regression discontinuity and instrumental variables.\nCase Study:\nJames H. Ware, 1989, ‘Investigating Therapies of Potentially Great Benefit: ECMO’, Statistical Science, available here.\nDonald A. Berry, 1989, ‘Comment: Ethics and ECMO’, Statistical Science, available here.\n\nLab:\nFollowing the guidance of the TA, please make an R package that bundles a little data and some code and add it to your GitHub. Don’t forget to include at least one test.\n\nWeek 12\n‘Lorem ipsum’.\nContent: Text-as-data.\nCase Study: Kevin Munger, Patrick Egan, Jonathan Nagler, Jonathan Ronen, and Joshua A. Tucker, 2017, ‘Political Knowledge and Misinformation in the Era of Social Media: Evidence From the 2015 UK Election’.\nLab:\nPlease form small groups and discuss, ‘to what extent do quantitative methods merely project forward the past, and what implications does this have for our conduct as practitioners and consumers?’\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nWeekly quiz\n20\nWeekly before the lecture\nProfessional conduct\n3\nAnytime during the teaching term\nPaper 1\n24\nEnd of Week 3\nPaper 2\n24\nEnd of Week 6\nPaper 3\n24\nEnd of Week 9\nFinal Paper (initial submission)\n1\nEnd of Week 12\nFinal Paper (peer review)\n3\nThree days after that\nFinal Paper\n25\nTen days after that\nWeekly quizzes\nDue date: Weekly before the lecture.\nWeight: 20 per cent (no quiz in Week 1 or Week 12 and only best eight out of ten count.)\nTask: Please complete a weekly quiz in Quercus.\nQuestions: The questions that form the quiz are drawn from those in the course notes.\nProfessional conduct\nDue date: Anytime during the teaching term.\nWeight: 3 per cent\nTask:\nWe (optionally) use Slack to interact in this class. At some point during the teaching term, please use Slack to answer another student’s question or otherwise similarly be generally helpful in a professional manner. When you do that, please share the comment into the ‘Professional conduct’ channel and @ me (hover on the message, click share message, type in the channel ‘profession_conduct’, add a message that @‘s me, and click ’share’). You’ll get the full mark just for one helpful interaction. (If you are opting out of using Slack - which is entirely fine - then instead, at some point in the term send me an email with a link that is relevant to the course materials and that I should add to the course notes. Please be clear that this is your ‘professional conduct’ submission by stating that in the subject line.)\nIt will not be possible to get any of this mark if you behave unprofessionally at all during the term. That includes abusive/rude emails/messages.\n\nPaper #1\nDue date: End of Week 3.\nWeight: 24 per cent (for Papers #1-#3 the best two of three count).\nTask: ‘Mandatory minimums’\nPaper #2\nDue date: End of Week 6.\nWeight: 24 per cent (for Papers #1-#3 the best two of three counts).\nTask: ‘Mr Willis of Ohio’\nPaper #3\nDue date: End of Week 9.\nWeight: 24 per cent (for Papers #1-#3 the best two of three counts).\nTask: ‘Five Votes Down’\nFinal Paper\nDue dates:\nInitial submission: End of Week 12.\nPeer review: Three days after that.\nFinal Paper: Ten days after that.\n\nWeight: 29 per cent (4 per cent of this is for initial submission and peer review conducted a week before).\nInitial submission: 1 per cent\nPeer review: 3 per cent\nFinal Paper: 25 per cent\n\nTask: ‘What’s next’\n\n\n\n",
      "last_modified": "2021-10-13T20:59:29-04:00"
    },
    {
      "path": "teaching.html",
      "title": "Teaching",
      "description": "My teaching is informed not only by my time in academia, but also by my experience working at my own start-up and in government. My approach is best characterised as practical, research-based, and emphasising workflow. I am an [RStudio Certified Tidyverse Trainer](https://education.rstudio.com/trainers) and I enjoy teaching students from a wide range of backgrounds. I co-lead the development of a package to help students learn R, available here: [DoSS Toolkit](https://www.dosstoolkit.com). My book, *[Telling Stories with Data](https://www.tellingstorieswithdata.com/)* supports my teaching.\n",
      "author": [],
      "contents": "\n\nContents\nCourse material\nTeaching experience\n\nCourse material\nI have designed and taught the following courses:\nExperimental Design\nSurveys, Sampling and Observational Data\nEthics and Data Science\nNatural Language Processing\nFoundations of the Data Sciences\nThe Other Course\nHistory of the Data Sciences\nTeaching experience\nUniversity of Toronto\n(Upcoming) Instructor, ‘STA304: Surveys, Sampling and Observational Data’, Department of Statistical Sciences, Winter 2022.\n(Upcoming) Instructor, ‘INF312: Worlds Become Data’, Winter 2022.\nInstructor, ‘INF2178: Experimental Design for Data Science’, Faculty of Information, Winter 2021\nInstructor, ‘STA304: Surveys, Sampling and Observational Data’, Department of Statistical Sciences, Fall 2020, evaluations\nInstructor, ‘INF2178: Experimental Design for Data Science’, Faculty of Information, Winter 2020, evaluations\nAustralian National University\nTutor, Macroeconomics 3, Semester 2, 2017, evaluations\nTutor, Microeconomics 3, Semester 1, 2017, evaluations\nTutor, Behavioural Economics, Semester 2, 2015, evaluations\nTutor, Business Economics, Semester 1, 2015, evaluations\nTutor, Microeconomics 1, Semester 1, 2013, evaluations\nTutor, Foundations of Economic and Financial Models, Semester 2, 2012\nUniversity of Queensland\nTutor, Microeconomic Policy, Semester 2, 2008\nTutor, Microeconomic Theory, Semester 1, 2008\nTutor, Introductory Microeconomics, Semester 2, 2007\nTutor, Introductory Microeconomics, Semester 1, 2007\nShort courses and workshops\nInstructor, Improving Representation of non-representative samples: Multilevel Regression with Post-stratification\nUniversity of Toronto, Department of Sociology, Social Science Methods Week 2021, 28 April 2021.\n\nInstructor, Gathering data\nWilfrid Laurier University, Laurier Institute for the Study of Public Opinion and Policy, 15 January 2021, https://youtu.be/XzZbEh6aO40.\n\nInstructor, Getting started with R\nUniversity of Toronto, Undergraduate Global Society for Genetics and Genome Biology, 22 December 2020.\n\nInstructor, Gathering Data from Messy Sources\nUniversity of Toronto, Independent Summer Statistics Community, 22 May 2020.\n\nInstructor, Getting started with MRP\nAustralian National University, 3 December 2019.\n\nInstructor, Introduction to Blogdown\nAustralian National University, RSE, 21 July 2017.\n\nInstructor, Introduction to LaTeX\nAustralian National University, RSE, 13 September 2017.\nAustralian National University, RSE, 3 May 2016.\n\n",
      "last_modified": "2021-10-13T20:59:30-04:00"
    },
    {
      "path": "the_other_course.html",
      "title": "The Other Course",
      "description": "This is a course that improves your skills in data science and gives you the space to write a paper within certain guardrails.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nCourse learning objectives\nPre-requisites\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nLearning diary\nPresentation I\nPresentation II\nPresentation III\nFinal Paper\n\n\nPreamble\nOverview\nThe course will be an enormous amount of work and cause you a large amount of stress because it is likely your first opportunity to do unstructured original research. This is unfortunate, but there’s little way around it. All I can tell you is that having done this course, it’ll be easier in the future. And pressure makes diamonds.\nThe purpose of this course is to write an original research paper, and in the process of that, to learn some useful skills. The paper will incorporate relevant literature, detailed data collection processes, be reproducible, use technically and statistically sound methodology, and present the outcomes in an informative manner. The work is divided into two parts, a report describing the relevant background and technical processes (an R Markdown produced pdf) and an interactive layer (either Shiny or an R Package).\nThe purpose of this course is to explore the technical aspects required to design and complete an end-to-end data science project, similar to those that students are likely to encounter in a professional environment. This course will require students to:\nGather data through scraping and the use of APIs.\nDesign supporting architecture to allow the data to gather over time.\nDevelop machine learning models describing the statistical relationship between variables within the dataset.\nTest the outcomes with new data to examine machine learning prediction veracity.\nPresent the outcomes of a highly specific concept in a meaningful manner to a non-technical audience.\nEssentially this course provides students with the freedom to conduct original research on a topic of interest to them within certain guidelines.\nFAQ\nCan I audit this course? No. It’s a reading course so the concept of auditing doesn’t make sense.\nCan I attend lectures? No. There are no lectures. Students update their GitHub repo on a weekly basis and we meet the next day to talk through things.\nCourse learning objectives\nCollect real-world data and design systems to allow for the dataset to continuously grow.\nRefine R skills.\nClean, manage, analyze, and make predictions with data towards the project goal.\nExplore and implement modelling options and explore relevant assumptions.\nExplore relationships within data\nDesign an interactive Shiny app or R Package for presentation of the results and to allow the model to be deployed and used by others.\nHave a high-quality project to show the culmination of learning.\nPre-requisites\nYou need to have taken ‘The Course’ or equivalent, such that you’ve taken courses such that you’ve covered everything through to (but not including) ‘Enrichment’ of Telling Stories with Data.\nAcknowledgements\nThanks to the following who helped develop this course: Thomas William Rosenthal.\nContent\nWeek 1\nTasks:\nCreate research plan.\nConduct initial literature review.\nAddress any weaknesses in version control.\nReadings:\nKing, Gary, ‘How to Write a Publishable Paper as a Class Project’, https://gking.harvard.edu/papers.\nShapiro, Jesse, ‘Four Steps to an Applied Micro Paper’, https://www.brown.edu/Research/Shapiro/pdfs/foursteps.pdf.\nRiederer, Emily, ‘RMarkdown Driven Development (RmdDD)’, https://emilyriederer.netlify.com/post/rmarkdown-driven-development/.\nMiyakawa, Tsuyoshi, ‘No raw data, no science: another possible source of the reproducibility crisis’, Molecular Brain, https://doi.org/10.1186/s13041-020-0552-2.\nBryan, Jenny, Happy Git and GitHub for the useR, https://happygitwithr.com.\nWeek 2\nTasks:\nContinue literature review.\nIdentify relevant data.\nMake first Shiny app.\nSetup GitHub Repo, with appropriate folder structure and README.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters 2-5.\nJesse Shapiro, ‘Code and Data for the Social Sciences: A Practitioner’s Guide’, https://web.stanford.edu/~gentzkow/research/CodeAndData.xhtml\nWeek 3\nTasks:\nGather data:\nBuild initial webscrapers.\nBuild simulated dataset.\n\nFinalize literature review.\nBegin automating.\nReadings:\nCouch, Simon, ‘Running R Scripts on a Schedule with GitHub Actions’, https://blog.simonpcouch.com/blog/r-github-actions-commit/.\nWickham, Hadley, 2020, Mastering Shiny, Chapters 2-5\nWeek 4\nTasks:\nDevelop basic infrastructure for housing data.\nSet-up GitHub actions to automate gathering and cleaning.\nEstablish data pipeline to update analysis dataset.\nWrite tests against the simulated clean dataset.\nWeek 5\nTasks:\nMake second Shiny app.\nBuild first R package.\nBegin cleaning dataset toward passing tests.\nContinue automating data gathering.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters 8-9, https://mastering-shiny.org/action-feedback.html.\nWickham, Hadley and Jenny Bryan, R Packages, Chapter 2, https://r-pkgs.org/whole-game.html.\nWeek 6\nTasks:\nFinish any data pipeline/architecture development.\nPrepare data for modelling:\nEDA.\nFully incorporate all datasources.\nFurther cleaning if necessary.\n\nDetermine features of interest.\nContinue developing statistics skills.\nFamiliarize with tidymodels.\nReadings:\nKuhn, Max, and Julia Silge, 2021, Tidy Modeling with R, Chapters 1-5.\nWickham, Hadley, and Garrett Grolemund, 2017, R for Data Science, Chapters 2-8.\nGareth M. James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, 2021, An Introduction to Statistical Learning, Second Edition, Chapters 1-4.\nWeek 7\nTasks:\nBuild model with tidymodels or alternative approach.\nBuild a second R package that is more involved.\nContinue developing statistics skills, including Bayesian methods.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R, Chapters 6-7.\nWickham, Hadley, and Garrett Grolemund, 2017, R for Data Science, Chapters 22-25.\nGareth M. James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, 2021, An Introduction to Statistical Learning, Second Edition, Chapters 5-7.\nMcElreath, Richard, 2020, Statistical Rethinking, Second edition, Chapters 1-4.\nWeek 8\nTasks:\nContinue machine learning development\nExplore, script, and compare different machine learning algorithm performance\nFinalize model development and evaluate results.\nBuild third Shiny app.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R, Chapters 8-9.\nWickham, Hadley, 2020, Mastering Shiny, Chapters 10-12.\nMcElreath, Richard, 2020, Statistical Rethinking, Second edition, Chapters 5-6.\nWeek 9\nTasks:\nContinue improving model and pipeline, especially model evaluation and refinement with data augmentation.\nContinue developing statistics skills.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R, Chapters 10-12.\nMcElreath, Richard, 2020, Statistical Rethinking, Second edition, Chapters 7-8.\nWeek 10\nTasks:\nBegin write-up of paper, especially data and model sections.\nBegin developing R package or Shiny app\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R, Chapters 13-14.\nMcElreath, Richard, 2020, Statistical Rethinking, Second edition, Chapters 11-13.\nWeek 11\nTasks:\nContinue write-up, especially results and discussion sections.\nFinish developing R package or Shiny app.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters 13-16.\nMcElreath, Richard, 2020, Statistical Rethinking, Second edition, Chapters 14-16.\nWeek 12\nFinalise all apsects.\nTasks:\nAs needed.\nAssessment\nLearning diary\nTask: Each week you will read relevant papers and books, engaging with them by writing notes and completing exercises. You will use GitHub to manage these notes and exercises and email a link to me at the end of each week. Additionally, reflect on what went well, what has room for improvement, and consider ‘lessons learned’ during the week.\nDate: At the end of the week please send me a link to the GitHub repo that contains this diary.\nWeight: 15 per cent.\nPresentation I\nTask: 10-15-minute presentation on what you’ve learned about the literature and plans.\nDate: Roughly end of Week 4 (exact date determined by lab presentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nPresentation II\nTask: 10-15-minute presentation on what you’ve learned about the data.\nDate: Roughly end of Week 8 (exact date determined by lab presentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nPresentation III\nTask: 10-15-minute presentation on what you’ve learned about the model.\nDate: Roughly end of Week 12 (exact date determined by lab presentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nFinal Paper\nTask: A fully reproducible paper and associated Shiny app or R Package. Toward the mid-term break we will have a meeting to discuss the topic of your final paper. It will be due on the last day of the exam period. This will be marked by me and reviewed by another professor.\nDate: Second last day of exam period.\nWeight: 40 per cent.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:30-04:00"
    },
    {
      "path": "toronto_data_workshop-stipends.html",
      "title": "Toronto Data Workshop Stipends",
      "author": [],
      "contents": "\nFor their support of these stipends we thank: Dean Wendy Duff and the Faculty of Information; and Department Chair Radu Craiu and the Department of Statistical Sciences.\nCall for applications\n16 June 2020\nKelly Lyons and Rohan Alexander are announcing three research stipends, each of $1,000, for University of Toronto students or recent graduates who identify as a member of a visible minority group, racialized group, or as a person of colour. The successful applicants will be invited to prepare a research paper on a topic of their choice under the supervision of a faculty mentor, and will be given the opportunity to present their paper at a meeting of the Toronto Data Workshop that suits their research timetable.\nIf you are interested in applying for this training opportunity please email rohan.alexander@utoronto.ca, by the end of Tuesday 30 June 2020, attaching a single PDF that contains:\nA brief (1 page) overview of what your paper will be about. Some aspect of this paper should involve real-world data and quantitative analysis. Strong applications will include: a specific and important research question; evidence of some developed ideas around data sources and methodology; and a clear motivation.\nYour CV. Strong applications will demonstrate potential through their grades, and by reference to projects on GitHub or similar.\nThe name of a University of Toronto faculty member who has agreed to supervise this work.\nYou are welcome to find your own supervisor for this training opportunity, but if you do not have a faculty supervisor already, and do not feel comfortable asking someone, then any of the following current or future faculty are more than happy to supervise you, and you should get in touch with one that matches your interests:\nJesse Gronsbell (Statistics)\nKelly Lyons (Information)\nLiza Bolton (Statistics)\nMonica Alexander (Statistics and Sociology)\nRohan Alexander (Information and Statistics)\nVianey Leos Barajas (Statistics and Environment)\nIf you have any questions about your application, then please email rohan.alexander@utoronto.ca before the closing date.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:31-04:00"
    },
    {
      "path": "toronto_data_workshop.html",
      "title": "Toronto Data Workshop",
      "description": "We share best practice for data science, and are especially interested in the data munging/cleaning/prep/comms stages that folks typically don't talk about. We meet for an hour each week and are interested in anything that is data-focused across academia and industry. Typically, Fridays at noon (Toronto time) via Zoom, with most talks recorded and shared. All welcome. Free. Sign up [here](https://forms.gle/sXbEixoa1iJR4Q7A8).\n",
      "author": [],
      "contents": "\n\nContents\nOverview\nCurrent schedule\nPast schedules\n\n\n\n\nOverview\nThe Toronto Data Workshop (TDW) brings together academia and industry to consider, collate, share, and disseminate best practices in doing data science, especially in the data-centric steps of a data science project: collection; cleaning; storage; retrieval; dissemination; protection; and communication. We meet weekly for an hour and aim to have a roughly even split of participants from academia and industry over the course of each term. For an invitation please sign up here. Anyone is welcome to attend - you don’t need to be affiliated with the university.\nCurrent organising committee:\nAmy Farrow,\nKelly Lyons,\nLorena Almaraz De La Garza, and\nRohan Alexander.\nPast committee members:\nFaria Khandaker.\nThe TDW is a joint initiative between the Faculty of Information and the Department of Statistical Sciences at the University of Toronto and we especially thank Dean Wendy Duff and Chair Radu Craiu for their support.\nCurrent schedule\nFall 2021\n\n\n\nThis term is mostly a special series of talks featuring University of Toronto speakers on the relationship between data science and their other field of expertise.\nDate\nSpeaker\n\nFri 24 Sep 2021, noon - 1pm\nKaren Chapple, Geography, planning, cities\nhttps://youtu.be/rNRwOStrb9o\nFri 1 Oct 2021, noon - 1pm\nSpecial on 2021 Canadian Election\nhttps://youtu.be/pCwJXgR7V5k\nFri 8 Oct 2021, noon - 1pm\nFedor Dokshin, Sociology\nhttps://youtu.be/QjTsDbH6MxM\nFri 15 Oct 2021, noon - 1pm\nDrew Stommes, Yale University\n\nFri 22 Oct 2021, noon - 1pm\nTegan Maharaj, Information\n\nFri 29 Oct 2021, noon - 1pm\nJosh Speagle, Astronomy\n\nFri 5 Nov 2021, noon - 1pm\nYun William Yu, Math\n\nFri 12 Nov 2021, noon - 1pm\nReading Week\n\nFri 19 Nov 2021, noon - 1pm\nRadu Craiu, Statistical Sciences\n\nFri 26 Nov 2021, noon - 1pm\nKieran Campbell, Biomedicine\n\nFri 3 Dec 2021, noon - 1pm\nLeanne Trimble, Libraries\n\nFri 10 Dec 2021, noon - 1pm\nNathan Taback, Teaching\n\nFriday, 24 September 2021, noon - 1pmKaren Chapple, Department of Geography and Planning/School of CitiesKaren Chapple is the inaugural Director of the School of Cities and Professor of Geography and Planning at the University of Toronto. Her research uses data science methods to identify and predict gentrification and displacement in cities. She is Professor Emerita at the University of California, Berkeley, where she helped to launch the undergraduate data science program.\nFriday, 1 October 2021, noon - 1pmSpecial meeting on 2021 Canadian Election\nDiscussion and presentations by:\nProfessor David Andrews on elections forecasting.\nProfessor Daniel Rubenson on the Canadian Election Study.\nJohnson Vo on his model of the 2021 election.\nEric Zhu, Brian Diep, Ashely (Jing Yuan) Zhang, Kristin (Xi Yu Huang), and Tanvir Hyder on their model of the 2021 election.\n\nFriday, 8 October 2021, noon - 1pmFedor Dokshin, Department of SociologyFedor Dokshin is an Assistant Professor of Sociology at the University of Toronto. He is a computational social scientist with research interests in social networks, organizations, and energy and the environment. Across these domains, Fedor leverages data science methods and novel data sources to improve existing measurement strategies.\nFriday, 15 October 2021, noon - 1pmDrew Stommes, Department of Political Science, Yale UniversityDrew Stommes is a doctoral candidate in the Department of Political Science at Yale University, where he researches democracy, political violence, and quantitative methods. He will talk about a recent working paper, ‘On the reliability of published findings using the regression discontinuity design in political science’.\nFriday, 22 October 2021, noon - 1pmTegan Maharaj, Faculty of Information\nI study AI systems and “what goes into” them, e.g. their real-world deployment context, and the effects that has on learning behaviour and generalization. I do that because I want to be able to use AI systems responsibly for problems I think are important, like impact and risk assessments for climate change, AI alignment, ecological management and other common-good problems. My website is: teganmaharaj.org.\nFriday, 29 October 2021, noon - 1pmJosh Speagle, Astronomy & Astrophysics, Dunlap Institute, Statistical SciencesJosh is a Banting & Dunlap Postdoctoral Fellow at the University of Toronto whose research focuses on using astrostatistics and “data science” to understand how galaxies like our own Milky Way form, behave, and evolve.\nFriday, 5 November 2021, noon - 1pmYun William, Yu Math Department, UofT; UTSC Computer & Mathematical SciencesYun William Yu is an assistant professor in the math department at UofT whose research focuses on algorithmic methods for computational biology and medical informatics.\nFriday, 12 November 2021, noon - 1pmReading Week\nFriday, 19 November 2021, noon - 1pmRadu Craiu, Statistical Sciences @ U of TDr. Radu V. Craiu is Professor and Chair of Statistical Sciences at the University of Toronto. His main research interests are in computational methods in statistics, especially, Markov chain Monte Carlo algorithms (MCMC), Bayesian inference, copula models, model selection procedures and statistical genetics.\nFriday, 26 November 2021, noon - 1pmKieran Campbell, Lunenfeld Tanenbaum Research InstituteDr. Kieran Campbell is an investigator at the Lunenfeld-Tanenbaum Research Institute and an assistant professor at the Departments of Molecular Genetics and Statistical Sciences, University of Toronto. His research focusses on Bayesian models and machine learning for high dimensional biomedical data, including single-cell and cancer genomics. Recently, he has led efforts to develop statistical machine learning methodology to integrate single-cell RNA and DNA sequencing data to uncover the effects of tumour clonal identity on gene expression, as well as methods to automatically delineate the tumour microenvironment from single-cell RNA-sequencing data. Such findings can improve our understanding of cancer progression and of why certain tumours are resistant to therapies, leading to relapse.\nFriday, 3 December 2021, noon - 1pmLeanne Trimble, UofT Libraries\nLeanne Trimble is a data librarian at the Map & Data Library, University of Toronto Libraries.\nFriday, 10 December 2021, noon - 1pmNathan Taback, Departments of Statistical SciencesNathan Taback is the director of Data Science programs and an Associate Professor, Teaching Stream in the Department of Statistical Sciences, and Computer Science (cross-appointed) at the University of Toronto. He currently serves as a Special Advisor to the Dean of Arts and Science on Computational and Data Science Education.\nPast schedules\nSummer 2021\n\n\n\nDate\nSpeaker\nTopic\nRecording\nFri 21 May 2021, noon-1pm\nDavid Shor, OpenLabs\nPolitical data science.\nhttps://youtu.be/_IEPKapa9_0\nFri 28 May 2021, noon-1pm\nSamantha Pierre, University of Toronto\nThe Effects of a Tony Award.\nhttps://youtu.be/rFojvBN0qGk\nFri 4 June 2021, noon-1pm\nHeather Krause, We All Count\nEquity in data.\nhttps://youtu.be/Yu_l8MpKK-E\nFri 11 June 2021, noon-1pm\nLaura Bronner, Data scientist\nQuantitative editing.\nhttps://youtu.be/LI5m9RzJgWc\nFri 18 June 2021, noon-1pm\nJacob Matson, Simetric, Inc.\nFrom data to dashboard.\nhttps://youtu.be/U8-6QKtWXCQ\nFri 25 June 2021, noon-1pm\nLaura Derksen, University of Toronto Mississauga (jointly hosted with the UTM Collaborative Digital Research Space.)\nEffect of Wikipedia\nhttps://youtu.be/Coz-HFesTsw\nFri 2 July 2021, noon-1pm\nZachary McCaw, Google\n-\n-\nFri 16 July 2021, noon-1pm\nKamilah Ebrahim, University of Toronto\nTrust in contact tracing apps.\nhttps://youtu.be/f_3bpEeRdhI\nFri 23 July 2021, noon-1pm\nAnnie Collins & Rohan Alexander, University of Toronto\nReproducibility of COVID-19 pre-prints\nhttps://youtu.be/_ncpTbhe8qA\nFri 30 July 2021, noon-1pm\nKeli Chiu, University of Toronto\nDetecting and explaining sexist and racist text with GPT-3\nhttps://youtu.be/xmmoVD5zTOQ\nFri 6 August 2021, 12:30-1:30pm\nIjeamaka Anyene, Kaiser Permanente Division of Research\nTaking the next step past standard charts.\nhttps://youtu.be/LlVf8foXUmM\nFri 13 August 2021, noon-1pm\nStudents from the Independent Summer Statistics Community\nAnalysis of Toronto data\nhttps://youtu.be/zkuMedB23f8\nFri 20 August 2021, noon-1pm\nStudents from Vianey Leos Barajas’ research group, University of Toronto\nSharks, lizards, and basketball!\nhttps://youtu.be/p697exbcMZE\nFriday, 21 May 2021, Noon - 1pmDavid Shor, OpenLabs, \nBio: David is an American data scientist who tries to elect Democrats. He is known for analyzing political polls and currently serves as head of data science with OpenLabs, a progressive nonprofit, and also as a Senior Fellow with the Center for American Progress Action Fund.\nTopic: Political data science.\nRecording: https://youtu.be/_IEPKapa9_0\nFriday, 28 May 2021, Noon - 1pmSamantha Pierre, University of Toronto, \nBio: Samantha is a fourth-year statistics student studying at the University of Toronto. Throughout the past year she has combined her love for theatre and statistics to analyze trends in the theatre community. She volunteers as a member of PAIR-CG to create a representational framework for the international theatre community. She currently works at WOMBO, an app developed by former U of T students, as head of music content.\nTopic: And The Nominees Are… An Empirical Study of the Effects of a Tony Award Win and Nomination on a Show’s Success.\nRecording: https://youtu.be/rFojvBN0qGk\nFriday, 4 June 2021, Noon - 1pmHeather Krause, We All Count, \nBio: Heather remains unconvinced. As a statistician with decades of global experience working on complex data problems and producing real-world knowledge, she has developed the Data Equity Framework to address the equity issues in data products and research projects. Her emphasis is on combining strong statistical analysis with clear and meaningful communication. She is currently working on implementing tools for equity and ethics in data. As the founder of two successful data science companies, she attacks the largest questions facing societies today, working with both civic and corporate organizations to improve outcomes and lives. Her relentless pursuit of clarity and realism in these projects pushed her beyond pure analysis to mastering the entire data ecosystem including award-winning work in data sourcing, modeling, and data storytelling, each incorporating bleeding edge theory and technologies. Heather is the founder of We All Count, a project for equity in data working with teams across the globe to embed a lens of ethics into their data products from funding to data collection to statistical analysis and algorithmic accountability. Her unique set of tools and contributions have been sought across a range of clients from MasterCard and Volkswagen to the United Nations, the Syrian Refugee Resettlement Secretariat, Airbnb, and the Bill and Melinda Gates Foundation. She is on the Data Advisory Board of the UNHCR.\nTopic: Equity in Data (or, how not to accidentally use data like a racist, sexist, colonialist, etc).\nRecording: https://youtu.be/Yu_l8MpKK-E\nFriday, 11 June 2021, Noon - 1pmLaura Bronner, Data scientist, \nBio: Laura is a data scientist, who most recently worked as the quantitative editor at FiveThirtyEight. More generally, she is a data scientist with an interest in causal inference, political science and quantitative text analysis. Before FiveThirtyEight, she was a Senior Analyst at the Analyst Institute, designing and analyzing field experiments for the 2018 election cycle. In September 2018, she completed a PhD in Political Science at the London School of Economics’ Department of Government.\nTopic: Quantitative editing.\nRecording: https://youtu.be/LI5m9RzJgWc\nFriday, 18 June 2021, Noon - 1pmJacob Matson, Simetric, \nBio: Jacob is VP of Finance & Operations at Simetric, Inc..\nTopic: From data ask to dashboard.\nRecording: https://youtu.be/U8-6QKtWXCQ\nFriday, 25 June 2021, Noon - 1pmLaura Derksen, University of Toronto Mississauga, \nBio: Laura is the Amgen Canada Professor in Health System Strategy at the University of Toronto Mississauga and assistant professor in Strategic Management at the Rotman School of Management. Her research interests are development and global health education, information and networks.\nTopic: The impact of student access to Wikipedia. Recording: https://youtu.be/Coz-HFesTsw\nFriday, 2 July 2021, Noon - 1pmZachary McCaw, Google\nBio: Zachary McCaw is a data scientist at Google.\nFriday, 16 July 2021, Noon - 1pmKamilah Ebrahim, University of Toronto, \nBio: Kamilah Ebrahim received a B.A. in Economics from the University of Waterloo in 2019 and is currently pursuing a Masters of Information in Human Centred Data Science at the University of Toronto. Kamilah is a 2020-21 Graduate Fellow at the University of Toronto Centre for Ethics focusing on the intersection between race, economics and data monopolies in Canada. Prior to joining the University of Toronto she held roles at the United Nation Economic and Social Commission for Asia and the Pacific (UN ESCAP), as well as the Canadian federal government.\nTopic: Trust in contact tracing apps.\nRecording: https://youtu.be/f_3bpEeRdhI\nFriday, 23 July 2021, Noon - 1pmAnnie Collins & Rohan Alexander, University of Toronto\nBio: Annie Collins is an undergraduate student at the University of Toronto specializing in applied mathematics and statistics with a minor in history and philosophy of science. In her free time, she focusses her efforts on student governance, promoting women’s representation in STEM, and working with data in the non-profit and charitable sector. Rohan Alexander is an assistant professor at the University of Toronto in Information and Statistical Sciences, and a faculty affiliate at the Schwartz Reisman Institute for Technology and Society. He holds a PhD in Economics from the Australian National University.\nTopic: Reproducibility of COVID-19 pre-prints.\nRecording: https://youtu.be/_ncpTbhe8qA\nFriday, 30 July 2021, Noon - 1pmKeli Chiu, University of Toronto\nBio: Keli Chiu is a recent graduate of master in Information at the University of Toronto with the concentration in Human-Centred Data Science. Prior to pursuing her master in the information fields, she worked as a web developer and fell in love with data. Her research interests are natural language processing applications, text analysis and ethics in AI and machine learning. She received rstudio::global Diversity Scholarships in the year of 2021.\nTopic: Detecting sexist and racist text contents with explanations accompanied with GPT-3\nRecording: https://youtu.be/xmmoVD5zTOQ\nFriday, 6 August 2021, 12:30pm - 1pmIjeamaka Anyene, Kaiser Permanente Division of Research, \nBio: Ijeamaka is a data analyst working in healthcare research. She specializes in using R and SAS for data analysis, epidemiological research, and data visualizations. She is also passionate about computational art, knowledge sharing / dissemination, and how to mix the two.\nTopic: Taking the next step past standard charts.\nRecording: https://youtu.be/LlVf8foXUmM\nFriday, 13 August 2021, Noon - 1pmStudent groups from the Independent Summer Statistics Community, University of Toronto\n‘Prospective Analytics’ comprised of Ashley Zhang, Eric Zhu, Muhammad Tsany and Sergio Zheng Zhou.\n‘Statistically Significant’ comprised of Aliza Lakho, Chloris Jiang, Janhavi Agarwal, and José Casas on whether young professionals should move to Toronto.\n‘Point Zero Five’ comprised of Pan Chen, Xiaoxuan Han, Yi Qin, and Yini Mao on the livability of Toronto for newcomers.\nRecording: https://youtu.be/zkuMedB23f8\nFriday, 20 August 2021, Noon - 1pmStudents from Vianey Leos Barajas’ research group, University of Toronto\nBio: Jessica Long, Simone Collier, Vinky Wang, Sophie Berkowitz, and Yun-Hsiang Chan are undergraduate students at the University of Toronto.\nTopic: The presentations will use statistical model to analyzing shark, lizard, and basketball movement data. The data was collected through drones, accelerometers or video tracking software.\nRecording: https://youtu.be/p697exbcMZE\nWinter 2021\n\n\n\nThanks to Paul Hodgetts for the Jays-inspired sticker.\nDate\nSpeaker\nTopic\nRecording\nThu 14 Jan, 4:30-5:30pm\nAndrew Miles, University of Toronto (jointly hosted with the UTM Collaborative Digital Research Space.)\nCode, plots, and values\nhttps://youtu.be/mdjOoKT-f7E\nWed 20 Jan, 4:30-5:30pm\nZia Babar, University of Toronto\nDerivative data security.\nhttps://youtu.be/fdVZqvECXXQ\nThu 28 Jan, 4:30-5:30pm\nIrene Duah-Kessie, University of Toronto\nBias and fairness in health.\nhttps://youtu.be/xwWvOeSXu5o\nThu 4 Feb, 4:30-5:30pm\nKathy Ge, Uber\nExperimentation and product design.\nhttps://youtu.be/UYzXElJTovg\nThu 11 Feb, 4:30-5:30pm\nGarrick Aden-Buie, R Studio\nUsing R Markdown.\nhttps://youtu.be/Hl798H6J-bg\nMon 15 Feb, Noon-1:00pm\nEmily Riederer, Capital One\nObservational causal inference.\nhttps://youtu.be/VP3BBZ7poc0\nThu 18 Feb, 4:30-5:30pm\nAnnie Collins, Haoluan Chen, Isaac Ehrlich, Mariam Walaa, Marija Pejcinovska, Mathew Wankiewicz, Michael Chong, Paul Hodgetts, Rohan Alexander, Samantha-Jo Caetano, Shirley Deng, and Yena Joo, University of Toronto\nDoSS toolkit launch.\nhttps://youtu.be/aeAXvW3K_wU\nThu 25 Feb, 9:00-5:30pm\nVarious\nToronto Workshop on Reproducibility\nSee here.\nFri 26 Feb, 9:00-5:30pm\nVarious\nToronto Workshop on Reproducibility\nSee here.\nThu 4 Mar, 4:30-5:30pm\nPetros Pechlivanoglou, The Hospital for Sick Children (SickKids) Research Institute\nSimulation and retrospective data for health economic decision making.\nhttps://youtu.be/-aZjLCPsO_w\nThu 11 Mar, 4:30-5:30pm\nLucas Cherkewski, Canadian Digital Service\nUsing publicly-available data.\nhttps://youtu.be/6vDedpF0lfg\nMon 15 Mar, 4:00-5:00pm\nTodd Feathers, Freelance reporter\nAlgorithmic fairness in universities. (jointly hosted with Maryclare Griffin)\nhttps://youtu.be/Hw5viOofnC0\nThu 18 Mar, 4:30-5:30pm\nSofia Ruiz Suarez, National University of Comahue\nAnimal tracking data.\nhttps://youtu.be/GMi5nLl4wos\nThu 25 Mar, 4:30-5:30pm\nAlex Cookson, Muse\nThe power of great datasets.\nhttps://youtu.be/E2aRKZczqKY\nThu 1 Apr, 4:30-5:30pm\nVik Pant, Natural Resources Canada\nIntegrating science & policy through DS & AI.\n-\nThu 8 Apr, 4:30-5:30pm\nFaria Khandaker, University of Toronto\n’Mining Process Models from Email Data.\nhttps://youtu.be/2M32PbclTnE\nThu 15 Apr, 4:30-5:30pm\nEmily A. Sellars, Yale University\nData issues in Mexican demographic history.\n\nThu 22 Apr, 4:30-5:30pm\nAimee Schwab-McCoy, Creighton University, Ashley Juavinett, UC San Diego, Chris Papalia, St. Andrew’s College, Samantha-Jo Caetano, University of Toronto\nPanel on teaching data-focused topics.\n\nThursday, 14 January, 4:30-5:30pmAndrew Miles, University of TorontoJointly hosted with Elizabeth Parke and the UTM Collaborative Digital Research Space.Andrew Miles is Assistant Professor of Sociology at the University of Toronto and Director of the Morality, Action, and Cognition Lab.\nTopic: Code, plots, and values.\nRecording: https://youtu.be/mdjOoKT-f7E\nWednesday, 20 January, 4:30-5:30pmZia Babar, University of Toronto\nZia Babar obtained his PhD from the University of Toronto where his research studies focused on the analysis and design of data-centered information systems for enabling enterprise transformation. He is engaged in a multi-year research engagement with IBM Research Labs and is a startup technical mentor at WeWork Labs. He is the organizer of technology meetup groups in both Toronto and Waterloo, and a course instructor at the Faculty of Information, University of Toronto.\nZia will provide a background on data security approaches, and a demonstration of machine learning and deep learning techniques that can be used for providing derivative data security.\nThursday, 28 January, 4:30-5:30pmIrene Duah-Kessie, University of Toronto\nIrene Duah-Kessie is a graduate of the University of Toronto’s Master of Science in Sustainability Management program. Throughout her studies, Irene published her research on racial income inequality in Toronto with the Wellesley Institute and is currently a part of the Turtle Island Journal of Indigenous Health Editorial Team. Irene is a Project Manager at Across Boundaries leading an initiative to address food security and mental health challenges in Toronto’s Black community. She is also the founder of Rise In STEM, a grassroots organization that aims to increase access to STEM learning opportunities in Black and marginalized communities.\nTopic: Exploring algorithmic bias and fairness and its impact on health outcomes faced by racialized communities.\nThursday, 4 February, 4:30-5:30pmKathy Ge, Uber\nKathy is a data scientist with Uber Eats primarily focused on the shopping experience including ranking and recommendations throughout the order flow. She received her M.Sc. in Computer Science and B.Sc in Computer Science and Statistics from the University of Toronto.\nTopic: How data insights and experimentation help drive product design and intelligent recommendations on the Uber Eats platform.\nThursday, 11 February, 4:30-5:30pmGarrick Aden-Buie, R StudioGarrick is a Data Science Educator at RStudio who lives in sunny St. Petersburg, Florida. His passion is combining creative coding with programming education, using code to build tools that teach coding to new and advanced R users alike. Like tidyexplain: a project that used ggplot2 and gganimate to reimagine database operations as colorful flying boxes instead of the typical Venn diagrams. Garrick has developed a number of open source addins and packages for RStudio—such regexplain, shrtcts and rsthemes—and is always easily distracted by projects that combine R Markdown and online learning or teaching.\nTopic: Using R Markdown in general and in some specific projects.\nMonday, 15 February, Noon-1:00pmEmily Riederer, Capital OneEmily is a Senior Analytics Manager at Capital One. Emily’s team focuses on reimagining analytical infrastructure by building data products, elevating business analysis with novel data sources and statistical methods, and providing consultation and training to partner teams.\nTopic: Causal design patterns for data analysts.\nThursday, 18 February, 4:30-5:30pmSpecial guest Bethany White (Department of Statistical Sciences).Annie Collins, Haoluan Chen, Isaac Ehrlich, Mariam Walaa, Marija Pejcinovska, Mathew Wankiewicz, Michael Chong, Paul Hodgetts, Rohan Alexander, Samantha-Jo Caetano, Shirley Deng, and Yena Joo, University of Toronto\nUniversity of Toronto DoSS toolkit launch.\nThe DoSS toolkit is a series of self-paced lessons that students can go through ahead of class, to achieve badges for various levels of accomplishment with R. Instructors can use the badges to work out the level of the class and either direct students to the toolkit to address deficiencies or cover missing aspects themselves.\nThursday, 25 February, 9:00-6:30pmVarious speakersToronto Workshop on Reproducibility\nFriday, 26 February, 8:00-6:00pmVarious speakersToronto Workshop on Reproducibility\nThursday, 4 March, 4:30-5:30pmPetros Pechlivanoglou, The Hospital for Sick Children (SickKids) Research Institute\nPetros Pechlivanoglou, PhD, is a Scientist at The Hospital for Sick Children (SickKids) Research Institute and an Assistant Professor at the University of Toronto, Institute of Health Policy Management and Evaluation. He studied economics in his native country, Greece, econometrics at the University of Groningen, the Netherlands and obtained a PhD in health econometrics from the same university. He completed a post-doctoral fellowship at the University of Toronto, within the Toronto Health Economics and Technology Assessment (THETA) Collaborative where he focused on methodological aspects around the application of decision analysis in health-care policy.\nPetros will talk about marrying simulation modeling and retrospective data for health economic decision making.\nThursday, 11 March, 4:30-5:30pmLucas Cherkewski, Canadian Digital ServiceLucas Cherkewski is a policy advisor at the Canadian Digital Service (CDS). He helps delivery teams improve government services. From that experience, he advises on structural changes to make better services the default. This work includes plenty of data-enabled research and analysis—Lucas is in a happy place when his work leads him to spend an afternoon poking around a dataset, trying to better understand government so he can help change it.\nLucas will talk about a few of these small CDS research projects, using publicly-available data to better understand the government’s operations.\nMonday, 15 March, 4:00-5:00pmTodd Feathers, Freelance reporter\nJointly hosted with Maryclare Griffin, University of Massachusetts Amherst.Todd Feathers is a freelance journalist covering artificial intelligence, surveillance, and the technologies changing our world. He spent years at daily newspapers reporting on politics, criminal justice, and health care. On every beat, new tech is solving problems and creating them. His goal is to use data, scientific research, and inside sources to cut through the hype and examine what our gadgets and algorithms really do. Writing in Vice, OneZero, The Wall Street Journal, and others.\nTodd will talk about ‘Major Universities are Using Race as a “High Impact Predictor” of Student Success’ published in The Markup on 2 March 2021.\nThursday, 18 March, 4:30-5:30pmSofia Ruiz-Suarez, National University of ComahueSofia Ruiz-Suarez holds an undergraduate degree in mathematics from the University of Buenos Aires and now is a PhD candidate at the institute for Research on Biodiversity and Environment. She also teaches mathematics at the University of Comahue and leads R-Ladies at her local city. Her research is focused on Bayesian statistics with applications in animal behaviour and movement.\nSofia will talk about animal tracking data. She will explain how sensors are used to track animal movement and activities, the characteristics of this type of data and how to deal with it.\nThursday, 25 March, 4:30-5:30pmAlex Cookson, MuseAlex Cookson is a Data Scientist at Muse, where he helps make the most of their data. In his spare time, you can find him participating in Tidy Tuesday or thinking up cool datasets to explore. And when he’s not doing that, he’s probably cycling around Toronto or doting on his two cats, Tom Tom and Ruby.\nAlex will explore the power of great datasets, and discuss the importance of interesting, fun datasets as a way to guide and motivate learning R.\nThursday, 1 April, 4:30-5:30pmVik Pant, Natural Resources Canada.\nDr. Vik Pant is the Chief Scientist and Chief Science Advisor of Natural Resources Canada (NRCan). He leads the Office of the Chief Scientist at NRCan and reports directly to the Deputy Minister. His office oversees the development and implementation of evidence-based science policy across NRCan sectors and agencies. His office also manages NRCan’s enterprise-wide technology strategy and portfolio of science products. He also runs the Digital Accelerator, which is an innovation platform for designing and launching AI-driven software products in NRCan. Vik is also the Founder of Synthetic Intelligence Forum, which is a leading community of practice focused on the industrial application of Artificial Intelligence (AI). He earned a doctorate from the Faculty of Information (iSchool) in the University of Toronto, a master’s degree in business administration with distinction from the University of London, a master’s degree in information technology from Harvard University, where he received the Dean’s List Academic Achievement Award, and an undergraduate degree in business administration from Villanova University. Vik serves as an Adjunct Professor in the Faculty of Information (iSchool) at the University of Toronto.\nVik will discuss supporting the Integration of Science and Policy through Data Science and Artificial Intelligence.\nThursday, 8 April, 4:30-5:30pmFaria Khandaker, University of Toronto\nFaria is a 2nd year student of the Information Systems and Design Concentration at the Faculty of Information and is one of the co-hosts of the Toronto Data Workshop. She holds an Honour’s Bachelor of Science Degree in Anthropology and Human Biology from the University of Toronto Scarborough. Since starting her masters, she became interested in research related to data-driven decision making within organizations. Under the supervision of Professor Arik Senderovich, she is researching topics related to the application of Machine Learning within the field of Process Mining and exploring various methodologies for gaining insights from email driven business processes.\nFaria will discuss mining process models from email data.\nThursday, 15 April, 4:30-5:30pmEmily A. Sellars, Yale UniversityEmily A. Sellars is an assistant professor in the Department of Political Science at Yale University. Before coming to Yale, she was an assistant professor in the Bush School of Government and Public Service at Texas A&M University and a postdoctoral scholar at the University of Chicago’s Harris School of Public Policy. She received her Ph. D. in Political Science and Agricultural and Applied Economics from the University of Wisconsin–Madison in 2015. Her research interests are at the intersection of political economy and development economics. Her research examines the political economy of emigration and population.\nEmily will discuss missing data and mis-measurement in Mexico’s 1900 census and the Historical Archive of Localities (AHL).\nThursday, 22 April, 4:30-5:30pmAimee Schwab-McCoy, Creighton University, Ashley Juavinett, UC San Diego, Chris Papalia, St. Andrew’s College, Samantha-Jo Caetano, University of TorontoAimee Schwab-McCoy is an Assistant Professor of Statistics at Creighton University. Ashley Juavinett is a neuroscientist, an educator, and a writer, currently working as an Assistant Teaching Professor at UC San Diego. Chris Papalia is a Mathematics and Science Teacher and Head of House at St. Andrew’s College. Samantha-Jo Caetano is an Assistant Professor, Teaching Stream, at the University of Toronto.\nPanel on teaching data-focused topics.\nFall 2020\n\n\n\nThanks to Hidaya Ismail for the brilliant maple leaf and dinosaur hex stickers.\nDate (Toronto time)\nSpeaker\nTopic\nRecording\nThu, 3 Sep, 4-5pm\nErik Drysdale (The Hospital for Sick Children)\nUsing hospital data\n\nTue, 8 Sep, 3:30-4:30pm\nSophie Bennett (Industry data scientist)\nUK A levels algorithm issues (jointly hosted with SRI)\n\nThu, 10 Sep, 4-5pm\nA Mahfouz, Diego Mamanche Castellanos, Hidaya Ismail, Ke-Li Chiu & Paul Hodgetts (University of Toronto)\nVarious R packages and research developed by students\n\nThu, 17 Sep, 4-5pm\nAmber Simpson (Queen’s University)\nCancer and AI\n\nThu, 24 Sep, 4-5pm\nChelsea Parlett-Pelleriti (Chapman University)\nTalking to non-statisticians about statistics\n\nThu, 1 Oct, 4-5pm\nFlorence Vallée-Dubois (Université de Montréal)\nCanadian demographics by riding (1991-2015)\n\nThu, 8 Oct, 4-5pm\nYim Register (University of Washington Data Lab)\nSelf-advocacy within machine learning systems\n\nThu, 22 Oct, 4-5pm\nJeff Waldman, Leanne Trimble, Leslie Barnes, & Lisa Strug (University of Toronto)\nPanel on data-focused resources at U of T\n\nThu, 29 Oct, 4-5pm\nFei Chiang (McMaster University)\nData currency and applications\n\nThu, 5 Nov, 4-5pm\nAndrew Whitby (Industry data scientist)\nCensuses\n\nMon, 9 Nov, 4-5pm\nTom Cardoso (Globe and Mail)\nBias Behind Bars\n\nThu, 12 Nov, 4-5pm\nKevin Armstrong (University of Toronto)\nMeasuring poverty for NGOs\n\nThu, 19 Nov, 4-5pm\nMichael Chong (University of Toronto)\nHigh-throughput Bayesian modelling workflow\nhttps://youtu.be/xM1vf_KT76g\nThu, 26 Nov, 4-5pm\nPostponed\n\n\nThu, 3 Dec, 5-6pm\nMonica Alexander (University of Toronto)\nUsing Facebook advertising data to estimate migration\nhttps://youtu.be/xM1vf_KT76g\nThu, 10 Dec, 4-5pm\nShabrina Mardevi (United Nations Population Fund & University of Toronto) & Romesh Silva (United Nations Population Fund)\nPopulation data estimation\nhttps://youtu.be/kfmKusnGDLI\nThu, 17 Dec, 4-5pm\nLiza Bolton (University of Toronto), Maria Tackett (Duke University), Nathalie Moon (University of Toronto), Teon Brooks (Mozilla Firefox)\nPanel on teaching data-focused topics\nhttps://youtu.be/c3R6pZisvm0\nThursday, 3 September 2020, 4-5pmSpecial guests Dean Wendy Duff (Faculty of Information) and Department Chair Radu Craiu (Department of Statistical Sciences).Erik Drysdale (The Hospital for Sick Children)Erik works as a Machine Learning Specialist at the Hospital for Sick Children (SickKids) for the Goldenberg Lab and AI in Medicine (AIM) initiative. His professional responsibilities include the development and training of the machine learning models for various pediatric data science projects. His research interests are focused on the intersection of statistics and machine learning methods such as high-dimensional inference, survival analysis, and optimization methods. Erik will talk about the challenges of applying ML in hospital data and why statistics still matters in ML.\nTuesday, 8 September 2020, 3:30-4:30pmJointly hosted with Gillian Hadfield and the Schwartz Reisman Institute for Technology and Society.Sophie Bennett (Industry data scientist)Sophie Bennett holds an undergraduate degree in Experimental Psychology from the University of Oxford and a PhD in Neuroscience from King’s College. She is the lead data scientist at Up Learn, a London-based online learning platform specialising in A levels. In this role, she conducts evaluations of course effectiveness and uses data to improve instruction and curriculum design. She is passionate about increasing the use of responsible evidence and statistics to guide social policy, and, in her spare time, enjoys working with publicly available datasets to explore London demographics, social issues and infrastructure. Sophie will discuss A Levels, Ofqual and algorithms.\nThursday, 10 September 2020, 4-5pmToronto Data Lab launch event.A Mahfouz (University of Toronto)Diego Mamanche Castellanos (University of Toronto)Hidaya Ismail (University of Toronto)Ke-Li Chiu (University of Toronto)Paul Hodgetts (University of Toronto)\nVarious Toronto Data Lab projects will be presented including arxivdl, aRianna, cesR, and more!\nThursday, 17 September 2020, 4-5pmAmber Simpson (Queen’s University)Dr. Simpson is the Canada Research Chair in Biomedical Computing and Informatics and Associate Professor in the School of Computing (Faculty of Arts and Science) and Department of Biomedical and Molecular Sciences (Faculty of Health Sciences). She specializes in biomedical data science and computer-aided surgery. Her research group is focused on developing novel computational strategies for improving human health. Dr Simpson will discuss cancer and AI.\nThursday, 24 September 2020, 4-5pmChelsea Parlett-Pelleriti (Chapman University)Chelsea is a PhD candidate and full-time instructional faculty at Chapman University where her research focuses on using novel statistical and Machine Learning methods (mostly Bayesian statistics, IRT models, and clustering) to behavioral data. As an instructor she teaches Python, R and Data Science, and loves using novel technology (like TikTok, Twitch, and flipped classes) to better engage and inspire students. Chelsea will discuss talking to non-DS team members about DS topics.\nThursday, 1 October 2020, 4-5pmFlorence Vallée-Dubois (Université de Montréal)Florence Vallée-Dubois is a Ph.D. candidate at the department of political science of the University of Montreal. She is also a member of the Centre for the Study of Democratic Citizenship and Canada Research Chair in Electoral Democracy. Her research interests focus on Quebec and Canadian politics, political behaviour and quantitative methods. Her doctoral project focuses on the political behaviour and democratic representation of seniors in Canada. Florence will discuss Canadian Demographics by Electoral Riding (1991-2015).\nThursday, 8 October 2020, 4-5pmYim Register (University of Washington Data Lab)Yim Register (they/them) is a radical optimist, child advocate, and PhD student at the University of Washington Data Lab exploring what self-advocacy looks like within machine learning systems. They study how empowering novices with Data Science knowledge can impact their participation and joy in an AI-driven world! Their passion project right now is writing a book called Life Lessons from Algorithms, a book that teaches how machine learning algorithms work through trauma recovery skills. Yim will discuss self-advocacy within machine learning systems.\nThursday, 22 October 2020, 4-5pmPanel discussion on data-focused resources at the University of Toronto.Jeff Waldman (University of Toronto)Leanne Trimble (University of Toronto)Leslie Barnes (University of Toronto)Lisa Strug (University of Toronto)\nJeff Waldman is the Manager, Institutional Data Governance; Leslie Barnes is the Digital Scholarship Librarian at UTL; Leanne Trimble is the Data and Statistics Librarian at UTL; Lisa Strug is a Senior Scientist in the Program of Genetics and Genome Biology, Associate Director of The Centre for Applied Genomics, Professor of Statistical Sciences and Biostatistics at the University of Toronto, and Director of CANSSI Ontario.\nThursday, 29 October 2020, 4-5pmFei Chiang (McMaster University)Fei Chiang is an Associate Professor in the Department of Computing and Software (Faculty of Engineering), the Director of the Data Science Research Group, and a Faculty Fellow at the IBM Centre for Advanced Studies. She served as an inaugural Associate Director of the MacData Institute. Her research interests and industrial experience is in data management, spanning data cleaning, data quality, data privacy, data fusion, and database systems. Professor Chiang will discuss data currency and its applications.\nThursday, 5 November 2020, 4-5pmAndrew Whitby (Industry data scientist)Andrew is a data scientist and economist currently looking for his next challenge. He is particularly interested in the economics of technology, creativity, innovation and growth. He wrote The Sum of the People: How the Census Has Shaped Nations from the Ancient World to the Modern Age which was published in March 2020. Previously, he worked as a Data Scientist at the World Bank, and at Nesta, the UK’s innovation think tank. His academic background combines economics, statistics and computer science. He completed his doctoral research in the Department of Economics at the University of Oxford. Andrew will discuss censuses.\nMonday, 9 November 2020, 4-5pmTom Cardoso (Globe and Mail)Tom Cardoso is a crime and justice reporter and data journalist for The Globe and Mail. Tom will discuss his Bias Behind Bars series of articles which show Black and Indigenous inmates in Canada are more likely to get worse scores than white inmates, based solely on their race.\nThursday, 12 November 2020, 4-5pmKevin Armstrong (University of Toronto)\nKevin Armstrong is a Masters of Information student at the University of Toronto, and a data consultant for ‘Women’s Integrated Sexual Health’ (WISH) - a three-year program delivering integrated health care in 16 countries in Africa and South Asia. Kevin will discuss methods for measuring poverty and use cases for NGOs.\nThursday, 19 November 2020, 4-5pmMichael Chong (University of Toronto)Michael is a PhD student in the Department of Statistical Sciences at the University of Toronto building models for demographic estimation. Previously, he completed his BSc in Integrated Science at McMaster University. Michael will discuss lessons from a high-throughput Bayesian modelling workflow\nThursday, 26 November 2020, 4-5pmPostponed\nThursday, 3 December 2020, 5-6pmMonica Alexander (University of Toronto)Monica Alexander is an Assistant Professor in Statistical Sciences and Sociology at the University of Toronto. She received her PhD in Demography from the University of California, Berkeley. Her research interests include statistical demography, mortality and health inequalities, and computational social science. Monica will talk about using Facebook advertising data to estimate migration. A recording of the talk is available here: https://youtu.be/xM1vf_KT76g.\nThursday, 10 December 2020, 4-5pmShabrina Mardevi (United Nations Population Fund and University of Toronto)Romesh Silva (United Nations Population Fund)\nShabrina is a Masters of Information student at the University of Toronto and a Population Data Estimation and Analysis Intern at the United Nations Population Fund. Romesh holds a PhD in Demography from the University of California, Berkeley, and is a Technical Specialist, Health & Social Inequalities, at the United Nations Population Fund.\nThursday, 17 December 2020, 4-5pmPanel discussion on teaching data-focused topics.Liza Bolton (University of Toronto)Maria Tackett (Duke University)Nathalie Moon (University of Toronto)Teon Brooks (Mozilla Firefox)Liza Bolton is an Assistant Professor, Teaching Stream, at the University of Toronto. Maria Tackett is an Assistant Professor of the Practice in the Department of Statistical Science at Duke University. Nathalie Moon is an Assistant Professor, Teaching Stream, University of Toronto. Teon L. Brooks, holds a PhD in experimental psychology from NYU, and now works as a data scientist for Mozilla Firefox. He also serves as the technical advisor and President of BrainWaves, an NIH-funded project to teach experimentation and cognitive neuroscience to high school students in NYC, and has co-founded Computation in Education Labs (CIEL), a nonprofit that aims to further the mission of the BrainWaves project while focusing on data science and computational thinking.\nSummer 2020\nThursday, 21 May 2020, 4-5pmRohan Alexander (University of Toronto, Information)Rohan is a post-doctoral fellow at the Faculty of Information, University of Toronto. He holds a PhD in Economics from the Australian National University. He will talk about getting data from PDFs into R, with an application to the Kenyan census.\nThursday, 28 May 2020, 4-5pmShiro Kuriwaki (Harvard University, Government)Shiro is a Ph.D. Candidate at the Department of Government, Harvard University. His research focuses on democratic representation in American Politics, for instance cast vote records, public opinion, survey methods, and applied statistics more generally. Shiro will bring together best practices for organizing data and code in the social sciences that experts have proposed with some of his own experience. He will propose a project-oriented workflow that adopts a minimal and consistent file organization structure within a single project, using RStudio Projects and GitHub. He will then discuss how to organize multiple projects that share common components, and propose the use of custom R packages to share code and Dataverse to share large datasets. He will use some of his own projects involving the Cooperative Congressional Election Study (CCES), one of the largest political surveys of American Politics, as a demonstration.\nRecording available here.\nThursday, 4 June 2020, 4-5pmMarija Pejcinovska (University of Toronto, Statistical Sciences)\nMarija is a second-year Ph.D. student in Statistics at the University of Toronto. Her research interests are in applied statistics, specifically the application of Bayesian methods to data and modeling challenges that arise in demography, public health, and certain areas of the social sciences. Marija will talk about a current project with the World Health Organization (WHO) focused on estimating global maternal mortality to share her R workflow and the different tools and packages she’s found helpful in the data processing stage. More specifically, she’ll be sharing a few ways of dealing with text and date data in R.\nThursday, 11 June 2020, 4-5pmHarrison Jones (Deloitte)Harrison is a Manager at Deloitte in Toronto, where he focuses on data analytics and machine learning in the property & casualty insurance, life insurance, health insurance, pensions, and the public sector. Harrison will talk about using R with actuarial data.\nThursday, 18 June 2020Cancelled in support of the Black Lives Matter movement and to provide an opportunity for reflection and learning. We also announced stipends in support of University of Toronto students or recent graduates who identify as a member of a visible minority group, racialized group, or as a person of colour.\nThursday, 25 June 2020, 4-5pmA Mahfouz (University of Toronto, Information)\nA is a Master of Information student at the University of Toronto with a background in geography. Their prior work has been largely concerned with data pipelines. A will talk about geographic data cleaning, extracting mappable data from Google Directions API results in Python.\nSlides available here.\nThursday, 2 July 2020, 4-5pmHeather McBrien (University of Toronto, Statistical Sciences)\nHeather just graduated from the Statistics BSc program at the University of Toronto, and is interested in modelling in population health research, particularly using novel data sources to answer questions where traditional data is lacking. Heather will talk about how the data that we collect can bias the results that we obtain and our knowledge of the problem.\nSlides available here.\nThursday, 9 July 2020, 4-5pmRoxanne Chui (University of Toronto, Information)\nRoxanne is an emerging anthropological data science professional. She did her BSc program in Forensic anthropology and worked in the pharmaceutical industry before doing her Masters in data science. She is passionate about excavating context from data for predicting future patterns of human behaviour. Roxanne will talk about an EDA approach to Tokyo AirBnB datasets and pattern discovery in listing prices using R - ‘What do we have here among millions of observations?’\nSlides available here.\nThursday, 16 July 2020, 4-5pmCasey Breen (University of California, Berkeley, Demography)\nCasey is a PhD student in the Demography Department at Berkeley. He previously worked at the Institute for Social Research and Data Innovation, home of IPUMS. Casey will talk about CenSoc, which is a project to link 1940 Census data with Social Security Administration mortality records in the US.\nThursday, 23 July 2020, 11am-noonMarta Kołczyńska (Institute of Political Studies of the Polish Academy of Sciences)Marta is an Assistant Professor at the Institute of Political Studies of the Polish Academy of Sciences and a visiting researcher in the Probabilistic Machine Learning Group, Department of Computer Science, Aalto University. Her research interests include comparative analyses of political attitudes and behavior across nations and over time, as well as the methodology of comparative research, in particular cross-national surveys. Marta will talk about cleaning survey data, in particular a project in which she gathers political trust items from different cross-national survey datasets to model time trends, and the tools she has developed to facilitate this work.\nThursday, 30 July 2020, 4-5pmAlex Luscombe (University of Toronto, Criminology and Sociolegal Studies)Alexander McClelland (Carleton University, Criminology and Criminal Justice)Alex Luscombe is a PhD student in the Centre for Criminology & Sociolegal Studies at the University of Toronto and a Junior Fellow at Massey College. Alexander McClelland is an Assistant Professor at the Institute of Criminology and Criminal Justice, Carleton University. They will talk about Policing the Pandemic, which is a project that was launched on 4 April, 2020, to track and visualize the massive and extraordinary expansions of police power in response to the COVID-19 Pandemic and the unequal patterns of enforcement that may arise as a result.\nSlides available here.\nThursday, 6 August 2020, 4-5pmSharla Gelfand (Freelance R Developer)Sharla is a freelance R developer specializing in enabling easy access to data and replacing manual, redundant processes with ones that are automated, reproducible, and repeatable. They will talk about creativity in R. Slides available here.\nThursday, 13 August 2020, 4-5pmRichard Iannone (R Studio)Rich is a Software Engineer at R Studio. Rich will talk about pointblank, which is an R package that allows workflows involving nice and easy data validation in reproducible documents.\nThursday, 20 August 2020, 4-5pmAije Egwaikhide (IBM)\nAije Egwaikhide holds an undergraduate degree in Economics and Statistics from the University of Manitoba, and a post-graduate degree in Business Analytics from St. Lawrence College, Kingston. She works at IBM where she is a Lead Data Scientist on the System Enablement group. Aije will talk about preparing data for optical character recognition (OCR).\nWinter 2020\nNoon, Friday, 24 January 2020Steven Pimentel (U of T, business intelligence)\nNoon, Friday, 31 January 2020Arik Senderovich (U of T, Information)\nNoon, Friday, 7 February 2020Kathy Chung (U of T, Records of Early English Drama)\nNoon, Friday, 14 February 2020Josh Harris (KOHO)\nNoon, Friday, 28 February 2020Eugene Joh (St. Michael’s Hospital)\nNoon, Friday, 6 March 2020Fatemeh Nargesian (University of Rochester, Computer Science)\nFall 2019\nNoon, Thursday, 26 September 2019Periklis Andritsos (ODAIA & U of T, Information)\nNoon, Thursday, 10 October 2019Hassan Teimoori (Deloitte, Omnia AI)Ludovic Rheault (U of T, Political Science)\nNoon, Wednesday, 16 October 2019Lauren Kennedy (Columbia University)\nNoon, Thursday, 24 October 2019Sharla Gelfand (Freelance R and Shiny developer)\nNoon, Thursday, 7 November 2019Maria D’Angelo (Delphia)Hareem Naveed (Munich Re)\nNoon, Thursday, 21 November 2019Michelle Alexopoulos (U of T, Economics)Paraskevi Massara (U of T, Medicine)\nIf you would like to receive invitations to the series, then you can subscribe here.\n\n\n\n",
      "last_modified": "2021-10-13T20:59:32-04:00"
    }
  ],
  "collections": ["posts/posts.json"]
}

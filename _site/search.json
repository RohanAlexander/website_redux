{
  "articles": [
    {
      "path": "2020-sta304.html",
      "title": "Surveys, Sampling, and Observational Data",
      "description": "STA304 is an upper-level undergraduate course at the University of Toronto's Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nHow to succeed\nHow we’ll work\nAdvice from past\nstudents\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nWeekly quizzes\nProfessional conduct\nPaper #1\nPaper #2\nPaper #3\nFinal Paper\n\n\nPreamble\n\n\nOverview\n\nThe best thing about being a statistician, is that you get to play in\neveryone’s backyard.\nJohn Tukey\n\nThe work of applied statisticians, regardless of their specific job\ntitle and area of application, is the most important and exciting work\nin the world right now. The ability to gather data, analyse it, and\ncommunicate your understanding of the underlying process is incredibly\nvaluable. In this course you will learn and apply the essentials of\nthis.\nWe focus on surveys, sampling and observational data. The very stuff\nof statistical science! We will approach these topics from a practical\nperspective. You will actually run surveys and learn how messy it is to\nput one together. You will learn how to think about sampling, how to\nimplement it, and why the details matter. You will forecast an election.\nAnd you will conduct original research. More generally, you will learn\nhow to obtain and analyse data and use it to make sensible claims about\nthe world.\nTo work as an applied statistician requires you to be able to, as\npart of a small team:\nGather data in less-than-perfect settings.\nEfficiently prepare and clean data toward some purpose.\nAnalyse it in a reproducible, thorough, modern, and\nstatistically-mature manner.\nCommunicate your analysis to stakeholders including colleagues and\nclients with and without formal statistical training.\nYou likely have some of these skills already. This course will\nfurther develop them. At the end of the course you will have a portfolio\nof work focused on surveying, sampling, and observational data, that you\ncould show off to a potential employer.\nEach week you will read relevant papers and books, engage with them\nthrough discussion with each other, myself, and the TA. You will bring\nthis all together and show off how much you have learnt through\npractical, on-going, assessment.\nIt is important to recognise that putting together everything that\nyou have learnt to this point in this way will be difficult. It is not\npossible to cover everything that you will need to know. You should\nproactively identify and address aspects where you are weak through\nseeking additional information and resources. This course acts as a\nguide as to what is important, it does not contain everything that is\nimportant.\nThis course is different to many other courses at the University of\nToronto. At the end of this course, you will have a portfolio of work\nthat you could show off to a potential employer. You will have developed\nthe skills to work successfully as an applied statistician or data\nscientist. And you will know how to fill gaps in your knowledge\nyourself. A lot of scholarships and jobs these days ask for GitHub and\nblog links etc to show off a portfolio of your work. This is the class\nthat gives you a chance to develop these. It’s very important to having\nsomething to show that needs to go beyond what is done in a normal\nclass.\nHow to succeed\nIn this course you will work in a self-directed, open-ended manner.\nIdentify relevant areas of interest and then learn the skills that you\nneed to explore those areas.\nTo successfully complete this course, you should expect to spend a\nlarge portion of your time reading and writing (both code and text).\nDeeply engage with the materials. Find a small study group and keep each\nother motivated and focused. At the start of the week, read the course\nnotes, all compulsory materials and some recommended materials based on\nyour interest. After doing that, but before the ‘lecture’ time you\nshould complete the weekly quiz. During ‘lectures’ I’ll live-code,\ndiscuss materials in the course notes, talk about an experiment, and\nyou’ll have a chance to discuss the materials with me.\nYou need to be more active in your learning in this course than\nothers - read the notes and related materials - and then go out there\nand teach yourself more and apply it. You will not be spoon-fed in this\ncourse. Each week try to write reproducible, understandable, R code\nsurrounded by beautifully crafted text that motivates, backgrounds,\nexplains, discusses and criticizes. Make steady progress toward the\nassessment.\nThis is not a ‘bird course’. Typically, after the term is finished,\nstudents say that the course is difficult but rewarding. The TAs and I\nare always available to answer any questions. Please come to office\nhours!\nHow we’ll work\nThis webpage will provide almost all the guiding materials that you\nneed and links to the relevant parts of the notes. The course notes are\navailable here: https://www.tellingstorieswithdata.com. Those contain\nnotes and other material that you could go over. There is a course Slack\nfor discussion. We’ll use Quercus really only for assessment submission\nand grading. I expect you to work professionally, and so we’ll try to\nuse professional tools to the extent possible.\nA rough weekly flow for the course would be something like:\nRead the week’s course notes.\nRead/watch/listen to the compulsory materials.\nComplete the weekly quiz.\nAttend the lecture.\nAttend the lab.\nMake progress on a paper.\nAdvice from past students\nSuccessful past students have the following advice (completely\nunedited by me):\n“Start reading and writing on a weekly basis, watch some videos on R\nand RMD but more importantly learn how to use Google.”\n“It is not a wise idea to take this course if you did not take any\nother STA 300 level course before.”\n“Start early, find a group of people you trust enough to divide the\nwork up fairly. Let people work to their strengths (people who know R\nshould do the modelling, good writers should write most of the reports,\netc.)”\n“Not to worry if you don’t do well on the first problem set—the\nnature of the course is to build up skills overtime, and it’s meant to\nbe challenging in the beginning. In the end, it is worth it because you\nlearn very valuable applicable skills on how to write professional\nreports.”\n“Work on your writing and direction following skills.”\n“Look at the rubric. There were times that I lost marks because I\ndidn’t follow the rubric properly. Go to office hours, they are very\nuseful as you can ask your own question and also get answers to\nquestions other people ask and you didn’t think of. Also, do the\nassignments to the best of your ability. You will lose marks if you\ndon’t put in effort and the only person you’re hurting is\nyourself.”\n“During lectures, focus more on the why the prof is doing what he’s\ndoing. When he runs certain commands in R, figure out why that sequence\nof code gives what you want, because it’ll help adapt his code into your\nassignment code. just remembering what he’s doing in lecture becomes\nuseless really quickly since the thought process matters more. also,\nstart everything early.”\n“Do this course when you really want to learn something and have a\nlot of time to working on it.”\n“you need to be very skillful in RStudio and latex. Otherwise you\nwould be struggling.”\n“Try to incorporate the feedback given and read a looottttttttt.\nAlso start early on the problem sets because they tend to take a lot of\ntime. Don’t give up!”\n“-Find a good group for problem sets”\n“If the assignments stay the same, I would tell students to approach\nthis class from the perspective of ‘storytelling with statistics’ rather\nthan a statistics course. You need to use R, and Markdown, and have a\nsolid understanding of concepts like regression and sampling, but more\nimportantly you need to be able to interpret results and write about\nthem in a way coherent and professional way.”\n“do your readings”\n“Definitely get ready to write reports”\n“Do not take sta304 with Prof Rohan, it is pretty tough”\n“Start your work a bit earlier, make sure to follow the format\nexpected and the rubric exactly.”\n“Read course material. Figure out WHY this paper/video is being\nshown to you and what you generally learn from it. Surround yourself\nwith people dedicated to putting in the effort to understand material\nand who are thorough in their work so you can discuss content and/or\nwork together.”\n“1. Be prepared to work extremely hard (8-11 hours a week). 2. Learn\nRStudio before course begins–STA130 is ideal preparation. 3. Start\nproblem sets as soon as they are released.”\n“learn to code early and extensively use the office hours with the\nprof.”\n“This course requires lots of time dedicated and is not an”easy bird\ncourse” but is an incredibly rewarding course if one wants to learn how\nstatistics is applied in the real world.”\nAcknowledgements\nThank you to the following people for generously providing comments,\nreferences, suggestions, and thoughts that directly contributed to this\noutline: Bethany White, Dan Simpson, Jesse Gronsbell, Kelly Lyons,\nLauren Kennedy, and Monica Alexander. Thank you especially to\nSamantha-Jo Caetano who influenced all aspects of this and co-taught the\nfirst version in Fall 2020.\nContent\nEach week you should go through the course notes and all compulsory\nmaterials. During the lecture I will live-code various aspects. I will\nalso discuss a case study, typically a paper. During the lab, a TA will\neither lead small group discussions or similarly lead other work. The\nlecture will be recorded and posted here, but again, it’s not enough to\njust watch that - you need to read and write yourself.\nWeek 1\n‘Drinking from a fire hose’.\nContent: Drinking\nfrom a fire hose, R\nEssentials.\nCase Study: Fisher’s\nLady Tasting Tea.\nLab: Go through first four modules of DoSS Toolkit and discuss any\nissues with the TA.\nWeek 2\n‘Science-ing’.\nContent: Workflow,\nStatic\ncommunication.\nCase Study: Tuskegee\nSyphilis Study.\nLab: Go through modules five to eight of DoSS Toolkit and discuss\nany issues with the TA.\nWeek 3\n‘Why, if ever I did fall off—which there’s no chance of—but if I\ndid–’.\nContent: Experiments,\nand treatment effects.\nCase Study: The\nOregon Health Insurance Experiment in the United States.\nSpecial guest: Greg Wilson on\nhow to run a meeting.\nLab:\nPlease pretend that you work as a junior analyst for a large\nconsulting firm. Further, pretend that your consulting firm has taken a\ncontract to put together a facial recognition model for the Canada\nBorder Services Agency’s Inland Enforcement branch. Write five or six\npoints with regard to your thoughts on this matter. What would you do\nand why? Then split into small groups and compare your points with\nothers. Do you think the model would end up being implemented?\nWith the help of the TA, please conduct ‘face-to-face’ surveys (via\nZoom). For this exercise, you will be randomly split into groups of two.\nYou have two minutes in each group and will then be swapped to another\ngroup. One person is to survey the other person asking the following\nquestions: i) ‘What is your gender?’, ii) ‘What is your age?’, iii)\n‘What is your marital status?’, iv) ‘What is your income?’, v) ‘If an\nelection were held today who would you vote for?’. After one person is\ndone, then switch roles. When you are the questioner you should record\nall responses using a small CSV (but not the person’s name please). When\nyou are the respondent you are welcome to not respond. You will cycle\nthrough this multiple times. At the end, please write a small reflection\nabout: 1) as a respondent, how you felt answering these questions and\nthe implications that you think this feeling may have for how survey\nquestions are answered more generally; and 2) as a questioner, how\ndifficult it was to code responses and the implications this may have\nfor the dataset that we analyse.\n\nWeek 4\n‘Stratified, systematic, and cluster sampling’\nContent: Stratified, systematic, and cluster\nsampling\nLab:\nFollowing the guidance of the TA, please read about the Canadian\nGeneral Social Survey: https://www150.statcan.gc.ca/n1/pub/89f0115x/89f0115x2019001-eng.htm\nand then:\nDiscuss its key features, strengths, and weaknesses generally.\nLook at the questionnaire - what is good and bad about it?\nHow do they find people to take the survey?\nWhat do they do about non-response?\n\nFollowing the guidance of the TA, please identify a GSS dataset that\nyou are interested in and then:\nLook at a specific question that is asked.\nSimulate the responses that you expect.\nDownload the dataset.\nConduct some exploratory data analysis.\nDiscuss how your expectations compare with reality.\n\n\nWeek 5\n‘Gathering data’.\nContent: Gathering\ndata.\nCase Study: Student\nCoaching: How Far Can Technology Go?\nLab:\nPlease pretend you work for Netflix and you want to know more about\nwhy people subscribe (or don’t!) when prices change. Please design an\nexperiment, discuss its key features and how you would implement it.\nPlease pay special attention to sampling issues. Then simulate an\noutcome.\nFollowing the guidance of the TA, please scrape some data and\ndiscuss some ethical considerations around the dataset that you created.\nYou may like to write a short blog post discussing the difference\nbetween data being public but scattered, and a consolidated dataset\nbeing public with reference to Kirkegaard and Bjerrekær, 2016, and\nPolitou, Alepis, and Patsakis, 2018 (if you do that please do email a\nlink to me out of interest).\n\nWeek 6\n‘Whoops, I forgot EDA’.\nContent: Exploratory\nData Analysis.\nCase Study: Civic\nhonesty around the globe\nLab:\nPretend that you work for Loblaws as a data scientist and it is late\nMarch 2020. As part of normal monitoring, you have noticed that\npurchases of flour and pasta have increased substantially. You had been\nplanning to increase the price of these items in April as part of a\ntrial, but now your manager is not sure whether it is appropriate to\nconduct the trial. Please write five or six points with regard to your\nthoughts on this matter. What would you do and why?\nAnalyse the Toronto AirBNB dataset with guidance from the TA.\n\nWeek 7\n‘IJALM - It’s Just A Linear Model’.\nContent: Linear\nand logistic regression and tidymodels\nCase Study: Upworthy\nA/B tests of headlines.\nSpecial guest: Kathy Ge on\nexperiments at Uber.\nLab recording:\nFollowing the guidance of the TA, please use Blogdown to create a\nsimple website and then design and execute a simple A/B test for your\nwebsite using Netlify.\n\nWeek 8\n‘Celestial Navigation’.\nContent: Simulation,\npower,\nRCTs,\nA/B\ntesting.\nCase Study: Please pick one chapter from Catherine D’Ignazio and\nLauren F. Klein, Data Feminism, that is of interest to you and\nread it (freely available: https://data-feminism.mitpress.mit.edu).\nLab:\nFollowing the guidance of the TA, please make a Shiny app that\nbundles a little data and some code and post it to shinyapps.com.\n\nWeek 9\n‘Multilevel regression with post-stratification’\nLecture: MRP.\nCase Study: Xbox\npaper\nLab: Use MRP to forecast the 2020 US presidential election.\nWeek 10\n‘Such a shame they’ll never meet’.\nContent: Matching\nand difference in differences.\nCase Study: Funding\nof Clinical Trials and Reported Drug Efficacy\nSpecial guest: Emily Riederer\non observational causal inference.\nSpecial guest: Tamar Oostrom\non funding of clinical trials.\nLab:\nFollowing the guidance of the TA, please look at McClelland,\nAlexander, 2019, ‘“Lock This Whore Up”: Legal Violence and Flows of\nInformation Precipitating Personal Violence against People Criminalised\nfor HIV-Related Crimes in Canada’, European Journal of Risk\nRegulation, 10 (1), pp. 132-147.\nThen look at Policing the Pandemic - https://www.policingthepandemic.ca/. Look into how they\ngathered their dataset and what it took to put this together. What is in\nthe dataset and why? What is missing and why? How could this affect the\nresults? How might similar biases enter into other datasets that you\nhave used or read about?\nPut together a brief model. You may like to write a short blog post\nabout the biases and influences that are in this dataset (if you do that\nplease do email a link to me out of interest).\n\nWeek 11\n‘Why does it always rain on me?’.\nContent: Regression\ndiscontinuity and instrumental\nvariables.\nCase Study:\nJames H. Ware, 1989, ‘Investigating Therapies of Potentially Great\nBenefit: ECMO’, Statistical Science, available here.\nDonald A. Berry, 1989, ‘Comment: Ethics and ECMO’, Statistical\nScience, available here.\n\nLab:\nFollowing the guidance of the TA, please make an R package that\nbundles a little data and some code and add it to your GitHub. Don’t\nforget to include at least one test.\n\nWeek 12\n‘Lorem ipsum’.\nContent: Text-as-data.\nCase Study: Kevin Munger, Patrick Egan, Jonathan Nagler, Jonathan\nRonen, and Joshua A. Tucker, 2017, ‘Political Knowledge and\nMisinformation in the Era of Social Media: Evidence From the 2015 UK\nElection’.\nLab:\nPlease form small groups and discuss, ‘to what extent do\nquantitative methods merely project forward the past, and what\nimplications does this have for our conduct as practitioners and\nconsumers?’\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nWeekly quiz\n20\nWeekly before the lecture\nProfessional conduct\n3\nAnytime during the teaching term\nPaper 1\n24\nEnd of Week 3\nPaper 2\n24\nEnd of Week 6\nPaper 3\n24\nEnd of Week 9\nFinal Paper (initial submission)\n1\nEnd of Week 12\nFinal Paper (peer review)\n3\nThree days after that\nFinal Paper\n25\nTen days after that\nWeekly quizzes\nDue date: Weekly before the lecture.\nWeight: 20 per cent (no quiz in Week 1 or Week 12 and only best\neight out of ten count.)\nTask: Please complete a weekly quiz in Quercus.\nQuestions: The questions that form the quiz are drawn from those in\nthe course notes.\nProfessional conduct\nDue date: Anytime during the teaching term.\nWeight: 3 per cent\nTask:\nWe (optionally) use Slack to interact in this class. At some point\nduring the teaching term, please use Slack to answer another student’s\nquestion or otherwise similarly be generally helpful in a professional\nmanner. When you do that, please share the comment into the\n‘Professional conduct’ channel and @ me (hover on the message, click\nshare message, type in the channel ‘profession_conduct’, add a message\nthat @‘s me, and click ’share’). You’ll get the full mark just for one\nhelpful interaction. (If you are opting out of using Slack - which is\nentirely fine - then instead, at some point in the term send me an email\nwith a link that is relevant to the course materials and that I should\nadd to the course notes. Please be clear that this is your ‘professional\nconduct’ submission by stating that in the subject line.)\nIt will not be possible to get any of this mark if you behave\nunprofessionally at all during the term. That includes abusive/rude\nemails/messages.\n\nPaper #1\nDue date: End of Week 3.\nWeight: 24 per cent (for Papers #1-#3 the best two of three\ncount).\nTask: ‘Mandatory\nminimums’\nPaper #2\nDue date: End of Week 6.\nWeight: 24 per cent (for Papers #1-#3 the best two of three\ncounts).\nTask: ‘Mr\nWillis of Ohio’\nPaper #3\nDue date: End of Week 9.\nWeight: 24 per cent (for Papers #1-#3 the best two of three\ncounts).\nTask: ‘Five\nVotes Down’\nFinal Paper\nDue dates:\nInitial submission: End of Week 12.\nPeer review: Three days after that.\nFinal Paper: Ten days after that.\n\nWeight: 29 per cent (4 per cent of this is for initial submission\nand peer review conducted a week before).\nInitial submission: 1 per cent\nPeer review: 3 per cent\nFinal Paper: 25 per cent\n\nTask: ‘What’s\nnext’\n\n\n\n",
      "last_modified": "2022-05-02T13:00:24-04:00"
    },
    {
      "path": "about.html",
      "title": "About",
      "author": [],
      "contents": "\nRohan Alexander is an assistant professor at the University of\nToronto, Canada, jointly appointed in Information\nand Statistical\nSciences. He is also a faculty affiliate at the Schwartz Reisman Institute for\nTechnology and Society. He holds a PhD in Economics from the\nAustralian National University where he was supervised by John Tang\n(chair), Martine\nMariotti, Tim\nHatton, and Zach\nWard.\nHe is interested in using statistical models to try to understand the\nworld. And particularly how we get the data that go into those models;\nwhose data are systematically missing; how we clean, prepare, and tidy\ndata before they are modelled; the effects of all this on the\nimplications of our models; and how we can reproducibly share the\ntotality of this process. This research interest has a few different\napplications. One of those is natural language processing (NLP), where\nhe is interested in understanding the effects of bringing together\nlarge, biased datasets and enormous models, and how this can be\nimproved. Another is Multilevel Regression with Post-stratification\n(MRP), where he examines the effects of trying to establish a\ncorrespondence between two datasets.\nHe tries to develop students in his research group that are\nskilled not only in using statistical methods across various\ndisciplines, but also appreciate their limitations, and think deeply\nabout their broader contexts of their work.\nExamples of his recent academic work\ninclude: ‘heapsofpapers’,\n‘Detecting Hate Speech with\nGPT-3’, and ‘On\nconsistency scores in text data with an implementation in R’.\nHis teaching notes are available: Telling Stories With\nData. He enjoys teaching and aims to\nhelp students from a wide range of backgrounds learn how to use data to\ntell convincing stories. In Information he has taught ‘Experimental Design’\nand lead reading courses in ‘Ethics and\nData Science’, ‘Information Management in Interdisciplinary\nResearch’ and ‘Reproducible Data Science’. In Statistical Sciences he\nhas taught ‘Surveys,\nSampling, and Observational Data’ and lead a reading course in ‘Natural\nLanguage Processing’. He is a RStudio Certified\nTidyverse Trainer.\nHe co-organizes the weekly Toronto\nData Workshop, which is more fun than it sounds. All welcome! Sign\nup here.\n\n\n\nHe is married to Monica\nAlexander and they have a 2-year-old. He probably spends too much\nmoney on books, and certainly too much time at libraries (in a pre-COVID\nworld). You can see some of the books that he recommends here. If you have\nany book recommendations of your own, then he’d love to hear them.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:25-04:00"
    },
    {
      "path": "academic.html",
      "title": "Academic",
      "author": [],
      "contents": "\nPeer-reviewed papers\nRohan Alexander and Zach Ward, 2018, ‘Age\nat Arrival and Assimilation During the Age of Mass Migration’,\nThe Journal of Economic History, 78(3), 904-937. Working paper\nversion.\nPre-prints\nRohan Alexander and Monica\nAlexander, 2021, ‘The Effect of Elections and Prime Ministers on\nDiscussion in the Australian Federal Parliament (1901—2018)’,\narXiv, 17 November, https://arxiv.org/abs/2111.09299. Under review at\nPSRM.\nKe-Li Chiu and Rohan Alexander, 2021, ‘Detecting Hate Speech with\nGPT-3’, arXiv, 23 March [4 November], https://arxiv.org/abs/2103.12407. Under review at\nEPJ Data Science.\nAnnie Collins and Rohan Alexander, 2021, ‘Reproducibility of\nCOVID-19 pre-prints’, arXiv, 22 July, https://arxiv.org/abs/2107.10724. Under review at\nScientometrics.\nRohan Alexander, Samantha-Jo Caetano, Haoluan Chen, Michael Chong,\nAnnie Collins, Shirley Deng, Isaac Ehrlich, Paul Hodgetts, Yena Joo,\nMarija Pejcinovska, Mariam Walaa, and Matthew Wankiewicz, 2021, ‘An\nIntroduction to DoSStoolkit’, arXiv, 19 May, https://arxiv.org/abs/2105.09347.\nKe-Li Chiu and Rohan Alexander, 2021, ‘On consistency scores in text\ndata with an implementation in R’, arXiv, 13 January, https://arxiv.org/abs/2101.05225.\nPaul A. Hodgetts and Rohan Alexander, 2020, ‘cesR: An R package for\nthe Canadian Election Study’, SocArXiv, 3 September, https://osf.io/preprints/socarxiv/a29h8/.\nSoftware\n\n\n\nRohan Alexander and Paul A. Hodgetts, 2021,\nAustralianPoliticians, https://rohanalexander.github.io/AustralianPoliticians/.\nThis R package is a series of functions that load datasets of\nbiographical and political information about Australian federal\npoliticians between 1901 and 2021. The datasets are up-to-date as of 30\nNovember 2021.\nPaul A. Hodgetts and Rohan Alexander, 2021, cesR, https://hodgettsp.github.io/cesR/. This R package\nprovides access to the Canadian Election Study Datasets.\nRohan Alexander and A Mahfouz, 2021, heapsofpapers, https://rohanalexander.github.io/heapsofpapers/. This R\npackage makes it easy to respectfully download heaps of papers (and\nCSVs, and websites, and similar). It is essentially a wrapper around a\nfor loop and utils::download.file(), but there are a bunch\nof small things that make things easier compared with writing that out\neach time. For instance, the package automatically slows down your\nrequests, lets you know where it is up to, and adjusts for papers that\nyou’ve already downloaded.\nPresentations\nUpcoming\n17 December 2021, University of Toronto Statistics and MachIne\nLEarning (SMILE) Journal Club.\n16 December 2021, Young Irish Statisticians.\nPast\nA super opinionated talk about data science, APIs, and grad school\napplications\n18 November 2021, University of Toronto, Undergraduate Statistical\nSciences Union Workshop. https://youtu.be/P1yvnq2Rojk\nRemarks at Trinity College\n19 October 2021, University of Toronto, Trinity College High Table.\nIntroduction to Andrew Gelman\n17 September 2021, University of Toronto, Data Sciences Institute\nlaunch.\nIntroduction to R\n22 December 2020, University of Toronto, Global Society for Genetics and\nGenome Biology.\nTurning Our World Into Data\n7 July 2021, Harvard Biostatistics Data Science in Action Summer\nCamp.\nForecasting Parliamentary Elections\n10 December 2019, Monash University, Department of Econometrics &\nBusiness Statistics, Melbourne.\n9 December 2019, Australian Society for Quantitative Political Science\nConference, Melbourne.\n2 December 2019, Australian National University, Cake for Comments,\nCanberra.\n20 November 2019, POP Politics Workshop, Canberra.\n17 October 2018, University of Toronto, Political Behaviour Group,\nToronto.\nA Word-Count Based Classifier of Politicians in the Australian\nFederal Parliament (1901–2018)\n4 September 2019, European Consortium for Political Research, General\nConference, Wroclaw.\n22 June 2019, European Political Science Association, Annual Conference,\nBelfast.\n18 June 2019, Quantitative Text Analysis Workshop, Dublin.\nThe Effect of Elections and Prime Ministers on Discussion in the\nAustralian Federal Parliament (1901—2018)\n11 January 2019, Political Methodology Specialist Group, Annual\nConference, Warwick.\n11 December 2018, Max Planck Institute for Demographic Research,\nRostock.\n22 November 2018, University of Toronto, Political Behaviour Group,\nToronto.\n25 October 2018, Australian National University, Research School of\nEconomics, Canberra.\n25 October 2018, Parliamentary Library, Parliament of Australia,\nCanberra.\n24 October 2018, Australian National University, School of Politics and\nInternational Relations, Canberra.\nExploring Australia’s Hansard (1901–2017)\n(Poster) 7-9 September, 2018 Economic History Association Meeting,\nMontreal.\nA Surnames-Based Analysis of Tasmanian Social Mobility\n(1803–2015)\n20 May 2016, UC Berkeley, Economic History Lunch, Berkeley.\n2 May 2016, Australian National University, Research School of\nEconomics, Canberra.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:25-04:00"
    },
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-05-02T13:00:26-04:00"
    },
    {
      "path": "book.html",
      "title": "Book",
      "author": [],
      "contents": "\nMy book Telling\nStories With Data was accepted for publication by CRC Press in\nMay 2021. It is currently under development, and I’d appreciate any\nfeedback.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:26-04:00"
    },
    {
      "path": "bookshelf.html",
      "title": "Bookshelf",
      "description": "Inspired by Patrick Collison's [version](https://patrickcollison.com/bookshelf), this is an incomplete (so far) list of the books that Monica and I own in Toronto. We've been a bit more liberal than Patrick and included a section on books that we've read and would like to own. If you have recommendations, then please [get in touch](mailto:rohan.alexander@utoronto.ca). We usually only buy books that we like, but starred books are ones either Monica or I especially like. \n",
      "author": [],
      "contents": "\n\nContents\nAcademic\nNon-fiction\nFiction\nCookbooks\nWant to buy\nBest books that I read\nin:\n\nAcademic\nBryant, John, and Junni L. Zhang, ‘Bayesian Demographic Estimation\nand Forecasting’.\nChan, Ngai Hang, ‘Time Series’.\nClark, Greg, ‘The Son Also Rises’.\nDuflo, Esther, ‘Expérience, science et lutte contre la pauvreté’.\nMonica ‘borrowed’ this from the Berkeley Demography library before\nDuflo won the Nobel and now we’re not giving it back.\nFoster, Ghani, Jarmin, Kreuter, Lane, ‘Big Data and Social\nScience’.\nFrancois Chollet with JJ Allaire, ‘Deep Learning with R’.\n⭐Friedman H, Jerome, Robert Tibshirani, and Trevor Hastie,\n‘Elements of Statistical Learning’.\n⭐Gelman, Andrew and Jennifer Hill, ‘Data Analysis Using Regression\nand Multilevel Hierarchical Models’. Ah, the money-maker! Thank you\nGelman and Hill. I haven’t properly studied this book, just dipped in\nand out as needed, but Monica’s probably read it more than enough for\nboth of us.\nGelman, Andrew, Jennifer Hill and Aki Vehtari, ‘Regression and Other\nStories’. Very disappointing follow-up. Hopefully they just go\nthrough their earlier book to update and tidy, and change all the code\nto Tidyverse and Stan.\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari\nand Donald Rubin, ‘Bayesian Data Analysis’. Known as the\nold-testament in our household.\nGirosi, Federico and Gary King, ‘Demographic Forecasting’.\nHealy, Kieran, ‘Data Visualization’.\nImai, Kosuke, ‘Quantitative Social Science’.\n⭐McElreath, Richard, ‘Statistical Rethinking’. Known as the\nnew-testament in our household.\nMcLean, Ian, ‘Why Australia Prospered’.\nNeuman, Lawrence W, ‘Social Research Methods’.\nPetty, William, John Graunt and Charles Henry Hull, ‘The Economic\nWritings of Sir William Petty: Together with the observations upon the\nbills of mortality, more probably by Captain John Graunt’.\n⭐Pitman, Jim, ‘Probability’. Monica loves this book. We own\nmultiple copies.\nPreston, Samuel, Patrick Heuveline and Michel Guillot,\n‘Demography’.\nSalganik, Matthew, ‘Bit by Bit: Social Research in the Digital\nAge’.\nSmith, David and Nathan Keyfitz, ‘Mathematical Demography’.\nStewart, James, ‘Calculus’.\nTaddy, Matt, ‘Business Data Science’.\nWachter, Ken, ‘Essential Demographic Methods’.\nWakerly, Dannis, William Mengenhall, Richard Scheaffer,\n‘Mathematical Statistics with Applications’.\n⭐Wickham, Hadley, and Grolemund, Garrett, ‘R for Data Science’.\nSome people convert to Catholicism when they get married, I\nconverted to R. But my knowledge was piecemeal and going through this\nbook addressed that.\n⭐Witten, Daniela, Gareth James, Robert Tibshirani, and Trevor\nHastie, ‘Introduction to Statistical Learning’. Going through this\nwith Peter taught me a lot including: 1) if you want to learn something\nthen buy a physical copy of a textbook, get a partner and commit to\nweekly chapter reviews; 2) learn statistics from statisticians; and 3)\nstatistics is awesome and I want to learn more. I always thought that I\nwas terrible at it because econometrics never came easily to me, but now\nI realise that maybe the econometrics-approach isn’t for me, but the\nstatistics one is.\nWu, Changbao and Mary Thompson, ‘Sampling Theory and Practice’.\nNon-fiction\n‘150 Years of Stats Canada!’.\nAchatz, Grant and Nick Kokonas, ‘Life, on the Line’.\n⭐Agassi, Andre, ‘Open’. Tennis is incidental to the aspects\nthat make this book great, so try it even if you don’t particularly like\nthe sport. I can’t remember who recommended it – seems like a Nick\nCrocker type of book?\nAslett, Don, ‘Is There Life After Housework’. Got given this at\nthe Museum of Clean in Pocatello, Idaho. The museum was surprisingly\ngood!\nCarson, Anne, ‘Autobiography of Red’. Present from\nDad.\nClemens, Mark, ‘The Mountain’. Present from Dad.\nClinton, Bill, ‘My Life’.\nCrabb, Annabel, ‘Stop At Nothing’. This Turnbull bloke sounds\nlike he’d be a great prime minister.\nDennison, CJ, ‘Yesterday’s Hobart Today’. Present from\nHelen.\nEdwards, John, ‘Keating: The Inside Story’.\nElliot, Francis and James Hanning, ‘Cameron’. I haven’t yet come\nacross a good David Cameron biography, but this one was interesting.\nFocused on pre-parliament period.\nGaskell, Elizabeth, ‘The Life of Charlotte Brontë’.\n⭐Halberstam, David, ‘The Best and the Brightest’. I read\nPlato’s Republic at an impressionable age and so I used to think that if\nwe could just put the smart people in charge then the ‘right’ decisions\nwould be made. This book cured me of that.\nHolden, Anthony, ‘King Charles III’.\nHumphrey, Luke, ‘Hansons Half-Marathon Method’.\nHumphrey, Luke, ‘Hansons Marathon Method’. Bought this; followed\nthis; ran my best marathon.\nJohnson, E, Robert and Janet L Byron, ‘Berkeley Walks’.\nKelly, Paul, ‘Triumph and Demise’. Present from Dad.\nKudelka, ‘Hobart’.\nLawrence, TE, ‘Seven Pillars of Wisdom’. ‘Borrowed’ from\nDad. .\nLepore, Jill, ‘If Then’. I’ve never been so disappointed by a\nbook. So much potential.\nLevitt, Steven and Stephen Dubner, ‘Freakonomics’.\nLove, David, ‘Unfinished Business’.\nMarr, David, ‘Political Animal’.\nMcNamee, Thomas, ‘Alice Waters and Chez Panisse’.\nMears, Ashley, ‘Very Important People’.\nMegalogenis, George, ‘The Longest Decade’.\nMitchell, M. Waldrop, ‘The Dream Machine’.\nMoore, Charles, ‘Margaret Thatcher’. Present from Dad.\nNT News, ‘What a Croc: Legendary Front Pages From the NT News’.\nPresent from Mark.\nObama, Barack, ‘A Promised Land’.\nObama, Barack, ‘Audacity of Hope’.\nPetzold, Charles, ‘Code: The Hidden Language of Computer Hardware\nand Software’.\nSchlesinger, Arthur, ‘A Thousand Days’.\nSimmons, Bill, ‘The Book of Basketball’.\nSorenson, Ted, ‘Kennedy’.\nStephanopoulos, George, ‘All Too Human’. I thought that politics\nwas romantic until I read this book when I was 20.\nTrump, Donald and Tony Schwartz, ‘The Art of the Deal’. This\nbook is terrible. Read that NYT\narticle about how he really made his money instead.\nTucker, Ross and Jonathan Dugas, ‘Runner’s World: The Runner’s\nBody’.\n⭐Vanhoenacker, Mark, ‘Skyfaring’. Read this on your next\nflight.\n⭐Vaughan, Diane, ‘The Challenger Launch Decision’. One of the\ngreatest non-fiction books ever.\nWormser, Baron, ‘The Road Washes Out in Spring’. Stayed at the\nauthor’s house, so bought some of his books and particularly liked this\none about how his family lived off the grid in New England. Liked it\neven better after living in Amherst for a while.\nZ, Jay, ‘Decoded’.\nFiction\nAesop, ‘Fables’.\nAmis, Kingsley, ‘Lucky Jim’.\nAmis, Kingsley, ‘The Crime of the Century’.\nBronte, Anne, ‘Agnes Grey’.\nBronte, Anne, ‘The Tenant of Wildfell Hall’.\nBronte, Charlotte, ‘Jane Eyre’.\nBronte, Charlotte, ‘Shirley’.\nBronte, Charlotte, ‘The Professor’.\nBronte, Charlotte, ‘Villette’.\nBronte, Emily, ‘Wuthering Heights’.\nCamus, Albert, ‘Le Chute’.\nChaucer, Geoffrey, ‘The Canterbury Tales’.\nChristie, Agatha, ‘Approximately 1,000,000 different titles’.\nCrichton, Michael, ‘The Andromeda Strain’.\nDavies, Robertson, ‘The Rebel Angels’.\nDeWitt, Helen, ‘Lightning Rods’.\nDeWitt, Helen, ‘Some Trick’.\n⭐DeWitt, Helen, ‘The Last Samurai’. Nothing to do with the Tom\nCruise movie.\nDickens, Charles, ‘Oliver Twist’.\nDoyle, Arthur Conan, ‘Various titles’.\nEliot, George, ‘Middlemarch’.\nEugenides, Jeffrey, ‘Middlesex’.\nFitzgerald, Scott, ‘Tender is the Night’.\nFlanagan, Richard, ‘The Sound of One Hand Clapping’. Present\nfrom Helen.\nFleming, Ian, ‘Moonraker’.\nFleming, Ian, ‘On Her Majesty’s Secret Service’.\nGalsworthy, ‘The Silver Spoon and Passers By’.\nGalsworthy, ‘The White Monkey and A Silent Wooing’.\nGalsworthy, John, ‘The Man of Property’.\nGalsworthy, John, ‘End of the Chapter’.\nGalsworthy, John, ‘Swan Song’.\nGalsworthy, John, ‘The Forsyth Saga’.\nGrisham, John, ‘The Pelican Brief’.\nHardy, Thomas, ‘Tess of the D’Urbervilles’.\nHaruf, Kent, ‘Plainsong’.\nIshiguro, Kazuo, ‘The Unconsoled’.\nle Carré, John, ‘A Perfect Spy’. Dad likes le Carré so I buy\nthem when there’s a nice edition.\nMelchor, Fernanda, ‘Hurricane Season’.\nOndaatje, Michael, ‘The English Patient’.\nPotok, Chaim, ‘The Chosen’.\nRowling, K, J, ‘Harry Potter and the Half-Blood Prince’.\nRushdie, Salman, ‘The Moor’s Last Sigh’.\nSchulz, Charles, ‘Snoopy and the Red Baron’.\nSchulz, Charles, ‘Very Funny, Charlie Brown’.\nSeth, Vikram, ‘The Golden Gate’.\nShakespeare, William, ‘Complete Works’.\nSimson, Graeme, ‘The Rosie Project’.\nThackeray, William, ‘Vanity Fair’.\nTolstoy, Leo, ‘War and Peace’.\n⭐Waugh, Evelyn, ‘Brideshead Revisited’.\nWaugh, Evelyn, ‘Officers and Gentlemen’.\nWinton, Tim, ‘Cloudstreet’. All Australians have a copy of this.\nI think it’s in the constitution.\nWinton, Tim, ‘Island Home’. Present from Helen. There may be a\ntheme emerging.\nWinton, Tim, ‘The Shepherd’s Hut’. Present from Helen.\nCookbooks\nAlexander, Stephanie, ‘The Cook’s Companion’. Again, all\nAustralians own this.\nCountry Women’s Association of Tasmania, ‘The 21st Birthday Cookery\nBook’. My understanding, based on Helen, is that all Tasmanian women\nown this.\nEvans, Matthew, Nick Haddow and Ross O’Meara, ‘The Gourmet Farmer\nGoes Fishing’. Present from Helen.\nGrossi, Guy, ‘Italian’. Present from Angela.\nKeller, Thomas, ‘Bouchon Bakery’.\nOliver, Jamie, ‘Jamie’s 30-Minute Meals’.\nPant, Pushpesh, ‘India’.\nRedzepi, Rene and David Zilber, ‘The Noma Guide to\nFermentation’.\nWomen’s Weekly, ‘Children’s Birthday Cake Book’.\nWant to buy\nCarreyrou, John, ‘Bad Blood: Secrets and Lies in a Silicon Valley\nStartup’. About Theranos, a company that faked blood test\nresults.\nChozick, Amy, ‘Chasing Hillary’. Extended 2016 Clinton campaign\ndiary. Many (most?) campaign dairies are terrible but this is worthwhile\nreading in and of itself and the interaction with ‘Devil’s Bargain’ was\nespecially good. See notes for ‘Devil’s Bargain’.\nGreen, Joshua, ‘Devil’s Bargain’. About Bannon and his\nrelationship with Trump. Worthwhile reading in and of itself, but the\ninteraction with ‘Chasing Hillary’ was especially good. Neither is\nquantitative, but both help to understand 2016 e.g. how could the Comey\nreopening have a statistical effect? Green shows Bannon spent years\ncreating specific mainstream doubts re Clinton. Chozick shows how/why\nClinton campaign decisions accentuated them. I’m as keen on quant\npolitical analysis as anyone (shout out to @petitpoll if you want Australian\npolling!), but the snippets (and there was not much unfortunately) about\neach campaign’s quant groups made me wonder if we have a cohort issue\nATM. Specifically, do those in charge of political campaigns (or for\nthat matter many businesses) know enough quant to know it’s important,\nbut not enough to appreciate, and hence be able to compensate for, it’s\nweaknesses?\nIgnatieff, Michael, ‘Fire and Ashes: Success and Failure in\nPolitics’. Changed the way that I thought about politics. Gave my\ncopy to Amir.\nPetzinger, Thomas, ‘Hard Landing’. About the deregulation of the\nUS airline market.\nPrice A, David, ‘The Pixar Touch’. Incredible details about\ntheir overnight success, 23 years in the making.\nThiel, Peter, ‘Zero to One’. Maybe it’s the jet-lag, but is this\na business book that’s actually not terrible? A few weak chapters, but\nenough interesting ones to outweigh them.\nYanighara, Hanya, ‘A Little Life’. Recommended by\nLauren.\nBest books that I read in:\n2019\nHahahahaha, the baby was born in 2019.\n\n2018:\nCarreyrou, John, ‘Bad Blood’.\nGreen, Joshua, ‘Devil’s Bargain’.\nChozick, Amy, ‘Chasing Hillary’.\nPetzinger, Thomas, ‘Hard Landing’.\nAgassi, Andre, ‘Open’.\nDeWitt, Helen, ‘Some Trick’.\nWaldrop, Mitchell M, ‘The Dream Machine’.\nPrice, David A, ‘The Pixar Touch’.\n\n",
      "last_modified": "2022-05-02T13:00:27-04:00"
    },
    {
      "path": "canadian_election_2021_forecasting.html",
      "title": "Forecasting the 2021 Canadian Election",
      "description": "Supported by the Canadian Election Study, CANSSI Ontario, Faculty of Information, and Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nOverview\nApproaches\nPoll of polls\nPrediction markets\nEconomic fundamentals\nKitchen sink\nMultilevel\nregression with post-stratification\n\nFAQ\nContact\n\nOverview\nThe 2021 Canadian Election will be held on 20 September. The Canadian Election Study, CANSSI Ontario, Faculty of\nInformation, and Department of Statistical Sciences are calling for your\nbest forecast for the winner of each of the 338 ridings. The three\nsubmissions will be invited to present their work at a special meeting\nof the Toronto Data Workshop to be held in on 1 October.\nWe are interested in exciting approaches that blend Canadian\npolitical understanding, statistical modelling, and data in innovative\nways. We have provided some examples below, but ultimately, the approach\nis up to you. We are interested in who you think will win each riding,\nand the reasoning that underpins your approach. The full methodology\nmust be public and reproducible to be considered.\nBefore the first poll closes in the eastern states, please submit a\nlink to a GitHub repository, or Dropbox folder, that contains your data,\nmodel, and a brief write up of your approach. For ease of comparison,\nplease also include the following CSV\nwith your riding-specific forecasts.\nTo submit your forecast, please fill out this form.\nThe three invited groups will be:\nThe student team with the greatest number of seats correctly\nforecast.\nThe undergraduate team with the greatest number of seats correctly\nforecast (or the second closest team if the undergraduate team\nwins).\nThe team with the most innovative and exciting approach.\nEach team may only submit one forecast. A forecast looks like\n(options are: LPC, CPC, BQ, NDP, GPC, Other):\nriding_code\nforecast_winner\n10001\nLPC\n10002\nCPC\n10003\nBQ\n10004\nNDP\n10005\nGPC\n10006\nOther\n…\n…\nWe recommend working as part of a team, but you are welcome to work\nindividually as well.\nApproaches\nPoll of polls\n538-style poll-of-polls are popular and a useful background is\nprovided by Jackman (2005).\nOne Canadian implementation is Éric Grenier’s Poll Tracker: https://newsinteractives.cbc.ca/elections/poll-tracker/canada/.\nPoll of polls models are typically national or provincial due to data\navailability. But in the methodology section of his website (scroll to\nthe bottom of the page), Grenier discusses how riding-specific estimates\ncan be created:\n\nThe seat projection model uses a proportional swing method based on\nthe difference between the results of the last election and current\npolls. For example, if a party managed 20 per cent in Quebec in the 2019\nfederal election and is now polling at 40 per cent in Quebec, the\nparty’s 2019 election results in each riding in Quebec are doubled. This\nswing is applied to every party in each riding.\n\nOne way to implement this would be to get a list\nof the ridings and the vote share in 2019, and to then apply Grenier’s\nprovincial-specific swings to that. Some riding-specific polling is also\navailable\nand this could be used to augment such a model. Additional complications\ncould include incumbency status and features of the local candidate,\nwhich Stevens et\nal. (2019) finds could be important in\nsomething like 10 per cent of contests.\nAlternatively, you could construct your own poll-of-polls model.\nPolling data is available.\nPrediction markets\nWolfers and Zitzewitz\n(2004) provide\nan overview of the role of prediction markets and argue they ‘are\ntypically fairly accurate, and that they outperform most moderately\nsophisticated benchmarks’. The UBC Sauder School of Business has\nimplemented a prediction market for the 2021 election: https://predictionmarkets.ca. This provides the\nessential basis of a model.\nOne way to implement a riding-specific approach would be to look at\nthe relationship between the 2019 prediction market - https://predictionmarkets.ca/CA19.php - and the actual\nelection results.\nEconomic fundamentals\nBélanger\nand Godbout (2010) implement ‘a classic\npolitico-economic model’. Their baseline model considers vote share as a\nfunction of unemployment, popularity of the governing party, and the\ntenure of that governing party. To implement that on a riding-specific\nbasis:\nVarious employment-related measures are available on a riding basis\nfrom the Canada\nRevenue Agency.\nThe overall popularity of the governing party could be based on any\nhigh-quality recent poll.\nThe tenure of the Liberal is known.\nAs our focus is riding-specific, this model could also be augmented\nto include the party of the incumbent in the riding.\nMongrain (2019) implements a\nsimilar model for the 2019 Canadian election and considers additional\nvariables.\nKitchen sink\n338Canada combines all of\nthe above along with demographics to produce estimates on a\nriding-specific basis. Some information about methodology is available:\nhttps://338canada.blogspot.com/2018/11/welcome-to-338canada.html#metho.\nThe essentials are similar to the Grenier uniform swing approach, with\nsome differences due to demographics and star candidates.\nMultilevel\nregression with post-stratification\nMultilevel regression with post-stratification (MRP) is one way to\nforecast an election. It trains a model on a survey, and then applies\nthat trained model to another dataset. It can be used to generate\nestimates for all 338 ridings, however the trade-off is increased\nuncertainty. Some notes about MRP with worked examples and supporting\nliterature are available here: https://www.tellingstorieswithdata.com/mrp.html.\nIf you are interested in implementing a MRP model, then please use\nthe 2019 CES data for the ‘survey’. Stephenson et al. (2021) provides important background. We\nwill provide access to the following 2021 CES data - age-group, gender,\nhighest education - after the election is finished that you can use to\nre-run your model and see what your model would have forecast. We are\nnot releasing the real 2021 CES data before the election because we do\nnot want there to be any potential concern that the CES is affecting the\nelection in any way.\nSome post-stratification data is available here.\nFAQ\nHow can I complicate the model? One way is to consider different\nfunctional specifications. Another way is to add additional layers to\nthe model, for instance finding extra information about each riding\n(hint: maybe past vote and incumbency!) and adding that to your model.\nOften the best forecasts are made by teams that combine an understanding\nof politics with statistics.\nCan I work as part of a team? Yes, that is recommended.\nContact\nFor any questions or comments, please contact Rohan Alexander: rohan.alexander@utoronto.ca.\n\n\n\nBélanger, Éric, and Jean-François Godbout. 2010. “Forecasting\nCanadian Federal Elections.” PS: Political Science &Amp;\nPolitics 43 (4): 691–99. https://doi.org/10.1017/S1049096510001113.\n\n\nJackman, Simon. 2005. “Pooling the Polls over an Election\nCampaign.” Australian Journal of Political Science 40\n(4): 499–517.\n\n\nMongrain, Philippe. 2019. “2019 Canadian Federal Election –\nForecasts for the Incumbent Party.” https://www.chairedemocratie.com/2019/10/22/2019-canadian-federal-election-forecasts-for-the-incumbent-party/.\n\n\nStephenson, Laura B, Allison Harell, Daniel Rubenson, and Peter John\nLoewen. 2021. “Measuring Preferences and Behaviours in the 2019\nCanadian Election Study.” Canadian Journal of Political\nScience/Revue Canadienne de Science Politique 54 (1): 118–24.\n\n\nStevens, Benjamin Allen, Md Mujahedul Islam, Roosmarijn de Geus, Jonah\nGoldberg, John R McAndrews, Alex Mierke-Zatwarnicki, Peter John Loewen,\nand Daniel Rubenson. 2019. “Local Candidate Effects in Canadian\nElections.” Canadian Journal of Political Science/Revue\nCanadienne de Science Politique 52 (1): 83–96.\n\n\nWolfers, Justin, and Eric Zitzewitz. 2004. “Prediction\nMarkets.” Journal of Economic Perspectives 18 (2):\n107–26. https://doi.org/10.1257/0895330041371321.\n\n\n\n\n",
      "last_modified": "2022-05-02T13:00:28-04:00"
    },
    {
      "path": "doss_toolkit-hiring.html",
      "title": "DoSS Toolkit - Call for applications",
      "author": [],
      "contents": "\nU of T students - please search the job id - 171201 Research\nAssistant - under oncampus jobs and associated job posting. For\ntheir support of this call we thank: the PIE Fund, and especially\nBethany White and Radu Craiu from the Department of Statistical Sciences\n(DoSS).\nCall for applications\n10 October 2020\nAre you an undergraduate or graduate student at the Univeristy of\nToronto? Would you like to work with Sam-Jo Caetano and Rohan Alexander\nto help put together a toolkit for applied statistics? It’s focused on R\nessentials such as ggplot, tidyverse, GitHub, and all their friends.\nIf so, please send an email to rohan.alexander@utoronto.ca with the subject line\n‘DoSS toolkit application’. Please attach one PDF that contains both a\ncover letter and a CV. As part of your cover letter, please include a\nlink to a GitHub repo showing off some code that you’ve written, or if\nyou don’t have that, a blogpost you’ve written that is of a\nstatistical/quantitative/technical nature.\nApplications will be reviewed on a rolling basis, but the final\ndeadline to apply is the end of Wednesday, 21 October 2020.\nThe normal RA hourly rate and conditions will apply.\nApplications from people that have been under-represented in\nstatistical sciences are particularly encouraged.\nBy way of background, we are looking to employ a small team of\nundergraduate and graduate students to help build a set of instructional\nmaterial about R that will be used across DoSS starting in Winter (and\nhopefully soon after that, the broader university and community). This\nwill build on work already done by a bunch of DoSS folks including\nBethany White and Nathan Taback, and of course build on and complement\nthe first-year courses.\nYou will help put together written material, videos, and assessment.\nYou will be credited as a contributor to what will be a public-facing\nresource. You will have a chance to develop your R, teaching, and\ncommunication skills, as well as gain experience working in a small\nteam.\nWe expect you to have some familiarity with R (i.e. have used it for\na course or two), but you do NOT need to be an R expert. Indeed some\nsuccessful applications may be in their first term with R.\nThe majority of the work will occur in early/mid November, but your\nappointment will run from November through to January to help deal with\nany lingering minor issues. The total time commitment would vary from 20\nto 60 hours, depending on your circumstances and availability. The work\nis flexible and can be done at a time that suits you. Given we are in a\npandemic, the work will be conducted remotely. Most day-to-day\nmanagement will occur through Slack and GitHub.\nWe hope you apply!\nRohan and Sam\n\n\n\n",
      "last_modified": "2022-05-02T13:00:29-04:00"
    },
    {
      "path": "foundations_of_the_data_sciences.html",
      "title": "Foundations of data sciences",
      "description": "The data sciences have a common concern: How can others be confident that our statistical approaches have been brought to bear on appropriate datasets? This course focuses on the 'data' of the data sciences. It develops in students an appreciation for the many ways in which dealing with a dataset can get out-of-hand, and establishes approaches to ensure data science is conducted in ways that engenders trusted findings. It focuses on everything that comes before modelling, and by focusing on those steps places modelling and analysis on a more firm foundation.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nLearning objectives\nPre-requisites\nTextbook\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nQuiz\nTutorial\nPaper #1\nPaper #2\nPaper #3\nPaper #4\nFinal Paper\n\nOther\nChildren in the\nclassroom\nAccommodations\nwith regard to assessment\nRe-grading\nPlagiarism and\nintegrity\nLate policy\nWriting\nMinimum submission\nrequirement\n\n\nPreamble\nOverview\nThe course will be an enormous amount of work and cause you some\namount of stress. This is unfortunate, but there’s little way around it.\nAll I can tell you is that having done this course, it’ll be easier in\nthe future.\nThe purpose of this course is to develop students who appreciate, and\ncan iterate on, the foundations of the data sciences.\nThis course will require students to:\nactively read and consider a large amount of literature;\nactively learn the statistical programming language R and apply it\nto real-world conditions;\ngather, clean, and prepare their own datasets; and\ndevelop killer statistics skills.\nEssentially this course provides students with everything that they\nneed to know to be able to do the most exciting thing in the world: use\ndata to tell convincing stories.\nFAQ\nCan I audit this course? Sure, but it’s pointless, because the only\nway to learn this stuff is to do the work.\nWhat is a tutorial? You write a paper. Then you send it to your\ntutor. The next day you have a meeting, ‘tutorial’, where you discuss it\nwith them.\nWhy is there so much assessment? The only way to learn is to\nactually do the work, and students only do the work when they are\nassessed. It’s unfortunate, but there’s no way around it.\nLearning objectives\nThe purpose of the course is to develop the core skills common to all\nof the data sciences across academia and industry. By the end of the\ncourse, you should be able to:\nEngage critically with ideas and readings in data science.\nConduct research in data science in a reproducible and ethical\nway.\nWrite and present your research.\nUnderstand what constitutes ethical high-quality data science\npractice, especially reproducibility and respect for those that underpin\nour data.\nRespectfully identify strengths and weaknesses in the data science\nresearch conducted by others.\nDevelop the ability to appropriately choose and apply statistical\nmodels to real-world situations.\nConduct all aspects of the typical data science workflow.\nReflect effectively on your own learning and professional\ndevelopment.\nPre-requisites\nNone.\nTextbook\nTelling Stories with\nData\nContent\nWeek 1\nIntroduction\nSeveral\nend-to-end worked examples: Canadian elections; Toronto\nhomelessness; and neonatal mortality.\nWeek 2\nR\nEssentials: R, R Studio, and R Studio Cloud; the dplyr\nverbs; base; ggplot2; and tidyverse.\nWeek 3\nReproducible\nworkflow: Reproducibility; R Markdown; R projects and file\nstructure; Git and GitHub; and R in practice.\nWeek 4\nWriting:\nDeveloping research questions; and writing.\nWeek 5\nStatic\ncommunication: Graphs; tables; and maps.\nWeek 6\nInteractive\ncommunication: Websites; interactive maps; and\nShiny.\nWeek 7\nGather\ndata: Sampling essentials; APIs; web scraping; and PDFs.\nWeek 8\nHunt\ndata: Experiments and randomized controlled trials; A/B testing; and\nimplementing surveys.\nFarm\ndata: Censuses.\nWeek 9\nClean\nand prepare data: Workflow; case study; checks and tests; and\nnames.\nWeek 10\nStore\nand share data: GitHub; R packages; depositing data; documentation;\nand personally identifying information.\nWeek 11\nExploratory\ndata analysis: Exploring individual variables; relationships between\nvariables; and multiple relationships.\nWeek 12\nIt’s\nJust A Linear Model: Simple linear regression; multiple linear\nregression; logistic regression; and Poisson regression.\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nQuiz\n10\nWeekly, end of each week\nTutorial\n10\nWeekly, end of each week\nPaper 1\n25\nFriday, noon, Week 4\nPaper 2\n25\nFriday, noon, Week 6\nPaper 3\n25\nFriday, noon, Week 8\nPaper 4\n25\nFriday, noon, Week 10\nFinal Paper (initial submission)\n1\nWednesday, noon Week 12\nFinal Paper (peer review)\n4\nFriday, noon, Week 12\nFinal Paper\n25\nTwo weeks after that\nYou must submit Paper 1. And you must submit the Final Paper.\nBeyond that, you have scope to pick an assessment schedule that works\nfor you. We will take your best two of the eleven tutorials for that 10\nper cent, and your best four of eleven quizzes for that 10 per cent. And\nwe will take your two best papers from Papers 1-4 for that 50 per cent\n(25 per cent for each). The remainder is made up of 1 per cent for\nsubmitting a draft of the Final Paper, 4 per cent for peer reviewing\nother people’s drafts of the Final Paper, and 25 per cent for the Final\nPaper.\nAdditional details:\nQuiz questions are drawn from those in the Quiz section that follows\neach chapter of Telling Stories with Data. Almost all of them\nare multiple choice, and you should expect to know the mark within a few\ndays of submission.\nTutorial questions are drawn from those in the Tutorial section that\nfollows each chapter of Telling Stories with Data. The general\nexpectation (although this differs from week to week) is about two pages\nof written content, which the tutor will read, discuss with you, and\nthen provide a mark. You should expect to know the mark within a few\ndays of the tutorial.\nIn general papers require a considerable amount of work, and are due\nafter the material has been covered in quizzes and tutorials (i.e. you\nwould draw on knowledge tested in the quizzes, and potentially material\ncould be re-used from the tutorial material). In general, they require\noriginal work to some extent. Papers are taken from the Papers appendix\nof Telling Stories with Data and students have access to the\ngrading rubrics before submission.\nQuiz\nDue date: Friday, noon, weekly (with grace period through to Sunday,\nmidnight, to submit without penalty).\nWeight: 10 per cent. Only best four out of eleven count.\nTask: Please complete a weekly quiz.\nTutorial\nDue date: Friday, noon, weekly (with grace period through to Sunday,\nmidnight, to submit without penalty).\nWeight: 10 per cent. Only best two out of eleven count.\nTask: Please complete a tutorial question.\nRubric:\n0 - Any typos, major grammatical errors, other table stakes issues\nfor this level. Too short.\n0.25 - Grammatical errors, if relevant: tables/graphs not properly\nlabeled, no references, other aspects that affect credibility.\n0.6 - Makes some interesting and relevant points, related to course\nmaterial (including required materials), but lacking in terms of\nstructure and story/argument.\n0.80 - Interesting paper that is well-structured, coherent, and\ncredible.\n1 - As with 0.80, but exceptional in some way.\n\nPaper #1\nYou must submit this paper.\nTask: Paper\nOne\nDue date: Friday, noon, Week 4 (with grace period through to Sunday,\nmidnight, to submit without penalty).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncount).\nPaper #2\nDue date: Friday, noon, Week 6 (with grace period through to Sunday,\nmidnight, to submit without penalty).\nTask: Paper\nTwo\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #3\nDue date: Friday, noon, Week 8 (with grace period through to Sunday,\nmidnight, to submit without penalty).\nTask: Paper\nThree\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #4\nDue date: Friday, noon, Week 10 (with grace period through to\nSunday, midnight, to submit without penalty).\nTask: Paper\nFour\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nFinal Paper\nTask: Final\nPaper\nYou must submit this paper.\nDue dates:\nInitial submission: Wednesday, noon, Week 12 (no grace period and no\nlate submissions accepted).\nPeer review: Friday, noon, Week 12 (no grace period and no late\nsubmissions accepted).\nFinal Paper: Two weeks after that (with grace period through to\nSunday, midnight, to submit without penalty).\n\nWeight: 30 per cent\nInitial submission: 1 per cent\nPeer review: 4 per cent\nFinal Paper: 25 per cent\n\nOther\nChildren in the classroom\nBabies (bottle-feeding, nursing, etc) are welcome in class as often\nas necessary. You are welcome to take breaks to feed your infant or\nexpress milk as needed, either in the classroom or elsewhere including:\nhttps://familycare.utoronto.ca/childcare/breastfeeding-at-u-of-t/.\nA list of baby change stations is also available: https://familycare.utoronto.ca/childcare/baby-change-stations-at-u-of-t/.\nPlease communicate with me so that I can make sure that we have regular\nbreaks to accommodate this. For older children, I understand that\nunexpected disruptions in childcare can happen. You are welcome to bring\nyour child to class in order to cover unforeseeable gaps in\nchildcare.\nAccommodations with\nregard to assessment\nPlease do not reveal your personal or medical\ninformation to me. I understand that illness or personal emergencies can\nhappen from time to time. The following accommodations to assessment\nrequirements exist to provide for those situations.\nStraight-forward (will automatically apply to all students - there’s\nno need to ask for these):\nQuiz: Only best four quizzes count.\nTutorial: Only best two tutorials count.\nPapers #1-#4: Worst two are dropped.\nSo for those (with the exception of Paper #1), if you have a\nsituation, then just don’t submit.\nSlightly more involved:\nPaper #1: You must submit something for Paper #1, even if it gets\nzero. If you have a medical reason that makes it impossible for you to\nsubmit Paper #1, then you are welcome to continue with the class, but\nthen one of the remaining term papers (Papers #2 - #4), must be done\nindividually to ensure fairness with the rest of the class.\nPeer review: No accommodation or late submission is possible for\nthis because it would hold up the rest of the class. If you cannot\nsubmit then email me before the deadline and the weight will be shifted\nto the final paper.\nFinal paper: The final paper is a critical piece of assessment. It’s\nalso up against deadlines for submission of grades. Extensions for valid\nreasons may be granted for a maximum of three days, however this isn’t\npossible for all students (i.e. there are restrictions around graduating\nstudents). Hence, the exact extension need to be at my discretion. To be\nconsidered, an extension request must be sent to rohan.alexander@utoronto.ca by the business day before\nthe due date so there is time to get advice from the Faculty about your\nparticular circumstance.\nRe-grading\nRequests to have your work re-graded will not be accepted within 24\nhours of the release of grades. This is to give you a chance to reflect.\nSimilarly, requests to have your work re-graded more than seven days\nafter the release of the grades will not be accepted. This is to ensure\nthe course runs smoothly.\nInside that 1-7 day period if you would like to request a re-grade,\nplease email rohan.alexander@utoronto.ca. Please specify where the\nmarking error was made in relation to the marking guide. The entire\nassessment will be re-marked and it is possible that your grade could\nreduce.\nPlagiarism and integrity\nPlease do not plagiarize. In particular, be careful to acknowledge\nthe source of code - if it’s extensive then through proper citation and\nif it’s just a couple of lines from Stack Overflow then in a comment\nimmediately next to the code.\nYou are responsible for knowing the content of the University of\nToronto’s Code of Behaviour on Academic Matters.\nAcademic offenses includes (but is not limited to) plagiarism,\ncheating, copying R code, communication/extra resources during closed\nbook assessments, purchasing labor for assessments (of any kind).\nAcademic offenses will be taken seriously and dealt with accordingly. If\nyou have any questions about what is or is not permitted in this course,\nplease contact me.\nPlease consult the University’s site on Academic Integrity http://academicintegrity.utoronto.ca/. Please also see\nthe definition of plagiarism in section B.I.1.(d) of the University’s\nCode of Behaviour on Academic Matters http://www.governingcouncil.utoronto.ca/Assets/Governing+Council+Digital+Assets/Policies/PDF/ppjun011995.pdf.\nPlease read the Code. Please review Cite it Right and if you require\nfurther clarification, consult the site How Not to Plagiarize http://advice.writing.utoronto.ca/wp-content/uploads/sites/2/how-not-to-plagiarize.pdf.\nLate policy\nYou are expected to manage your time effectively. If no extension has\nbeen granted and no accommodation applies, then the late submission of\nan assessment item carries a penalty of 10 percentage points per day to\na maximum of one week after which it will no longer be accepted, e.g. a\nproblem set submitted a day late that would have otherwise received 8/10\nwill receive 7/10, if that same problem set was submitted two days late\nthen it would receive 6/10.\nWriting\nPapers and reports should be well-written, well-organized, and easy\nto follow. They should flow easily from one point to the next. They\nshould have proper sentence structure, spelling, vocabulary, and\ngrammar. Each point should be articulated clearly and completely without\nbeing overly verbose. Papers should demonstrate your understanding of\nthe topics you are studying in the course and your confidence in using\nthe terms, techniques and issues you have learned. As always, references\nmust be properly included and cited. If you have concerns about your\nability to do any of this then please make use of the writing support\nprovided to the faculty, colleges and the SGS Graduate Centre for\nAcademic Communication.\nMinimum submission\nrequirement\nIf you are going to not be able to submit at least two term papers,\nand/or be unable to submit the final paper then it would be unfair on\nthe other students to allow you to pass the course. Please ensure you\nand your registrar get in touch with me as early as possible if this may\nbe the case for you.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:29-04:00"
    },
    {
      "path": "group.html",
      "title": "Research Group",
      "author": [],
      "contents": "\n\nContents\nOverview\nPeople\nFaculty affiliates\nIndustry affiliates\nStudents\n\n\n\n\n\nThanks to Paul Hodgetts for the\nfantastic logo.\nOverview\nMy research group exists to:\nconduct research at the intersection of information and statistical\nsciences;\nbring together researchers and practitioners from various academic\ndisciplines and industry; and\nprovide high-quality training opportunities for students.\nWe organize the Toronto Data Workshop, which everyone is welcome to\nattend - sign up here.\nWe also maintain an internal reading group and presentation\nschedule.\nPeople\nFaculty affiliates\nKelly\nLyons.\nSamantha-Jo\nCaetano.\nIndustry affiliates\nSharla Gelfand.\nHareem Naveed.\nStudents\nStudents are equal partners, have considerable autonomy, are given\nco-authorship, and are paid. They take ownership of their project and\ncontribute critically to its success.\n\n\n\nCurrent\nAmy Farrow is a Master of Information student at\nthe University of Toronto.\nAnnie Collins is an undergraduate student at the\nUniversity of Toronto specializing in applied mathematics and statistics\nwith a minor in history and philosophy of science. Annie worked on ‘An Introduction to\nDoSStoolkit’ and ‘Reproducibility of COVID-19\npre-prints’.\nDan Xu is a doctoral student in the Faculty of\nInformation at the University of Toronto. His research focus is on\nmisinformation propagation in politics.\nKe-Li Chiu is a Master of Information student at\nthe University of Toronto interested in natural language processing.\nKe-Li worked on: ‘On\nconsistency scores in text data with an implementation in R’ and ‘Detecting Hate Speech with\nGPT-3’.\nPaul Hodgetts is a Master of Information student at\nthe University of Toronto. Paul put together cesR, which is\nan R package that makes it easier to gather and use the Canadian\nElection Study surveys from 1965 through to 2019, described here: https://osf.io/preprints/socarxiv/a29h8/. Work in\nprogress involves estimates of stateless populations.\nPast\nA Mahfouz worked with me as a Master of Information\nstudent at the University of Toronto with a background in geography.\nTheir prior work has been largely concerned with data pipelines. A\ncontributed to many projects including: 1) heapsofpapers\nwhich is an R package that makes it easier to respectfully download\nfiles from the internet. 2) ‘Discussions of bias in AI/ML research’: In\nthis paper we gather a sample of recent AI/ML research and use natural\nlanguage processing to understand the extent to which bias, in an\nethical rather than statistical sense, is considered. 3) ‘Communicating\ngeographically-based Bayesian models’: In this paper we introduce a\nmethod to communicate the geographic results of Bayesian models.\nDiego Mamanche Castellanos worked with me as a\nMaster of Information student at the University of Toronto, to which he\nbrought more than six years of experience in financial companies. Diego\nfocused on the paper, ‘Understanding OCR in the context of a broader\nstatistical workflow’.\nHidaya Ismail worked with me as a Master of\nInformation student at the University of Toronto. Hidaya focused on\nextracting and organising data from websites, in particular TikTok.\nYian Wang worked with me as an undergraduate\nstudent studying for an Honours Bachelor of Science degree with majors\nin statistics and economics and a minor in mathematics. Yian is\ninterested in surveys and current work involves understanding the effect\nof COVID shutdowns on the restaurant industry.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:30-04:00"
    },
    {
      "path": "history_of_the_data_sciences.html",
      "title": "History of statistics and data sciences",
      "description": "Statistics and the data sciences have a long and robust history. Understanding that history provides students with a better appreciation for the methods that they are applying today.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nLearning objectives\nPrerequisites\nTextbooks\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nTutorial papers\nFinal Paper\n\n\nPreamble\nOverview\nOften students are taught, say, linear regression in such a way that\nthey come to believe that statisticians simply stumbled upon it one day.\nIn fact, the idea of combining different observations in this way, took\nthe work of decades and even centuries to come to terms with.\nUnderstanding the history of statistics and data sciences, more\ngenerally, provides a more solid foundation for applying those skills\ntoday. We are interested in why certain methods were developed, and\nbecame popular, and the circumstances under which this occurred because\nthat provides us with a nuanced knowledge of when we should apply them\nourselves.\nWe study history because we want to understand how our predecessors\nsolved their problems. That means understanding, not just what they did,\nbut the circumstances in which they did it, and the choices they faced.\nThat knowledge allows us to better solve our own problems. At the very\nleast, it helps us to avoid repeating mistakes; and, if fully\naccomplished, can even allow to improve our own approaches.\nThe history of statistics and the data sciences is one of greatness,\nand we will cover that extensively. But it also one in which that\ngreatness was sometimes developed for abhorrent purposes, and there were\nmany contributors, actual or potential, who were overlooked. We will\ncover these aspects too.\nThe hope is that having taken this course, you will understand what\nyou have been studying in statistics and the data sciences with fresh\neyes, and bring this deeper appreciation with you throughout the rest of\nyour career.\nLearning objectives\nThe purpose of the course is to develop an appreciation of history of\nstatistics and the data sciences to such an extent so as to provide a\nfirmer foundation for your conduct of applied statistics and data\nscience. By the end of the course, you should be able to:\nEngage critically with ideas and readings in the history of\nstatistics and data sciences.\nConduct research in the history of data science and statistics.\nWrite and present your research.\nUnderstand why the methods and approaches developed when they did,\nand the circumstances under which they developed.\nAppreciate that much of the statistical machinery that we use today\nwas developed with respect to eugenics.\nRespectfully identify strengths and weaknesses in the work of\nothers.\nReflect effectively on your own learning and professional\ndevelopment.\nPrerequisites\nAt least 1.0 FCE 300+ level STA courses with a minimum grade of 80\nper cent in each course.\nTextbooks\nStigler, S, 1986, The History of Statistics: The Measurement of\nUncertainty before 1900, Harvard University Press.\nFriendly, M, and Wainer, H, 2021, A History of Data\nVisualization and Graphic Communication, Harvard University\nPress.\nSheynin, 2017, Theory of Probability. A Historical Essay,\nhttps://arxiv.org/abs/1802.09966,\nContent\nWeek 1\nOverview. Also early astronomical and gambling underpinnings. Least\nsquares, combining observations, and uncertainty. Legendre, Laplace,\nBernoulli, De Moivre, Simpson.\nContent:\nStephen E. Fienberg, 1992, ‘A Brief History of Statistics in Three\nand One-Half Chapters: A Review Essay’, Statistical\nScience.\nM. G. Kendall, 1960, ‘Studies in the History of Probability and\nStatistics. Where Shall the History of Statistics Begin?’,\nBiometrika.\nStigler, 1986, Chs 1-2.\nIan Hacking, 2006, The Emergence of Probability.\n\nWeek 2\nFocuses on the 1700s, especially inverse probability. Gauss, Laplace,\nCentral Limit Theorem.\nContent:\nStigler, 1986, Chs 3-4\nSheynin, 2017, Chs 1-7.\n\nWeek 3\nEarly 1800s, and moves to the social sciences. Quetelet, Poisson,\nCournot, Lexis, binomials and Law of Large Numbers.\nContent:\nStigler, 1986, Chs 5-6.\nSheynin, 2017, Chs 8-9.\n\nWeek 4\nLate 1800s and heredity. Galton, Edgeworth, and Pearson. Regression\nand correlation.\nContent:\nStigler, 1986, Chs 7-8.\nSheynin, 2017, Chs 10-11.\nDavid Salsburg, 2002, The Lady Tasting Tea.\nTheodore M. Porter, 2020, The Rise of Statistical Thinking,\n1820–1900.\n\nWeek 5\nLate 1800s and early 1900s. Edgeworth, Pearson, and Yule. Regression,\nand correlation.\nContent:\nStigler, 1986, Chs 9-10.\nDavid Freedman, 1999, ‘From association to causation: some remarks\non the history of statistics’.\nDonald MacKenzie, 1981, Statistics in Britain, 1865-1930: The\nSocial Construction of Scientific Knowledge.\nErich Lehmann, 2011, Fisher, Neyman, and the Creation of\nClassical Statistics, Springer.\n\nWeek 6\nEarly 1900s\nStephen M. Stigler, 1996, ‘The History of Statistics in 1933’,\nStatistical Science\nSheynin, 2017, Chs 12-15.\nStephen M. Stigler, 2016, The Seven Pillars of Statistical\nWisdom.\nJan von Plato, 1994, Creating Modern Probability.\nErich Lehmann, 2007, Reminiscences of a Statistician.\nWeek 7\nSpecial topic: Data visualization\nContent:\nFriendly and Wainer, 2021, Chs 1-6 and 9.\n\nWeek 8\nSpecial topic: Bayesian methods\nContent:\nStephen E. Fienberg, 2006, ‘When Did Bayesian Inference Become\n“Bayesian”?’, Bayesian Analysis.\nThomas Hoskyns Leonard, 2014, ‘A personal history of Bayesian\nstatistics’, WIREs Computational Statistics.\nSharon Bertsch McGrayne, 2012, The Theory That Would Not\nDie.\nWilliam D. Nordhaus, ‘An Economic History of Computing’.\nDennis V. Lindley, 2001, ‘The Philosophy of Statistics’, Journal\nof the Royal Statistical Society: Series D.\n\nWeek 9\nSpecial topic: Causal inference\nContent:\nJudea Pearl and Dana Mackenzie, 2018, Book of Why, Ch\n2.\n\nWeek 10\nSpecial topic: Whither statistics? The rise of data science\nContent:\nLeo Breiman, 2001, ‘Statistical Modeling: The Two Cultures’,\nStatistical Sciences.\nDavid J. Hand, 2015, ‘Statistics and computing: the genesis of data\nscience’, Statistics and Computing.\nDavid Donoho, 2017, ‘50 Years of Data Science’, Journal of\nComputational and Graphical Statistics.\n\nWeek 11\nSpecial topic: Overlooked contributors\nContent:\nMargo Anderson, 1992, ‘The History of Women and the History of\nStatistics’, Journal of Women’s History\nKatie Hafner, 2021, ‘Arianna Rosenbluth Dies at 93; Pioneering\nFigure in Data Science’, New York Times.\nKitagawa–Blinder–Oaxaca decomposition.\nMary E. Thompson, ‘Reflections on women in statistics in Canada’, in\nXihong Lin, et al., eds, 2014, Past, present, and future of\nstatistical science, CRC Press.\nNancy M. Reid, ‘The whole women thing’, in Xihong Lin, et al., eds,\n2014, Past, present, and future of statistical science, CRC\nPress.\nLouise M. Ryan, ‘Reflections on diversity’, in Xihong Lin, et al.,\neds, 2014, Past, present, and future of statistical science,\nCRC Press.\n\nWeek 12\nSpecial topic: Reckoning with the past and thinking about the future.\nStatistics and society.\nContent:\nHow to consider our history?\nAlain Desrosières, 2002, The Politics of Large Numbers,\nHarvard University Press.\nXihong Lin, et al., eds, 2014, Past, present, and future of\nstatistical science, CRC Press.\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nTutorial\n60\nFortnightly before the lecture\nFinal Paper\n40\nTen days after that\nTutorial papers\nDue date: Fortnightly before the lecture.\nWeight: Each is worth 10 per cent.\nTask: Write a paper of 2-6 pages on a topic covered in the preceding\ntwo weeks. These will be circulated and discussed in class.\nFinal Paper\nDue dates: Final day of exam block.\nWeight: 40 per cent.\nTask: Write an original paper on a topic covered in the class.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:30-04:00"
    },
    {
      "path": "index.html",
      "title": "Rohan Alexander",
      "author": [],
      "contents": "\n\n          \n          \n          Rohan Alexander\n          \n          \n          Home\n          Academic\n          Group\n          Teaching\n          Toronto Data Workshop\n          Blog\n          \n          \n          Other\n           \n          ▾\n          \n          \n          Bookshelf\n          Toronto Workshop on Reproducibility\n          \n          \n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Rohan Alexander\n            \n            \n              \n                \n                    \n                      \n                        Twitter\n                      \n                    \n                  \n                                    \n                    \n                      \n                        GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                        CV\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Email\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            \n            I am an assistant professor at the University of Toronto\n            in Information\n            and Statistical\n            Sciences. I am also the assistant director of CANSSI Ontario,\n            a senior fellow at Massey College, a\n            faculty affiliate at the Schwartz Reisman\n            Institute for Technology and Society, and a co-lead of\n            the DSI\n            Thematic Program in Reproducibility.\n            I hold a PhD in Economics from the Australian National\n            University where I focused on economic history and was\n            supervised by John\n            Tang (chair), Martine\n            Mariotti, Tim\n            Hatton, and Zach\n            Ward.\n            My book on foundational data skills, tentatively titled\n            Telling\n            Stories With Data, was accepted for publication by\n            CRC Press in May 2021. And I am co-editor (alongside Lauren Kennedy and\n            Andrew\n            Gelman) of a book tentatively titled Multilevel\n            Regression and Poststratification: A Practical Guide and New\n            Developments, which was accepted for publication by\n            Cambridge University Press in July 2021.\n            I use statistical models to try to understand the world.\n            I am particularly interested in: how we get the data that go\n            into those models; whose data are systematically missing;\n            how we clean, prepare, and tidy data before they are\n            modelled; the effects of all this on the implications of our\n            models; and how we can reproducibly share the totality of\n            this process. This research interest has a few different\n            applications. One of those is Natural Language Processing\n            (NLP), where I am interested in understanding the effects of\n            bringing together large, biased datasets and enormous\n            models, and how this can be improved. Another is Multilevel\n            Regression with Post-stratification (MRP), where I examine\n            the effects of trying to establish a correspondence between\n            two datasets.\n            Students in my research\n            group develop skills not only in using statistical\n            methods in reproducible ways across various disciplines, but\n            also appreciate their limitations, and think deeply about\n            the broader context of their work. Some recent papers\n            include: ‘Reproducibility of\n            COVID-19 pre-prints’, ‘heapsofpapers’,\n            ‘Detecting Hate\n            Speech with GPT-3’, and ‘On consistency\n            scores in text data with an implementation in R’.\n            I enjoy teaching\n            and aim to help students from a wide range of backgrounds\n            learn how to use data to tell convincing stories. In the\n            Faculty of Information, I have taught ‘Experimental\n            Design’ and lead reading courses in ‘Ethics\n            and Data Science’, ‘Information Management in\n            Interdisciplinary Research’ and ‘Reproducible Data Science’.\n            In Statistical Sciences I have taught ‘Surveys,\n            Sampling, and Observational Data’ and lead a reading\n            course in ‘Natural\n            Language Processing’. I am a RStudio\n            Certified Tidyverse Trainer and an associate editor of\n            the Journal of Statistics and Data Science\n            Education.\n            I co-organize the weekly Toronto\n            Data Workshop. All welcome! Sign up here.\n            \n            \n            \n            I am married to Monica Alexander,\n            and we have two young children. I probably spend too much\n            money on books, and certainly too much time at libraries (in\n            a pre-COVID world). You can see some of the books that I\n            recommend here.\n            If you have any book recommendations of your own, then I’d\n            love to hear them.\n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Rohan Alexander\n            \n            \n              \n                \n                                    \n                    \n                      Twitter\n                    \n                  \n                                    \n                    \n                      GitHub\n                    \n                  \n                                    \n                    \n                      CV\n                    \n                  \n                                    \n                    \n                      Email\n                    \n                  \n                                  \n              \n            \n            \n              \n              I am an assistant professor at the University of\n              Toronto in Information\n              and Statistical\n              Sciences. I am also the assistant director of CANSSI\n              Ontario, a senior fellow at Massey College, a\n              faculty affiliate at the Schwartz Reisman\n              Institute for Technology and Society, and a co-lead of\n              the DSI\n              Thematic Program in Reproducibility.\n              I hold a PhD in Economics from the Australian National\n              University where I focused on economic history and was\n              supervised by John\n              Tang (chair), Martine\n              Mariotti, Tim\n              Hatton, and Zach\n              Ward.\n              My book on foundational data skills, tentatively titled\n              Telling\n              Stories With Data, was accepted for publication\n              by CRC Press in May 2021. And I am co-editor (alongside Lauren Kennedy\n              and Andrew\n              Gelman) of a book tentatively titled Multilevel\n              Regression and Poststratification: A Practical Guide and\n              New Developments, which was accepted for publication\n              by Cambridge University Press in July 2021.\n              I use statistical models to try to understand the\n              world. I am particularly interested in: how we get the\n              data that go into those models; whose data are\n              systematically missing; how we clean, prepare, and tidy\n              data before they are modelled; the effects of all this on\n              the implications of our models; and how we can\n              reproducibly share the totality of this process. This\n              research interest has a few different applications. One of\n              those is Natural Language Processing (NLP), where I am\n              interested in understanding the effects of bringing\n              together large, biased datasets and enormous models, and\n              how this can be improved. Another is Multilevel Regression\n              with Post-stratification (MRP), where I examine the\n              effects of trying to establish a correspondence between\n              two datasets.\n              Students in my research\n              group develop skills not only in using statistical\n              methods in reproducible ways across various disciplines,\n              but also appreciate their limitations, and think deeply\n              about the broader context of their work. Some recent\n              papers include: ‘Reproducibility\n              of COVID-19 pre-prints’, ‘heapsofpapers’,\n              ‘Detecting Hate\n              Speech with GPT-3’, and ‘On consistency\n              scores in text data with an implementation in R’.\n              I enjoy teaching\n              and aim to help students from a wide range of backgrounds\n              learn how to use data to tell convincing stories. In the\n              Faculty of Information, I have taught ‘Experimental\n              Design’ and lead reading courses in ‘Ethics\n              and Data Science’, ‘Information Management in\n              Interdisciplinary Research’ and ‘Reproducible Data\n              Science’. In Statistical Sciences I have taught ‘Surveys,\n              Sampling, and Observational Data’ and lead a reading\n              course in ‘Natural\n              Language Processing’. I am a RStudio\n              Certified Tidyverse Trainer and an associate editor of\n              the Journal of Statistics and Data Science\n              Education.\n              I co-organize the weekly Toronto\n              Data Workshop. All welcome! Sign up here.\n              \n              \n              \n              I am married to Monica\n              Alexander, and we have two young children. I probably\n              spend too much money on books, and certainly too much time\n              at libraries (in a pre-COVID world). You can see some of\n              the books that I recommend here.\n              If you have any book recommendations of your own, then I’d\n              love to hear them.\n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2022-05-02T13:00:30-04:00"
    },
    {
      "path": "inf2178.html",
      "title": "INF2178: Experimental Design",
      "description": "INF2178 is a masters-level course at the University of Toronto's Faculty of Information.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nHow to succeed\nHow we’ll work\nAdvice from past\nstudents\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nReading Week\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nWeekly quizzes\nProfessional conduct\nPaper #1\nPaper #2\nPaper #3\nFinal Paper\n\n\nPreamble\nOverview\nExperimental design has a long and robust tradition within\ntraditional applications such as agriculture, medicine, physics, and\nchemistry. It allows us to speak of causality with confidence.\nTypically, these are situations in which control groups can be\nestablished, randomization is appropriate, and ethical concerns can be\nassuaged. Unfortunately, such a set-up is rarely possible in the full\nextent of the modern applications where we want to understand\ncausality.\n\n\n\nSource: https://xkcd.com/2400/\nThis course covers the traditional approaches and statistical\nmethods, but focuses on what to do when traditional experimental design\nmethods cannot be implemented or are not appropriate (i.e. what feels\nlike most of the time these days). We cover experiments in their modern\nguise especially the concerns that we might have when we can run them;\nbut also methods that can provide some causal understanding even when we\ncannot conduct traditional experiments. Importantly, these approaches do\nnot rely on ‘big data’ or fancy statistics, but instead on thoroughly\ninterrogating the data that are available to get understanding through\nas simple means as possible.\nThis is a hands-on course in which you will conduct research projects\nusing real-world data. This means that you will: obtain and clean\nrelevant datasets; develop your own research questions; use the\nstatistical techniques that you are introduced to in class to answer\nthose questions; and finally communicate your results in a meaningful\nway. This course is designed around approaches that are used extensively\nin academia, government, and industry. Furthermore, it includes many\naspects, such as data cleaning and preparation, that are critical, but\nrarely taught.\nThis course is different to many other courses at the University of\nToronto. At the end of this course, you will have a portfolio of work\nthat you could show off to a potential employer. You will have developed\nthe skills to work successfully as an applied statistician or data\nscientist. And you will know how to fill gaps in your knowledge\nyourself. A lot of scholarships and jobs these days ask for GitHub and\nblog links etc to show off a portfolio of your work. This is the class\nthat gives you a chance to develop these. It’s very important to having\nsomething that shows off what you can do, and that needs to go beyond\nwhat is done in a normal class.\n\nHow to succeed\nIn this course you will work in a self-directed, open-ended manner.\nIdentify relevant areas of interest and then learn the skills that you\nneed to explore those areas.\nTo successfully complete this course, you should expect to spend a\nlarge portion of your time reading and writing (both code and text).\nDeeply engage with the materials. Find a small study group and keep each\nother motivated and focused. At the start of the week, read the course\nnotes, all compulsory materials and some recommended materials based on\nyour interest. After doing that, but before the ‘lecture’ time you\nshould complete the weekly quiz. During ‘lectures’ I’ll live-code,\ndiscuss materials in the course notes, talk about an experiment, and\nyou’ll have a chance to discuss the materials with me.\nYou need to be more active in your learning in this course than\nothers - read the notes and related materials - and then go out there\nand teach yourself more and apply it. You will not be spoon-fed in this\ncourse. Each week try to write reproducible, understandable, R code\nsurrounded by beautifully crafted text that motivates, backgrounds,\nexplains, discusses and criticizes. Make steady progress toward the\nassessment.\nThis is not a ‘bird course’. Typically, after the term is finished,\nstudents say that the course is difficult but rewarding. The TAs and I\nare always available to answer any questions. Please come to office\nhours!\nHow we’ll work\nThis webpage will provide almost all the guiding materials that you\nneed and links to the relevant parts of the notes. The course notes are\navailable here: https://www.tellingstorieswithdata.com. Those contain\nnotes and other material that you could go over. There is a course Slack\nfor discussion. We’ll use Quercus really only for assessment submission\nand grading. I expect you to work professionally, and so we’ll try to\nuse professional tools to the extent possible.\nA rough weekly flow for the course would be something like:\nRead the week’s course notes.\nRead/watch/listen to the compulsory materials.\nComplete the weekly quiz.\nAttend the lecture.\nAttend the lab.\nMake progress on a paper.\nAdvice from past students\nSuccessful past students have the following advice (completely\nunedited by me):\n‘Read the rubrics and treat INF2178 as a storytelling with data\ncourse rather than INF1344 part 2. Let the point distribution rubric\nguide what parts of the paper to focus on/expand. And pay attention to\nthe “telling stories” part of the site URL. The point of the papers\nisn’t to chuck every statistical method and cool R trick you know in\nthere, it’s to practice building data-driven arguments that different\naudiences might actually care about. Last, the piece of advice I wish I\nhad followed for the class: keep a log of things that you find\nconfusing/cool/useful.’\n‘Allocate as much time as you realistically can to projects. It all\ntakes longer than expected (particularly debugging) so be a friend to\nyour future self and don’t leave work to the last minute. Really.’\n‘Read the paper rubrics very carefully! The papers will always take\nlonger than you think they will so try to start early and put enough\ntime before submitting to make sure you sort out any issues with\nformatting and knitting your pdf because there will almost always be\nissues (especially if you’re doing it for the first time). Write the\npapers with an external audience in mind, not just as a school paper\nthat only Rohan will read. Consider the papers to be personal projects\nthat your peers and potential employers will be reading, and try to\nwrite something you feel could be published. Also, comment your code and\nthank yourself later :)’\n‘Do the readings even though there are a lot and don’t be afraid to\nask questions no matter how stupid you think they are (unless the answer\ncan easily be found, ie “is assignment 1 group or solo”). Also, Rohan is\nnot as intimidating as he initially seems. Also, if you did poorly on\nassignment 1, don’t drop the class. There’s still so much to learn and\nthe chance of making it up with the other two assignments.’\n‘You’re going to have to practice solving your own code problems,\nreviewing and keeping track of detailed assignment requirements,\ncritical thinking about data, and editing your own work. It will take\nmore time than you think.’’\n‘1) Try to keep up week to week as best as possible; watching the\nlectures is more rewarding that way because you have some understanding,\nespecially if you watch asynchronously and can’t just ask the professor\nquestions. Sometimes that means even skimming what readings you can if\ntime is tight, otherwise you may feel quite lost. 2) R documentation is\nyour best friend when you don’t wholly understand the examples in the\ncourse notes, or you’re looking for other viable solutions. Stack\nOverflow is also a great help, but don’t forget to cite everything\nyou’ve taken from there so you remember where it came from when\nwondering, “How does this even work? It works, but how?” 3) Sometimes,\nyour code will infuriate you. Take breaks. Step away for a half hour, do\nsomething else entirely for a while, or even come back tomorrow. Don’t\nbeat yourself up too much over it. You can also ask for assistance in\nthe course Slack, because odds are someone else has already encountered\nthis issue and arrived at a solution. 4) Trust Rohan and his process.\nIt’s going to rely on your efforts to learn on your own -and it’s going\nto feel like a harsh bootcamp- but you’ll learn to make friends with\ndata and coding. 5) Practice the examples on your own before class. 6)\nDon’t be afraid or intimidated by other’s who seem to know more than\nyou. 7) Attend Toronto Data Workshop whenever you can. 8) Form a study\ngroup early on’\n‘Don’t stop at just the assignment prompt. Have fun with your topic\nand see how you can take it further’\nAcknowledgements\nThanks to the following who helped develop this course: Monica\nAlexander, Kelly Lyons, Sharla Gelfand, Faria Khandaker, Hidaya Ismail,\nA Mahfouz, Paul Hodgetts, Thomas Rosenthal.\nContent\nEach week you should go through the course notes and all compulsory\nmaterials. During the lecture I will live-code various aspects. I will\nalso discuss a case study, typically a paper. During the lab, a TA will\neither lead small group discussions or similarly lead other work. The\nlecture will be recorded and posted here, but again, it’s not enough to\njust watch that - you need to read and write yourself.\nWeek 1\n‘Drinking from a fire hose’.\nContent: Drinking\nfrom a fire hose, R\nEssentials.\nCase Study: Fisher’s\nLady Tasting Tea.\nLab: Go through first four modules of DoSS Toolkit and discuss any\nissues with the TA.\nWeek 2\n‘Science-ing’.\nContent: Workflow,\nStatic\ncommunication.\nCase Study: Tuskegee\nSyphilis Study.\nLab: Go through modules five to eight of DoSS Toolkit and discuss\nany issues with the TA.\nWeek 3\n‘Why, if ever I did fall off—which there’s no chance of—but if I\ndid–’.\nContent: Experiments,\nand treatment effects.\nCase Study: The\nOregon Health Insurance Experiment in the United States.\nSpecial guest: Greg Wilson on\nhow to run a meeting.\nLab:\nPlease pretend that you work as a junior analyst for a large\nconsulting firm. Further, pretend that your consulting firm has taken a\ncontract to put together a facial recognition model for the Canada\nBorder Services Agency’s Inland Enforcement branch. Write five or six\npoints with regard to your thoughts on this matter. What would you do\nand why? Then split into small groups and compare your points with\nothers. Do you think the model would end up being implemented?\nWith the help of the TA, please conduct ‘face-to-face’ surveys (via\nZoom). For this exercise, you will be randomly split into groups of two.\nYou have two minutes in each group and will then be swapped to another\ngroup. One person is to survey the other person asking the following\nquestions: i) ‘What is your gender?’, ii) ‘What is your age?’, iii)\n‘What is your marital status?’, iv) ‘What is your income?’, v) ‘If an\nelection were held today who would you vote for?’. After one person is\ndone, then switch roles. When you are the questioner you should record\nall responses using a small CSV (but not the person’s name please). When\nyou are the respondent you are welcome to not respond. You will cycle\nthrough this multiple times. At the end, please write a small reflection\nabout: 1) as a respondent, how you felt answering these questions and\nthe implications that you think this feeling may have for how survey\nquestions are answered more generally; and 2) as a questioner, how\ndifficult it was to code responses and the implications this may have\nfor the dataset that we analyse.\n\nWeek 4\n‘Gathering data’.\nContent: Gathering\ndata.\nCase Study: Student\nCoaching: How Far Can Technology Go?\nLab:\nPlease pretend you work for Netflix and you want to know more about\nwhy people subscribe (or don’t!) when prices change. Please design an\nexperiment, discuss its key features and how you would implement it.\nPlease pay special attention to sampling issues. Then simulate an\noutcome.\nFollowing the guidance of the TA, please scrape some data and\ndiscuss some ethical considerations around the dataset that you created.\nYou may like to write a short blog post discussing the difference\nbetween data being public but scattered, and a consolidated dataset\nbeing public with reference to Kirkegaard and Bjerrekær, 2016, and\nPolitou, Alepis, and Patsakis, 2018 (if you do that please do email a\nlink to me out of interest).\n\nWeek 5\n‘Whoops, I forgot EDA’.\nContent: Exploratory\nData Analysis.\nCase Study: Civic\nhonesty around the globe\nLab:\nPretend that you work for Loblaws as a data scientist and it is late\nMarch 2020. As part of normal monitoring, you have noticed that\npurchases of flour and pasta have increased substantially. You had been\nplanning to increase the price of these items in April as part of a\ntrial, but now your manager is not sure whether it is appropriate to\nconduct the trial. Please write five or six points with regard to your\nthoughts on this matter. What would you do and why?\nAnalyse the Toronto AirBNB dataset with guidance from the TA.\n\nReading Week\n\n\n\nWeek 6\n‘IJALM - It’s Just A Linear Model’.\nContent: Linear\nand logistic regression and tidymodels\nCase Study: Upworthy\nA/B tests of headlines.\nSpecial guest: Kathy Ge on\nexperiments at Uber.\nLab recording:\nFollowing the guidance of the TA, please use Blogdown to create a\nsimple website and then design and execute a simple A/B test for your\nwebsite using Netlify.\n\nWeek 7\n‘Celestial Navigation’.\nContent: Simulation,\npower,\nRCTs,\nA/B\ntesting.\nCase Study: Please pick one chapter from Catherine D’Ignazio and\nLauren F. Klein, Data Feminism, that is of interest to you and\nread it (freely available: https://data-feminism.mitpress.mit.edu).\nLab:\nFollowing the guidance of the TA, please make a Shiny app that\nbundles a little data and some code and post it to shinyapps.com.\n\nWeek 8\n‘Such a shame they’ll never meet’.\nContent: Matching\nand difference in differences.\nCase Study: Funding\nof Clinical Trials and Reported Drug Efficacy\nSpecial guest: Emily Riederer\non observational causal inference.\nSpecial guest: Tamar Oostrom\non funding of clinical trials.\nLab:\nFollowing the guidance of the TA, please look at McClelland,\nAlexander, 2019, ‘“Lock This Whore Up”: Legal Violence and Flows of\nInformation Precipitating Personal Violence against People Criminalised\nfor HIV-Related Crimes in Canada’, European Journal of Risk\nRegulation, 10 (1), pp. 132-147.\nThen look at Policing the Pandemic - https://www.policingthepandemic.ca/. Look into how they\ngathered their dataset and what it took to put this together. What is in\nthe dataset and why? What is missing and why? How could this affect the\nresults? How might similar biases enter into other datasets that you\nhave used or read about?\nPut together a brief model. You may like to write a short blog post\nabout the biases and influences that are in this dataset (if you do that\nplease do email a link to me out of interest).\n\nWeek 9\n‘Why does it always rain on me?’.\nContent: Regression\ndiscontinuity and instrumental\nvariables.\nCase Study:\nJames H. Ware, 1989, ‘Investigating Therapies of Potentially Great\nBenefit: ECMO’, Statistical Science, available here.\nDonald A. Berry, 1989, ‘Comment: Ethics and ECMO’, Statistical\nScience, available here.\n\nLab:\nFollowing the guidance of the TA, please make an R package that\nbundles a little data and some code and add it to your GitHub. Don’t\nforget to include at least one test.\n\nWeek 10\n‘Post Hoc, Ergo Propter Hoc’.\nContent: DAGs,\nbias, and paradoxes.\nCase Study: Joshua Kalla and David Broockman, 2016, ‘Campaign\nContributions Facilitate Access to Congressional Officials: A Randomized\nField Experiment’\nLab:\nFollowing the guidance of the TA, please look back on the case\nstudies that we’ve covered so far. Please break up into small groups and\ncreate DAGs for each. Then write some notes about the potential for\nconfounding, selection bias and measurement bias. Pick one person in\nyour group to make a brief 2-minute presentation about what you\ndid.\n\nWeek 11\n‘But it works on my machine’.\nContent: Shiny, cloud, and\ndeploying.\nCase Study: Alexander, M., Wildeman, C., Roehrkasse, A., and\nRudlang-Perman, K., 2020, ‘Forecasting child welfare outcomes in the\nUnited States’, Shiny app;\nTechnical model\nsummary.\nLab:\nFollowing the guidance of the TA, and thinking about what we covered\nin lectures, please read, compare, and discuss:\nBendavid, E., Mulaney, B., Sood, N., Shah, S., Ling, E.,\nBromley-Dulfano, R., …, and Tversky, D, 2020, ‘COVID-19 Antibody\nSeroprevalence in Santa Clara County, California’, MedRxiv, https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf.\nGelman, Andrew, 2020, ‘Concerns with that Stanford study of\ncoronavirus prevalence’, Statistical Modeling, Causal Inference, and\nSocial Science, 19 April, https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/.\nEisen, Michael B., and Robert Tibshirani, 2020, ‘How to Identify\nFlawed Research Before It Becomes Dangerous’, New York Times,\n20 July, https://www.nytimes.com/2020/07/20/opinion/coronavirus-preprints.html.\nGelman, Andrew and Bob Carpenter, 2020, ‘Bayesian analysis of tests\nwith unknown specificity and sensitivity’, 8 July, http://www.stat.columbia.edu/~gelman/research/published/specificity.pdf.\n\n\nWeek 12\n‘Lorem ipsum’.\nContent: Text-as-data.\nCase Study: Kevin Munger, Patrick Egan, Jonathan Nagler, Jonathan\nRonen, and Joshua A. Tucker, 2017, ‘Political Knowledge and\nMisinformation in the Era of Social Media: Evidence From the 2015 UK\nElection’.\nLab:\nPlease form small groups and discuss, ‘to what extent do\nquantitative methods merely project forward the past, and what\nimplications does this have for our conduct as practitioners and\nconsumers?’\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nWeekly quiz\n20\nWeekly before the lecture\nProfessional conduct\n1\nAnytime during the teaching term\nPaper 1\n25\nEnd of Week 3\nPaper 2\n25\nEnd of Week 6\nPaper 3\n25\nEnd of Week 9\nFinal Paper (initial submission)\n1\nEnd of Week 12\nFinal Paper (peer review)\n3\nThree days after that\nFinal Paper\n25\nTen days after that\nWeekly quizzes\nDue date: Weekly before the lecture.\nWeight: 20 per cent (no quiz in Week 1 or Week 12 and only best\neight out of ten count.)\nTask: Please complete a weekly quiz in Quercus.\nQuestions: The questions that form the quiz are drawn from those in\nthe course notes.\nProfessional conduct\nDue date: Anytime during the teaching term.\nWeight: 1 per cent\nTask: We (optionally) use Slack to interact in this class. At some\npoint during the teaching term, please use Slack to answer another\nstudent’s question or otherwise similarly be generally helpful in a\nprofessional manner. When you do that, please share the comment into the\n‘Professional conduct’ channel and @ me (hover on the message, click\nshare message, type in the channel ‘profession_conduct’, add a message\nthat @‘s me, and click ’share’). You’ll get the full mark just for one\nhelpful interaction. (If you are opting out of using Slack - which is\nentirely fine - then instead, at some point in the term send me an email\nwith a link that is relevant to the course materials and that I should\nadd to the course notes. Please be clear that this is your ‘professional\nconduct’ submission by stating that in the subject line.)\nPaper #1\nDue date: End of Week 3.\nWeight: 25 per cent (for Papers #1-#3 the best two of three\ncount).\nTask: ‘Mandatory\nminimums’\nPaper #2\nDue date: End of Week 6.\nWeight: 25 per cent (for Papers #1-#3 the best two of three\ncounts).\nTask: ‘These\nnumbers mean dial it up’\nPaper #3\nDue date: End of Week 9.\nWeight: 25 per cent (for Papers #1-#3 the best two of three\ncounts).\nTask: ‘The\nShort List’.\nFinal Paper\nDue dates:\nInitial submission: End of Week 12.\nPeer review: Three days after that.\nFinal Paper: Ten days after that.\n\nWeight: 29 per cent (4 per cent of this is for initial submission\nand peer review conducted a week before).\nInitial submission: 1 per cent\nPeer review: 3 per cent\nFinal Paper: 25 per cent\n\nTask: ‘Two\nCathedrals’\n\n\n\n",
      "last_modified": "2022-05-02T13:00:31-04:00"
    },
    {
      "path": "INF312.html",
      "title": "Worlds become data",
      "description": "INF312 is an upper-level undergraduate course at the University of Toronto's Faculty of Information.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nAcknowledgements\nSyllabus\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nQuiz\nTutorial\nPaper #1\nPaper #2\nPaper #3\nPaper #4\nFinal Paper\n\nOther\nDescription\nAccommodations\nwith regard to assessment\nRe-grading\nPlagiarism and\nintegrity\nLate policy\nWriting\n\n\nPreamble\nOverview\nTo a certain extent we are wasting our time. We have a perfect model\nof the world–it is the world! But it is too complicated. Because of this\nwe must simplify the world in order for it to become data. In this\ncourse we explore how we do this, and the implications.\nFAQ\nCan I audit this course? Sure, but it is pointless, because the only\nway to learn this stuff is to do the work.\nWhat is a tutorial? You write a paper. Then you send it to your\ntutor. The next day you have a meeting, ‘tutorial’, where you discuss it\nwith them.\nWhy is there so much assessment? The only way to learn is to\nactually do the work, and students only do the work when they are\nassessed. It is unfortunate, but there’s no way around it.\nAcknowledgements\nThank you to the following people for generously providing comments,\nreferences, suggestions, and thoughts that directly contributed to this\noutline: Monica Alexander and Uzair Mirza.\nSyllabus\n2022.\nContent\nAlmost all content will closely follow Telling Stories with\nData.\nWeek 1\nContent:\nIntroduction\nSeveral\nend-to-end worked examples\n\nWeek 2\nContent:\nR\nEssentials\n\nWeek 3\nContent:\nReproducible\nworkflow\n\nWeek 4\nContent:\nWriting\nStatic\ncommunication\n\nWeek 5\nContent:\nInteractive\ncommunication\n\nWeek 6\n‘Gathering data’.\nContent:\nUsing APIs, scraping.\n\nWeek 7\n‘Gathering data II’.\nContent:\nOCR, semi-structured datasets, and text.\n\nWeek 8\n‘Hunting data’.\nContent:\nExperiments, sampling,\n\nWeek 9\n‘Cleaning data’.\nContent:\nWorkflow for cleaning data.\nEffective naming, checks, and testing.\n\nWeek 10\n‘Store, retrieve, disseminate and protect’ and ‘share, but not too\nmuch’.\nContent:\nR packages for data, and documentation including datasheets.\nPersonally identifying information, hashing and salting, GDPR and\nHIPPA, simulated data, and differential privacy.\n\nWeek 11\nContent: Overview\nWeek 12\n‘Final paper’.\nContent:\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nQuiz\n20\nWeekly before the lecture\nTutorial\n20\nWeekly the day before the tutorial\nPaper 1\n25\nEnd of Week 4\nPaper 2\n25\nEnd of Week 6\nPaper 3\n25\nEnd of Week 8\nPaper 4\n25\nEnd of Week 10\nFinal Paper (initial submission)\n1\nMiddle of Week 12\nFinal Paper (peer review)\n4\nEnd of Week 12\nFinal Paper\n25\nTwo weeks after that\nYou must submit Paper 1. And you must submit the Final Paper.\n‘End of’ means Sunday 11:59pm.\nBeyond that, you have scope to pick an assessment schedule that works\nfor you. We will take your best 3 of the 11 tutorials, or your best 8 of\n11 quizzes for that 20 per cent—whichever results in a better grade for\nyou (i.e. you can choose to do either quizzes or tutorials). And we will\ntake your two best papers from Papers 1-4 for that 50 per cent (25 per\ncent for each). The remainder is made up of 1 per cent for submitting a\ndraft of the Final Paper, 4 per cent for peer reviewing other people’s\ndrafts of the Final Paper, and 25 per cent for the Final Paper.\nAdditional details:\nQuiz questions are drawn from those in the Quiz section that follows\neach chapter of Telling Stories with Data. Almost all of them\nare multiple choice, and you should expect to know the mark within two\ndays of submission.\nTutorial questions are drawn from those in the Tutorial section that\nfollows each chapter of Telling Stories with Data. The general\nexpectation (although this differs from week to week) is about two pages\nof written content, which the tutor will read, discuss with you, and\nthen provide a mark. You should expect to know the mark within three\ndays of the tutorial.\nIn general papers require a considerable amount of work, and are due\nafter the material has been covered in quizzes and tutorials (i.e. you\nwould draw on knowledge tested in the quizzes, and potentially material\ncould be re-used from the tutorial material). In general, they require\noriginal work to some extent. Papers are taken from the Papers appendix\nof Telling Stories with Data and students have access to the\ngrading rubrics before submission.\nQuiz\nYou should choose to do either tutorials or quizzes.\nDue date: Weekly before the lecture.\nWeight: 20 per cent. Only best eight out of eleven count and only if\nthat is better for you than counting tutorials.\nTask: Please complete a weekly quiz in Quercus.\nTutorial\nYou should choose to do either tutorials or quizzes.\nDue date: Weekly the day before the tutorial.\nWeight: 20 per cent. Only best three out of eleven count and only if\nthat is better for you than counting quizzes.\nTask: Please complete a tutorial question and submit it via\nQuercus.\nRubric:\n0 - Any typos, major grammatical errors, other table stakes issues\nfor this level. Too short.\n0.25 - Grammatical errors, if relevant: tables/graphs not properly\nlabeled, no references, other aspects that affect credibility.\n0.6 - Makes some interesting and relevant points, related to course\nmaterial (including required materials), but lacking in terms of\nstructure and story/argument.\n0.80 - Interesting paper that is well-structured, coherent, and\ncredible.\n1 - As with 0.80, but exceptional in some way.\n\nPaper #1\nYou must submit this paper.\nTask: ‘Mandatory Minimums’ (details will be added to Quercus).\nDue date: End of Week 4.\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncount).\nPaper #2\nDue date: End of Week 6.\nTask: ‘The Short List’ (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #3\nDue date: End of Week 8.\nTask: TBA (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #4\nDue date: End of Week 10.\nTask: TBA (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nFinal Paper\nTask: TBA (details will be added to Quercus).\nYou must submit this paper.\nDue dates:\nInitial submission: Middle of Week 12.\nPeer review: End of Week 12.\nFinal Paper: Two weeks after that.\n\nWeight: 30 per cent\nInitial submission: 1 per cent\nPeer review: 4 per cent\nFinal Paper: 25 per cent\n\nOther\nDescription\nThis course covers issues in the practices of translating phenomena\nto data and algorithmic description. What happens, what is gained, what\nis lost, when things that happen in the world are recorded and made into\ninformation or recorded as a document? The course explores\nrepresentation, modeling, correctness, reliability, and bias in\ndifferent types of data and algorithms. We will learn about diverse\ntopics such as cultural and algorithmic bias, challenges of big data,\nwhat happens when the world is transformed into images, what are the\nimplications of having your social status determined by data and scores\non your social media profile, and what we gain or miss when we deal with\ngeographical information systems.\nAccommodations with\nregard to assessment\nYou do not need to reveal your personal or medical\ninformation to me. I understand that illness or personal emergencies can\nhappen from time to time. The following accommodations to assessment\nrequirements exist to provide for those situations.\nStraight-forward (will automatically apply to all students - there’s\nno need to ask for these):\nQuiz: Worst three quizzes are dropped.\nTutorial: Worst eight tutorials are dropped.\nPapers #1-#4: Worst two are dropped.\nSo for those (with the exception of Paper #1), if you have a\nsituation, then just don’t submit.\nSlightly more involved:\nPaper #1: I’m open to a day or two without penalty to account for\nsituations. Beyond that it begins to slow down the class. You must\nsubmit something for Paper #1.\nPeer review: No accommodation or late submission is possible for\nthis because it would hold up the rest of the class. If you cannot\nsubmit then email me before the deadline and the weight will be shifted\nto the final paper.\nFinal paper: The final paper is a critical piece of assessment. It’s\nalso up against deadlines for submission of grades. Extensions for valid\nreasons may be granted for a maximum of three days, however this isn’t\npossible for all students (i.e. there are restrictions around graduating\nstudents). Hence, the exact extension need to be at my discretion. To be\nconsidered, an extension request must be sent to rohan.alexander@utoronto.ca by the business day before\nthe due date so there is time to get advice from the Faculty about your\nparticular circumstance.\nRe-grading\nRequests to have your work re-graded will not be accepted within 24\nhours of the release of grades. This is to give you a chance to reflect.\nSimilarly, requests to have your work re-graded more than seven days\nafter the release of the grades will not be accepted. This is to ensure\nthe course runs smoothly.\nInside that 1-7 day period if you would like to request a re-grade,\nplease email rohan.alexander@utoronto.ca with a subject line that\nstarts with INF2178. You must specify where the marking error was made\nin relation to the marking guide. Your entire assessment will be\nre-marked and it is possible that your grade could reduce.\nPlagiarism and integrity\nPlease do not plagiarize. In particular, be careful to acknowledge\nthe source of code - if it’s extensive then through proper citation and\nif it’s just a couple of lines from Stack Overflow then in a comment\nimmediately next to the code.\nYou are responsible for knowing the content of the University of\nToronto’s Code of Behaviour on Academic Matters.\nAcademic offenses includes (but is not limited to) plagiarism,\ncheating, copying R code, communication/extra resources during closed\nbook assessments, purchasing labour for assessments (of any kind).\nAcademic offenses will be taken seriously and dealt with accordingly. If\nyou have any questions about what is or is not permitted in this course,\nplease contact me.\nPlease consult the University’s site on Academic Integrity http://academicintegrity.utoronto.ca/. Please also see\nthe definition of plagiarism in section B.I.1.(d) of the University’s\nCode of Behaviour on Academic Matters http://www.governingcouncil.utoronto.ca/Assets/Governing+Council+Digital+Assets/Policies/PDF/ppjun011995.pdf.\nPlease read the Code. Please review Cite it Right and if you require\nfurther clarification, consult the site How Not to Plagiarize http://advice.writing.utoronto.ca/wp-content/uploads/sites/2/how-not-to-plagiarize.pdf.\nLate policy\nYou are expected to manage your time effectively. If no extension has\nbeen granted and no accommodation applies, then the late submission of\nan assessment item carries a penalty of 10 percentage points per day to\na maximum of one week after which it will no longer be accepted, e.g. a\nproblem set submitted a day late that would have otherwise received 8/10\nwill receive 7/10, if that same problem set was submitted two days late\nthen it would receive 6/10.\nWriting\nPapers and reports should be well-written, well-organized, and easy\nto follow. They should flow easily from one point to the next. They\nshould have proper sentence structure, spelling, vocabulary, and\ngrammar. Each point should be articulated clearly and completely without\nbeing overly verbose. Papers should demonstrate your understanding of\nthe topics you are studying in the course and your confidence in using\nthe terms, techniques and issues you have learned. As always, references\nmust be properly included and cited. If you have concerns about your\nability to do any of this then please make use of the writing support\nprovided to the faculty, colleges and the SGS Graduate Centre for\nAcademic Communication.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:32-04:00"
    },
    {
      "path": "professional.html",
      "title": "Professional",
      "author": [],
      "contents": "\nProfessional experience\n\nPetit Poll\nMay 2016 – Current\nThis is a joint project with Monica Alexander. Petit Poll\ncombines non-representative polling data with a hierarchical Bayesian\nmodel to cheaply deliver meaningful Australian political polling. I am\nresponsible for survey design and analysis, as well as marketing and\ncommunication.\nWe polled the 2016 Australian Federal election and got a\n(statistically) reasonable result. In terms of seats we were five off.\nFour of those were just a result of our small sample size: there were\nthe three that turned unexpectedly in Tasmania; and the one in South\nAustralia that went to the Nick Xenophon team. If we had more data from\nthose areas then the model would have had a better chance, but when\nthere’s not much data the prior has a big impact.\nGrosvenor Public Sector\nAdvisory\nConsultant, April 2017 – February 2019\nI consulted at Grosvenor on a casual basis to complete a specific\nproject for the European Commission relating to public procurement. This\ninvolved: identifying data sources; preparing for and supporting data\nacquisition; conducting data quality confirmation; helping with survey\ndesign and validation; and some minor managerial responsibilities.\nThe Centre for\nInternational Economics\nEconomist, January 2012 – August 2013; August 2015 – November\n2015\nThe CIE is a privately-owned economic consultancy. I contributed to\nreports for public- and private-sector clients as part of a small team.\nTopics included: valuing public sector outputs; housing sector taxation;\nthe global meat market; wheat price elasticities; variations to modern\nawards; migration; and labor markets.\nGoCampaign\nCo-founder and Director, July 2011 – May 2015\nAs a co-founder and director of GoCampaign (later GoCatalyze), a data\nanalysis tool, I was responsible for the creation and development of a\nbusiness along with Andrew Barnes, Chris Eigeland and Chris Hood. There\nwere many aspects to this including creating marketing material and\nwebsites; making pitch decks; customer on-boarding and service;\npresenting; market testing; and some minor managerial responsibilities.\nGoCatalyze completed the ANZ Innovyz START accelerator program in 2013\nand won the iAward Data Category in 2014. GoCatalyze is now part of\nGO1.\nReserve Bank of Australia\nCadet/Analyst/Senior Analyst, February 2009 – December 2011\nI researched topics related to banknotes, for example an econometric\nanalysis of banknote demand during the 2007-08 financial crisis. I was\nalso responsible for creating and analysing counterfeit banknote\ndatasets, and gave banknote-related presentations to the public.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:32-04:00"
    },
    {
      "path": "reading_course-ethics.html",
      "title": "Reading Course: Ethics and Data Science",
      "description": "This is a reading course focused on the intersection of ethics and data science.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nAcknowledgements\n\nContent\nWeek 1 - General\nWeek 2 - Data and\nconsent\nWeek 3 - Women and\ngender\nWeek 4 - Race\nWeek 5 - Natural\nLanguage Processing\nWeek 6 - AI Ethics\nWeek 7 - Privacy\nWeek\n8 - Images/video with particular reference to facial\nrecognition\nWeek 9 - Corporate\nSurveillance\nWeek\n10 - Privacy and surveillance in Canada and other countries\nWeek 11 -\nAlgorithmic decision-making\nWeek\n12 - History of ethical concerns broadly, and domain-specific ethical\npractices\n\nAssessment\nFour\nethical and technical blog posts (30 per cent)\nPaper 1 (30 per cent)\nPaper 2 (40 per cent)\n\n\nPreamble\nOverview\nThe purpose of this reading course is to develop students who\ncan:\nengage in thoughtful, ethical, critique of data science, its\nantecedents, current state, and likely evolution; and\nwork productively to implement existing data science methods, as\nwell as contribute to the creation of novel methods or\napplications.\nEach week students will read relevant papers and books, engage with\nthem through discussion with each other and the instructor, learn\nrelated technical skills, and bring this together through on-going\nassessment. All students are expected to be prepared for each week’s\ndiscussion through completing the readings and technical requirements. A\nspecific student will act as the lead for each week.\nThe course outline is available here.\nFAQ\nCan I audit this course? It’s a reading course so the concept of\nauditing doesn’t make sense. There are no lectures, we have weekly\ndiscussions. You’re welcome to come along to the discussions if you’d\nlike but please do the readings first.\nAcknowledgements\nThanks to the following who helped develop this course: A Mahfouz,\nAssel Kushkeyeva, Irene Duah-Kessie, Ke-li Chiu, Paul Hodgetts, and\nThomas Rosenthal.\nContent\nWeek 1 - General\n\nEthical\nCore:\nCantwell Smith, Brian, 2019, The Promise of AI, MIT Press,\nChapters 10-12.\nHealy, Kieran, 2020, ‘The Kitchen Counter Observatory’, 21 May, https://kieranhealy.org/blog/archives/2020/05/21/the-kitchen-counter-observatory/.\nKeyes, Os, 2019, ‘Counting the Countless’, Real Life, 8\nApril, https://reallifemag.com/counting-the-countless/.\nO’Neil, Cathy, 2016, Weapons of Math Destruction, Crown\nBooks, Chapters 1, 3, and 4.\nAdditional (pick two):\nGreen, Ben, 2018, ‘Data Science as Political Action: Grounding Data\nScience in a Politics of Justice’, arXiv, 1811.03435, https://arxiv.org/abs/1811.03435.\nIrving, Geoffrey, and Amanda Askell, 2019, ‘AI Safety Needs Social\nScientists’, Distill, 19 February, https://distill.pub/2019/safety-needs-social-scientists/.\nLeslie, David, 2020, ‘Tackling COVID-19 through Responsible AI\nInnovation: Five Steps in the Right Direction’, Harvard Data Science\nReview, 5 June, https://hdsr.mitpress.mit.edu/pub/as1p81um.\nSuresh, Harini, and John V. Guttag, 2019, ‘A Framework for\nUnderstanding Unintended Consequences of Machine Learning’,\narXiv, 1901.10002, https://arxiv.org/abs/1901.10002.\nRaji, Inioluwa Deborah, 2020, ‘The Discomfort of Death Counts:\nMourning through the Distorted Lens of Reported COVID-19 Death Data’,\nPatterns, https://doi.org/10.1016/j.patter.2020.100066\nTechnical\nReview ‘Essentials’ from Telling Stories With Data, if\nnecessary.\nWeek 2 - Data and consent\n\nEthical\nCore:\nBoykis, Vicki, 2019, ‘Neural nets are just people all the way down’,\n16 October, https://vicki.substack.com/p/neural-nets-are-just-people-all-the.\nCrawford, Kate, and Vladan Joler, 2018, ‘Anatomy of an AI System:\nThe Amazon Echo As An Anatomical Map of Human Labor, Data and Planetary\nResources’, AI Now Institute and Share Lab, 7 September, https://anatomyof.ai.\nCrawford, Kate, 2020, ‘Kate Crawford: Anatomy of AI’, Lecture,\nUniversity of New South Wales, 28 January, https://youtu.be/uM7gqPnmDDc.\nKitchin, Rob, 2014, The data revolution: Big data, open data,\ndata infrastructures and their consequences, Sage, Introduction,\nChapters 8, and 10. (Access via U of T library).\nAdditional (pick two):\nBergis Jules, Ed Summers and Vernon Mitchell, 2018, ‘Documenting The\nNow: Ethical Considerations for Archiving Social Media Content Generated\nby Contemporary Social Movements: Challenges, Opportunities, and\nRecommendations’, White Paper, DocNow, https://www.docnow.io/docs/docnow-whitepaper-2018.pdf.\nBoyd, Danah, and Kate Crawford, 2012, ‘Critical Questions for Big\nData’, Information, Communication & Society, 15(55),\n662-679, https://www.microsoft.com/en-us/research/wp-content/uploads/2012/05/CriticalQuestionsForBigDataICS.pdf.\nDenton, Emily, Alex Hanna, Razvan Amironesei, Andrew Smart, Hilary\nNicole, Morgan Klaus Scheuerman, 2020, ‘Bringing the People Back In:\nContesting Benchmark Machine Learning Datasets’, arXiv, 14\nJuly, https://arxiv.org/abs/2007.07399.\nEubanks, Virginia, 2019, ‘Automating Inequality: How high-tech tools\nprofile, police and punish the poor’, Lecture, University of Toronto, 12\nMarch, https://www.youtube.com/watch?v=g1ZZZ1QLXOI.\nLemov, Rebecca, 2016, ‘Big data is people!’, Aeon, 16 June,\nhttps://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human.\nOffice of Oversight and Investigations Majority Staff, 2013, ‘A\nReview of the Data Broker Industry: Collection, Use, and Sale of\nConsumer Data for Marketing Purposes’, Staff Report for Chairman\nRockefeller, 18 December, United States Senate, Committee on\nCommerce, Science and Transportation, https://www.commerce.senate.gov/services/files/0d2b3642-6221-4888-a631-08f2f255b577.\nRadin, Joanna, 2017, ‘“Digital Natives”: How Medical and Indigenous\nHistories Matter for Big Data’, Osiris, 32 (1), 43-64, https://www.journals.uchicago.edu/doi/pdf/10.1086/693853.\nSnowberg, Erik and Leeat Yariv, 2018, ‘Testing The Waters: Behavior\nAcross Participant Pools’, NBER Working Paper, No. 24781, http://www.nber.org/papers/w24781.\nTechnical\nReview ‘Hunt, gather and farm’ from Telling Stories With\nData, if necessary.\nWeek 3 - Women and gender\nEthical\nCore:\nD’Ignazio, Catherine, and Lauren F. Klein, 2020, Data\nFeminism, MIT Press.\nGebru, Timnit, 2020, ‘Race and Gender’, The Oxford Handbook of\nEthics of AI, Chapter 13, Oxford University Press.\nAdditional (pick two):\nBorgerson, Janet L., 2007, ‘On the Harmony of Feminist Ethics and\nBusiness Ethics’, Business and Society Review, 112\n(4):477-509.\nD’Ignazio, Catherine, and Lauren F. Klein, ‘Feminist data\nvisualization’, Workshop on Visualization for the Digital Humanities\n(VIS4DH), Baltimore. IEEE. 2016.\nHill, Kashmir, 2017, ‘What Happens When You Tell the Internet You’re\nPregnant’, Jezebel, 27 July, https://jezebel.com/what-happens-when-you-tell-the-internet-youre-pregnant-1794398989.\nKeyes, Os, 2018, ‘The misgendering machines: Trans/HCI implications\nof automatic gender recognition’, Proceedings of the ACM on\nHuman-Computer Interaction, 2(CSCW), 1-22, https://dl.acm.org/doi/pdf/10.1145/3274357.\nQuintin, Cooper, 2017, ‘Pregnancy Panopticon’, DEFCON 25, https://www.eff.org/files/2017/07/27/the_pregnancy_panopticon.pdf.\nWoods, Heather Suzanne, 2018, ‘Asking more of Siri and Alexa:\nfeminine persona in service of surveillance capitalism’, Critical\nStudies in Media Communication, 35.4, pp. 334-349.\nTechnical\nReview the essentials of Bayesian models by going through McElreath,\n2020, Statistical Rethinking, 2nd Edition, (at least chapters 1, 2, 4,\n7, 9, 11, 12, and 13) to address any shortcomings.\nWeek 4 - Race\nTom Davidson, Assistant Professor, Sociology, Rutgers University:\nhttps://youtu.be/YDmxMn2Doq0.\nEthical\nCore:\nDavidson, Thomas, Debasmita Bhattacharya, and Ingmar Weber, 2019,\n‘Racial bias in hate speech and abusive language detection datasets’,\narXiv, https://arxiv.org/abs/1905.12516.\nNoble, Safiya Umoja, 2018, Algorithms of Oppression: How Search\nEngines Reinforce Racism, NYU Press, Chapter 2.\nAdditional (pick two):\nBuolamwini, Joy and Timnit Gebru, 2018, ‘Gender Shades:\nIntersectional Accuracy Disparities in Commercial Gender\nClassification’, Proceedings of Machine Learning Research Conference on\nFairness, Accountability, and Transparency, 81: pp. 1–15, http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf\nKwet, Michael, 2019, ‘Digital colonialism: US empire and the new\nimperialism in the Global South’, Race & Class 60.4, 3-26.\nScheuerman, M. K., Wade, K., Lustig, C., and Brubaker, J. R., 2020,\n‘How We’ve Taught Algorithms to See Identity: Constructing Race and\nGender in Image Databases for Facial Analysis’, Proceedings of the ACM\non Human-Computer Interaction, 4(CSCW1), 1-35.\nZiad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil\nMullainathan, 2019, ‘Dissecting racial bias in an algorithm used to\nmanage the health of populations’, Science, Vol. 366, Issue 6464,\npp. 447-453, DOI: 10.1126/science.aax2342, https://science.sciencemag.org/content/366/6464/447/tab-pdf\nTechnical\nPick a project from The Markup’s Show Your Work section (https://themarkup.org/series/show-your-work) and\nreproduce it, writing your own code. You may pick whatever language you\nare comfortable in.\nWeek 5 - Natural Language\nProcessing\n\nEthical\nCore:\nBender, Emily M., Angelina McMillan-Major, Timnit Gebru and\nShmargaret Shmitchell, 2021, ‘On the Dangers of Stochastic Parrots: Can\nLanguage Models Be Too Big?’, https://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf\nHovy, Dirk and Shannon L. Spruit, 2016, ‘The Social Impact of\nNatural Language Processing’, Proceedings of the 54th Annual Meeting of\nthe Association for Computational Linguistics, pp. 591–598, https://aclweb.org/anthology/P16-2096.pdf.\nPrabhumoye, Shrimai, Elijah Mayfield, and Alan W Black, 2019,\n‘Principled Frameworks for Evaluating Ethics in NLP Systems’,\nProceedings of the 2019 Workshop on Widening NLP, https://aclweb.org/anthology/W19-3637/.\nAdditional (pick two):\nBolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama\nand Adam T. Kalai, 2016, ‘Man is to Computer Programmer as Woman is to\nHomemaker? Debiasing Word Embeddings’, Advances in Neural Information\nProcessing Systems 29 (NIPS 2016), http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-d.\nChang, Kai-Wei, Vinod Prabhakaran, and Vicente Ordonez, 2019, ‘Bias\nand Fairness in Natural Language Processing’, Proceedings of the 2019\nConference on Empirical Methods in Natural Language Processing and the\n9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP): Tutorial Abstracts, https://aclweb.org/anthology/D19-2004/.\nHutchinson, Ben, Vinodkumar Prabhakaran, Emily Denton, Kellie\nWebster, Yu Zhong, and Stephen Denuyl, 2020, ‘Social Biases in NLP\nModels as Barriers for Persons with Disabilities’, arXiv, https://arxiv.org/abs/2005.00813.\nSolaiman, Irene, Miles Brundage, Jack Clark, Amanda Askell, Ariel\nHerbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim,\nSarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie,\nJasmine Wang, 2019, ‘Release Strategies and the Social Impacts of\nLanguage Models’, arXiv, https://arxiv.org/abs/1908.09203.\nTatman, Rachel, 2020, ‘What I Won’t Build’, Widening NLP Workshop\n2020, Keynote address, 5 July, https://slideslive.com/38929585/what-i-wont-build and http://www.rctatman.com/talks/what-i-wont-build.\nZhao, Jieyu, Tianlu Wang, Mark Yatskar, Vicente Ordonez and Kai-Wei\nChang, 2017, ‘Men Also Like Shopping: Reducing Gender Bias Amplification\nusing Corpus-level Constraints’, Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Processing, pp. 2979–2989, https://aclweb.org/anthology/D17-1323.pdf.\n(Optional/fun/horrifying) Hao, Karen, 2020, ‘The messy, secretive\nreality behind OpenAI’s bid to save the world’, MIT Review, 17 February,\nhttps://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/.\nTechnical\nImplement a NLP model via Hugging Face or Spacy, depending on your\nlanguage preference.\nWeek 6 - AI Ethics\nShion Guha, Assistant Professor, University of Toronto, will join\nthe discussion briefly this week.\nEthical\nCore:\nBrundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter\nEckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff,\nBobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob\nSteinhardt, Carrick Flynn, Seán Ó hÉigeartaigh, Simon Beard, Haydn\nBelfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans,\nMichael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei, 2019, ‘The\nMalicious Use of Artificial Intelligence: Forecasting, Prevention, and\nMitigation’, arXiv, https://arxiv.org/abs/1802.07228.\nJobin, A., Ienca, M., and Vayena, E, 2019, ‘The global landscape of\nAI ethics guidelines’, Nature Machine Intelligence, 1(9), pp. 389-399.\nhttps://www.nature.com/articles/s42256-019-0088-2.\nAdditional (pick two):\nAustralian Human Rights Commission, 2019, ‘Human Rights and\nTechnology Discussion Paper’, December, https://tech.humanrights.gov.au/sites/default/files/2019-12/TechRights_2019_DiscussionPaper.pdf.\nCrawford, Kate, Amba Kak and Jason Schultz, 2020, ‘Submission to the\nAustralian Human Rights Commission Human Rights & Technology\nDiscussion Paper’, AI Now Institute, New York University, 13 March.\nKaplan, Andreas, Michael Haenlein, 2019, ‘Siri, Siri, in my hand:\nWho’s the fairest in the land? On the interpretations, illustrations,\nand implications of artificial intelligence’, Business Horizons, Volume\n62, Issue 1, pp. 15-25.\nLeslie, David, 2019, ‘Understanding Artificial Intelligence Ethics\nand Safety: A guide for the responsible design and implementation of AI\nsystems in the public sector’, Alan Turing Institute.\nLuciano, Floridi, and Cowls Josh, 2019, ‘A Unified Framework of Five\nPrinciples for AI in Society’, Harvard Data Science Review, 1 July, https://hdsr.mitpress.mit.edu/pub/l0jsh9d1.\nPaglioni, Vincent, 2015, ‘The Ethics of Intelligent Machines’,\nInvestment Management Consultants Association, https://investmentsandwealth.org/getattachment/f3614756-1e1d-49c7-a201-29dbc22d8fbf/IWM15NovDec-EthicsIntelligentMachines.pdf\nWinfield, Alan F., Katina Michael, Jeremy Pitt, Vanessa Evers, 2019,\n‘Machine Ethics: the Design and Governance of Ethical AI and Autonomous\nSystems’, Proceeding of IEEE, Volume 107, Issue 3, pp. 509-517.\nSam Corbett-Davies and Sharad Goel, 2018, ‘The Measure and\nMismeasure of Fairness: A Critical Review of Fair Machine Learning’, 14\nAugust, https://arxiv.org/pdf/1808.00023.pdf.\nInareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman,\nAnd Aram Galstyan, 2019, ‘A Survey on Bias and Fairness in Machine\nLearning’, https://arxiv.org/pdf/1908.09635.pdf.\nIrene Y. Chen, Fredrik D. Johansson, David Sontag, 2018, ‘Why Is My\nClassifier Discriminatory?’, https://arxiv.org/pdf/1805.12002.pdf.\nTechnical\nUse RASA (https://rasa.com/) to build a chatbot, or OpenAI’s GPT-2\nor GPT-3 to generate text.\nWeek 7 - Privacy\nJonathan A. Obar, Assistant Professor, Department of\nCommunication Studies, York University, will be invited to join the\ndiscussion briefly this week.\nEthical\nCore:\nHyunghoon Cho, Daphne Ippolito, Yun William Yu, 2020, ‘Contact\nTracing Mobile Apps for COVID-19: Privacy Considerations and Related\nTrade-offs’, arXiv, https://arxiv.org/abs/2003.11511.\nObar, Jonathan A. and Oeldorf-Hirsch, Anne, 2018, ‘The Biggest Lie\non the Internet: Ignoring the Privacy Policies and Terms of Service\nPolicies of Social Networking Services’ TPRC 44: The 44th Research\nConference on Communication, Information and Internet Policy, http://dx.doi.org/10.2139/ssrn.2757465.\nAdditional (pick two):\nBlumberg, Andrew J. and Peter Eskersley, 2009, ‘On Locational\nPrivacy, and How to Avoid Losing it Forever’, https://www.eff.org/wp/locational-privacy.\nde Montjoye, Yves-Alexandre, César A. Hidalgo, Michel Verleysen, and\nVincent D. Blondel, 2013, ‘Unique in the Crowd: The privacy bounds of\nhuman mobility’, Scientific Reports, vol 3, https://doi.org/10.1038/srep01376.\nObar, Jonathan A., and Anne Oeldorf-Hirsch, 2018, ‘The clickwrap: A\npolitical economic mechanism for manufacturing consent on social media’,\nSocial Media+ Society, 4.3, 2056305118784770\nSolove, Daniel J, 2007, ‘“I’ve Got Nothing to Hide” and Other\nMisunderstandings of Privacy’, San Diego Law Review, Vol. 44,\np. 745-772.\nZimmeck, Sebastian, Story, Peter, Smullen, Daniel, Ravichander,\nAbhilasha, Wang, Ziqi, Reidenberg, Joel, Cameron Russell, N., &\nSadeh, Norman, 2019, ‘MAPS: Scaling Privacy Compliance Analysis to a\nMillion Apps’, Proceedings on Privacy Enhancing Technologies, Volume 3,\npp. 66-86.\nZimmer, Michael, Priya Kumar, Jessica Vitak, Yuting Liao and Katie\nChamberlain Kritikos, 2018, “‘There’s nothing really they can do with\nthis information’: unpacking how users manage privacy boundaries for\npersonal fitness information”, Information, Communication & Society,\nVol 23, Issue 7, pp. 1020-1037.\nTechnical\nFind or generate a dataset, then implement differential privacy on\nit. Examine and discuss the results.\nOberski, Daniel, and Frauke Kreuter, 2020, ‘Differential Privacy and\nSocial Science: An Urgent Puzzle’, Harvard Data Science Review, https://doi.org/10.1162/99608f92.63a22079.\nRubinstein, Benjamin I. P. and Francesco Alda, 2017, ‘diffpriv: An R\nPackage for Easy Differential Privacy’, Journal of Machine Learning\nResearch, 18, pp. 1-5.\nWeek\n8 - Images/video with particular reference to facial recognition\nJeffrey Knockel, Research Associate, Citizen Lab, University of\nToronto, will be invited to join the discussion briefly this\nweek.\nEthical\nCore:\nBuolamwini, Joy, Vicente Ordóñez, Jamie Morgenstern, and\nLearned-Miller, Erik, 2020, ‘Facial recognition technologies: A primer’,\nAlgorithmic Justice League, 29 May.\nInioluwa Deborah Raji, Timnit Gebru, Margaret Mitchell, Joy\nBuolamwini, Joonseok Lee, and Emily Denton, 2020, ‘Saving Face:\nInvestigating the Ethical Concerns of Facial Recognition Auditing’, In\nProceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES\n’20). Association for Computing Machinery, New York, NY, USA, 145–151.\nDOI:https://doi.org/10.1145/3375627.3375820.\nAdditional (pick two):\nHill, Kashmir, 2020, ‘Wrongfully Accused by an Algorithm’, New York\nTimes, 24 June, https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html.\nHill, Kashmir, 2020, ‘The Secretive Company That Might End Privacy\nas We Know It’, New York Times, 18 January, https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html.\nKnockel, Jeffrey, and Ruohan Xiong, 2019, ‘(Can’t) Picture This 2:\nAn Analysis of WeChat’s Realtime Image Filtering in Chats’, Citizen Lab,\n15 July, https://citizenlab.ca/2019/07/cant-picture-this-2-an-analysis-of-wechats-realtime-image-filtering-in-chats/.\nLearned-Miller, Erik, Vicente Ordóñez, Jamie Morgenstern, and Joy\nBuolamwini, 2020, ‘Facial recognition technologies in the wild: A call\nfor a federal office’, Algorithmic Justice League, 29 May,\nTechnical\nChollet, Francois, and J. J. Allaire, 2018, Deep Learning with R,\nChapter 5 ‘Deep learning for computer vision’.\nWeek 9 - Corporate\nSurveillance\nEthical\nCore:\nZuboff, Shoshana, 2019, The Age of Surveillance Capitalism, and\nwatch related interview: https://www.youtube.com/watch?v=hIXhnWUmMvw\nZuboff, Shoshana, 2019, ‘Written Testimony Submitted to The\nInternational Grand Committee on Big Data, Privacy, and Democracy’, 28\nMay, Ottawa, https://www.ourcommons.ca/Content/Committee/421/ETHI/Brief/BR10573725/br-external/ZuboffShoshana-e.pdf\nand watch related video https://youtu.be/6N2kJNwGgUg?t=4869.\nAdditional (pick two):\nBennett Cyphers and Gennie Gebhart, “Behind One-Way Mirror: A Deep\nDive Into the Technology of Corporate Surveillance”, https://www.eff.org/files/2019/12/11/behind_the_one-way_mirror-a_deep_dive_into_the_technology_of_corporate_surveillance.pdf\nMarczak, Bill and John Scott-Railton, 2020, ‘Move Fast and Roll Your\nOwn Crypto: A Quick Look at the Confidentiality of Zoom Meetings’,\nCitizen Lab, 3 April, https://citizenlab.ca/2020/04/move-fast-roll-your-own-crypto-a-quick-look-at-the-confidentiality-of-zoom-meetings/.\nParsons, Christopher, Andrew Hilts, and Masashi Crete-Nishihata,\n2017, ‘Approaching Access: A comparative analysis of company responses\nto data access requests in Canada’, Citizen Lab, Research Brief No. 106.\nAvailable at: https://citizenlab.ca/wp-content/uploads/2018/02/approaching_access.pdf.\n(Optional/fun) Duhigg, Charles, 2012, ‘How Companies Learn Your\nSecrets’, New York Times, 19 February, https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\nTechnical\nCreate a datasheet or model card for an open source dataset or\nmodel.\nGebru, Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman\nVaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford, 2018,\n‘Datasheets for Datasets’, arXiv, https://arxiv.org/abs/1803.09010\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy\nVasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji and\nTimnit Gebru, 2019, ‘Model Cards for Model Reporting’, FAT ’19:\nProceedings of the Conference on Fairness, Accountability, and\nTransparency, pp. 220–229 https://doi.org/10.1145/3287560.3287596.\nWeek\n10 - Privacy and surveillance in Canada and other countries\nLisa Austin, Professor, Law, University of Toronto, will be\ninvited to join the discussion briefly this week.\nEthical\nCore:\nKhoo, Cynthia, Kate Robertson, and Ronald Deibert, 2019, ‘Installing\nFear: A Canadian Legal and Policy Analysis of Using, Developing, and\nSelling Smartphone Spyware and Stalkerware Applications,’ Citizen Lab,\nResearch Report No. 120, University of Toronto, June, https://tspace.library.utoronto.ca/bitstream/1807/96321/1/stalkerware-legal.pdf.\nObar, Jonathan A., 2017, ‘Keeping Internet Users in the Know or in\nthe Dark? The Data Privacy Transparency of Canadian Internet Carriers: A\nThird Report’, IXMaps, https://ixmaps.ca/docs/DataPrivacyTransparencyCanadianCarriers-2017.pdf\nRuan, Lotus, Crete-Nishihata, Masashi, Knockel, Jeffrey, Xiong,\nRuohan and Dalek, Jakub, 2020, ‘The Intermingling of State and Private\nCompanies: Analysing Censorship of the 19th National Communist Party\nCongress on WeChat,’ The China Quarterly, pp. 1–30. doi:\n10.1017/S0305741020000491.\nAdditional (pick two):\nAustin, Lisa, and David Lie, 2019, ‘Safe Sharing Sites’, New York\nUniversity Law Review, Vol. 94, No. 4, pp. 581 - 623.\nKnockel, Jeffrey, Christopher Parsons, Lotus Ruan, Ruohan Xiong,\nJedidiah Crandall, and Ron Deibert, 2020, ‘We Chat, They Watch: How\nInternational Users Unwittingly Build up WeChat’s Chinese Censorship\nApparatus,’ Citizen Lab, Research Report No. 127, University of Toronto,\nMay, https://tspace.library.utoronto.ca/bitstream/1807/101395/1/Report%23127--wechattheywatch-web.pdf.\nObar, Jonathan A., and Brenda McPhail, 2018, ‘Preventing Big Data\nDiscrimination in Canada: Addressing design, consent and sovereignty\nchallenges’, Centre for International Governance Innovation (CIGI), https://www.cigionline.org/articles/preventing-big-data-discrimination-canada-addressing-design-consent-and-sovereignty.\nParsons, Christopher, Adam Molnar, Jakub Dalek, Jeffrey Knockel,\nMiles Kenyon, Bennett Haselton, Cynthia Khoo, and Ron Deibert, 2019,\n‘The Predator in Your Pocket: A Multidisciplinary Assessment of the\nStalkerware Application Industry,’ Citizen Lab, Research Report,\nNo. 119, University of Toronto, June, https://tspace.library.utoronto.ca/bitstream/1807/96320/1/stalkerware-holistic.pdf.\nScott, James C., 1998, Seeing Like a State: How Certain Schemes to\nImprove the Human Condition Have Failed.\nVarious, ‘GDPR Checklist’, https://gdpr.eu/checklist/.\nVarious, ‘Summary of privacy laws in Canada’, Office of the Privacy\nCommissioner, https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/02_05_d_15/.\nTechnical\nTBD based on student interest.\nWeek 11 - Algorithmic\ndecision-making\nJamie Duncan, Junior Policy Analyst, Artificial Intelligence Hub,\nInnovation, Science and Economic Development Canada, will be invited to\njoin the discussion briefly this week.\nEthical\nCore:\nSpiegelhalter, David, 2020, ‘Should We Trust Algorithms?’, Harvard\nData Science Review, 31 January, https://doi.org/10.1162/99608f92.cb91a35a.\nMolnar, Petra and Lex Gill, 2018, ‘Bots at the Gate: A Human Rights\nAnalysis of Automated Decision-Making in Canada’s Immigration and\nRefugee System,’ Citizen Lab and International Human Rights Program,\nFaculty of Law, University of Toronto, Research Report No. 114,\nUniversity of Toronto, September, https://citizenlab.ca/wp-content/uploads/2018/09/IHRP-Automated-Systems-Report-Web-V2.pdf.\nAdditional (pick two):\nDe-Arteaga, Maria, Riccardo Fogliato, and Alexandra Chouldechova, ‘A\nCase for Humans-in-the-Loop: Decisions in the Presence of Erroneous\nAlgorithmic Scores’. https://arxiv.org/abs/2002.08035.\nMitchell, Shira, Eric Potash, Solon Barocas, Alexander D’Amour, and\nKristian Lum, 2018, ‘Prediction-Based Decisions and Fairness: A\nCatalogue of Choices, Assumptions, and Definitions’, arXiv, 1811.07867.\nhttps://arxiv.org/abs/1811.07867.\nRudin, Cynthia, Caroline Wang, and Beau Coker, ‘The Age of Secrecy\nand Unfairness in Recidivism Prediction’, Harvard Data Science Review,\nhttps://hdsr.mitpress.mit.edu/pub/7z10o269.\nSuresh, Harini, Natalie Lao, and Ilaria Liccardi, ‘Misplaced Trust:\nMeasuring the Interference of Machine Learning in Human\nDecision-Making’, https://arxiv.org/pdf/2005.10960.pdf\nThe Joint Council for the Welfare of Immigrants v Secretary of State\nfor the Home Department, 2020, ‘Grounds of Challenge’ and ‘Response’,\navailable: https://www.foxglove.org.uk/news/c6tv7i7om2jze5pxs409k3oo3dyel0\nand background here: https://www.theguardian.com/uk-news/2020/aug/04/home-office-to-scrap-racist-algorithm-for-uk-visa-applicants.\nTechnical\nMcElreath says that researchers use point estimates to describe\nposterior distributions, not to support particular decisions. But this\nisn’t always viable. Using a post from the Stan Case Study (https://mc-stan.org/users/documentation/case-studies.html)\nas a guide, please develop a Bayesian hierarchical model in Stan. Please\npost-process your model to support/recommend a decision, and justify\nyour choices.\nWeek\n12 - History of ethical concerns broadly, and domain-specific ethical\npractices\nEthical (Please pick two\nareas.)\nMedicine:\nParker, Michael, J A Muir Gray, 2001, ‘What is the role of clinical\nethics support in the era of e-medicine?’, Journal of Medical Ethics, 27\nsuppl I:i33–i35 https://jme.bmj.com/content/medethics/27/suppl_1/i33.full.pdf\nChancellor, S., Baumer, E. P., & De Choudhury, M. (2019). Who is\nthe” Human” in Human-Centered Machine Learning: The Case of Predicting\nMental Health from Social Media. Proceedings of the ACM on\nHuman-Computer Interaction, 3(CSCW), 1-32. https://doi.org/10.1145/3359249\nVayena, Effy, and Alessandro Blasimme, 2020, ‘The Ethics of AI in\nBiomedical Research, Medicine and Public Health’, The Oxford Handbook of\nEthics of AI, Chapter 37, Oxford University Press.\nEngineering:\nDavis, Michael, 1991, ‘Thinking Like an Engineer: The Place of a\nCode of Ethics in the Practice of a Profession’, https://www.jstor.org/stable/pdf/2265293.pdf?refreqid=excelsior%3A94aaba1458bc97cf0563cf7d16861188\nMichaelson, Christopher, 2014, ‘The Competition for the Tallest\nSkyscraper: Implications for Global Ethics and Economics’, CTBUH\nJournal, Issue IV, https://www.jstor.org/stable/pdf/24192831.pdf?ab_segments=0%252Fbasic_SYC-5187%252Ftest&refreqid=excelsior%3A9bf439c8785e93d009d8e42608e6b425\nMillar, Jason, 2020, ‘Engineering’, The Oxford Handbook of Ethics of\nAI, Chapter 23, Oxford University Press.\nStatistics:\nWells, Martin, 2020, ‘Statistics’, The Oxford Handbook of Ethics of\nAI, Chapter 26, Oxford University Press.\nLaw:\nAngwin, Julia, Jeff Larson, Surya Mattu and Lauren Kirchner, 2016,\n‘Machine Bias’, ProPublica, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\nEubanks, Virginia, 2014, ‘How Big Data Could Undo Our Civil-Rights\nLaw’, https://prospect.org/justice/big-data-undo-civil-rights-laws/\nSurden, Harry, 2020, ‘Law: Basic Questions’, The Oxford Handbook of\nEthics of AI, Chapter 38, Oxford University Press.\nFinances:\nGeslevich Packin, Nizan, Yafit Lev Aretz, 2015, ‘Big Data and Social\nNetbanks: Are You Ready to Replace Your Bank?’, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2567135\nEducation:\nMayfield, E., Madaio, M., Prabhumoye, S., Gerritsen, D., McLaughlin,\nB., Dixon-Román, E., & Black, A. W. (2019, August). Equity beyond\nbias in language technologies for education. In Proceedings of the\nFourteenth Workshop on Innovative Use of NLP for Building Educational\nApplications (pp. 444-460). https://doi.org/10.1177/2053951720913064\nRubel, A., & Jones, K. M. (2016). Student privacy in learning\nanalytics: An information ethics perspective. The information society,\n32(2), 143-159. https://doi.org/10.1080/01972243.2016.1130502\nZeide, Elana, 2020, ‘Education’, The Oxford Handbook of Ethics of\nAI, Chapter 42, Oxford University Press.\nGeneral non-computational:\nSelbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S.,\n& Vertesi, J. (2019, January). Fairness and abstraction in\nsociotechnical systems. In Proceedings of the Conference on Fairness,\nAccountability, and Transparency (pp. 59-68). https://dl.acm.org/doi/pdf/10.1145/3287560.3287598\nEarlier calls for ethics in computing\nAgre, Philip E., 1997, ‘Towards a critical technical practice:\nLessons learned from trying to reform AI’, Social science, technical\nsystems, and cooperative work: Beyond the great divide, Ed. by Geoffrey\nC. Bowker, Susan Leigh Star, Will Turner, and Les Gasser. Mahwah, NJ:\nLawrence Erlbaum Associates, pp. 131–158. URL: https://web.archive.org/web/20040203070641/http://polaris.gseis.ucla.edu/pagre/critical.html.\nFriedman, Batya, and Helen Nissenbaum, 1996, ‘Bias in computer\nsystems’, ACM Trans. Inf. Syst, 14, 3 (July 1996), 330–347. DOI: https://doi.org/10.1145/230538.230561.\nTechnical\nTBD based on student interest.\nAssessment\nFour ethical\nand technical blog posts (30 per cent)\nOver the course of the term, you are expected to submit four blog\nposts that each comprise two aspects: 1) ethical and 2) technical. These\ntwo aspects should be related to each other. You must submit all four,\nbut only your best three blog posts will count, that is each blog post\nwill account for 10 per cent of your overall mark.\nFor the first aspect (ethical), you are expected to write a moderate\nlength discussion (think a paper of about two to three pages), of a\nreading, or set of readings, that we have covered over the past two\nweeks. Strong submissions will not limit themselves to reviewing a\nreading but will draw in larger issues and detail their own point of\nview.\nFor the second aspect (technical), you are expected to implement some\nsmall related technical aspect of what we have covered in the past two\nweeks. For instance, if we covered natural language processing then you\nmay critically review a paper, and put together a chat bot.\nTo be clear, these two aspects should be related, tied together, and\nshould be in the one blog post.\nYou should submit your blog post by emailing me a link to the\nrelevant blog post on your website.\nThe proposed specific list of deadlines is:\nBlog post 1: midnight, Sunday 24 January, 2021.\nBlog post 2: midnight, Sunday 7 February, 2021.\nBlog post 3: midnight, Sunday 7 March, 2021.\nBlog post 4: midnight, Sunday 21 March, 2021.\nIn Week 1 we will discuss how these dates fit in with your other\ncommitments and finalise them at that point.\nThe instructor will make the marking guide available at least a week\nbefore the submission deadline.\nPaper 1 (30 per cent)\nTask\nPlease gather and clean data on UofT salaries from the Sunshine List.\nThen conduct a Bayesian statistical analysis of your dataset to discuss\nthe extent to which gender has an effect on salary. Finally please\nprepare a paper of around 10 pages that discusses your analysis. (Hint:\ngender is not explicitly part of the Sunshine List, you will need to\ngrapple with what to do.)\nBackground\nYou should make appropriate use of appendices for additional and\nsupporting material, and thoroughly reference your paper, but neither\nthe appendices nor the reference list count toward your page limit. Your\npaper should have an appropriate title, author, date, abstract, and\nintroduction. It should document and overview your dataset. It should\nclearly specify your model, and then discuss the results of your\nanalysis and any weaknesses. Your analysis should be fully reproducible,\nwith code and data hosted on a public GitHub repo. Additionally, you\nshould include a thorough discussion of ethical considerations relevant\nto your analysis. This would likely take at least three pages, but you\nare welcome to write as much as is needed to make the points you would\nlike to make. Likely the best way to do this is to include a brief\noverview of the ethical points that you would like to discuss, and then\ninclude the rest of the discussion in an appendix. I understand that\nBayesian analysis may be new to you. I will assist you with putting\ntogether the model, but it is up to you to understand and interpret the\noutput.\nSubmission\nTo submit your paper you should email me a link to a public GitHub\nrepo. That repo should contain your paper in PDF format and all\nsupporting code and data. Please send this email by midnight, Sunday, 14\nFebruary, 2021. Please do not make any changes to the repo after this. I\nwill make the marking guide available at least a week before the\nsubmission deadline.\nPaper 2 (40 per cent)\nTask\nIn consultation with me, please identify an appropriate research\nquestion and data source that, like the requirement for Paper 1,\ncombines both ethical and technical aspects. Please prepare a paper that\nrepresents your best attempt to answer this question and shows off your\nability to engage in thoughtful, ethical, critique. The paper should be\nas long as necessary, although all extraneous material should be\nincluded in appendices. The expectation is that this paper should make\nan original contribution, that could be published in an academic\njournal.\nBackground\nPlease see the background provided for Paper 1, as this applies for\nPaper 2 as well.\nSubmission\nYou must send the email with the GitHub link to me by midnight,\nSunday, 23 April, 2020. Please do not make any changes to the repo after\nthis. I will make the marking guide available at least a week before the\nsubmission deadline. No extensions are possible because of deadlines for\ninstructors to submit grades.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:33-04:00"
    },
    {
      "path": "reading_course-nlp.html",
      "title": "Reading Course: 'Natural Language Processing'",
      "author": [],
      "contents": "\n\nContents\nOverview\nContent\nAssessment\n\nOverview\nThe purpose of this reading course is to develop students who\ncan:\nengage in thoughtful, ethical, critique of Natural Language\nProcessing (NLP);\nwork productively to implement existing NLP methods; and\nuse NLP to contribute to our understanding of the world.\nStudents are expected to develop:\nan understanding of NLP and its place in the world;\nexceptional written and verbal communication skills; and\ncontribute in some small way to our understanding of something\nrelated to NLP.\nContent\nWeek 1: Essentials I\nSilge, Julia & David Robinson, 2020, Text Mining with\nR, Chapters 1-4: https://www.tidytextmining.com.\nHovy, Dirk and Shannon L. Spruit, 2016, ‘The Social Impact of\nNatural Language Processing’, Proceedings of the 54th Annual Meeting\nof the Association for Computational Linguistics, pp. 591–598,https://aclweb.org/anthology/P16-2096.pdf.\nPrabhumoye, Shrimai, Elijah Mayfield, and Alan W Black, 2019,\n‘Principled Frameworks for Evaluating Ethics in NLP Systems’,\nProceedings of the 2019 Workshop on Widening NLP, https://aclweb.org/anthology/W19-3637/.\n\nWeek 2: Essentials II\nSilge, Julia & David Robinson, 2020, Text Mining with\nR, Chapters 5-7: https://www.tidytextmining.com.\nBolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama\nand Adam T. Kalai, 2016, ‘Man is to Computer Programmer as Woman is to\nHomemaker? Debiasing Word Embeddings’, Advances in Neural\nInformation Processing Systems, 29 (NIPS 2016), http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-d.\nChang, Kai-Wei, Vinod Prabhakaran, and Vicente Ordonez, 2019, ‘Bias\nand Fairness in Natural Language Processing’, Proceedings of the\n2019 Conference on Empirical Methods in Natural Language Processing and\nthe 9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP): Tutorial Abstracts, https://aclweb.org/anthology/D19-2004/.\n\nWeek 3: Essentials III\nSilge, Julia & David Robinson, 2020, Text Mining with\nR, Chapters 8-9: https://www.tidytextmining.com.\nHutchinson, Ben, Vinodkumar Prabhakaran, Emily Denton, Kellie\nWebster, Yu Zhong, and Stephen Denuyl, 2020, ‘Social Biases in NLP\nModels as Barriers forPersons with Disabilities’, arXiv, https://arxiv.org/abs/2005.00813.\n\nWeek 4: NLP intermediate I\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine\nLearning for Text Analysis in R, Chapters 1-3, https://smltar.com.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language\nProcessing, 3rd ed., Chapter 3, https://web.stanford.edu/~jurafsky/slp3/.\nSolaiman, Irene, Miles Brundage, Jack Clark, Amanda Askell,\nArielHerbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook\nKim, SarahKreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris\nMcGuffie, Jasmine Wang, 2019, ‘Release Strategies and the Social Impacts\nof Language Models’,arXiv, https://arxiv.org/abs/1908.09203.\n\nWeek 5: NLP intermediate II\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine\nLearning for Text Analysis in R, Chapters 4-6, https://smltar.com.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language\nProcessing, 3rd ed., Chapters 4 and 5, https://web.stanford.edu/~jurafsky/slp3/.\nTatman, Rachel, 2020, ‘What I Won’t Build’, Widening NLP\nWorkshop 2020, Keynote address, 5 July, https://slideslive.com/38929585/what-i-wont-build and http://www.rctatman.com/talks/what-i-wont-build.\n\nWeek 6: NLP intermediate III\n(Read this one first) Jurafsky, Dan, and James H. Martin, 2020,\nSpeech and Language Processing, 3rd ed., Chapters 6 and 7, https://web.stanford.edu/~jurafsky/slp3/.\nHvitfeldt, Emil & Julia Silge, 2020, Supervised Machine\nLearning for Text Analysis in R, Chapters 7-9, https://smltar.com.\nZhao, Jieyu, Tianlu Wang, Mark Yatskar, Vicente Ordonez and Kai-Wei\nChang,2017, ‘Men Also Like Shopping: Reducing Gender Bias Amplification\nusing Corpus-level Constraints’, Proceedings of the 2017 Conference\non Empirical Methods in Natural Language Processing, pp. 2979–2989,\nhttps://aclweb.org/anthology/D17-1323.pdf.\n\nWeek 7: Deep learning I\nFrançois Chollet with J. J. Allaire, 2018, Deep Learning with\nR, Chapters 1-4.\n\nWeek 8: Deep learning II\nFrançois Chollet with J. J. Allaire, 2018, Deep Learning with\nR, Chapters 6.\nBender, Emily M. and Koller, Alexander, 2020, ‘Climbing towards NLU:\nOn Meaning, Form, and Understanding in the Age of Data’, *Proceedings of\nthe 58th Annual Meeting of the\n\nWeek 9: Deep learning III\nAnna Rogers, Isabelle Augenstein, 2020, ‘What Can We Do to Improve\nPeer Review in NLP?’, arXiv, 8 October, https://arxiv.org/abs/2010.03863.\nJurafsky, Dan, and James H. Martin, 2020, Speech and Language\nProcessing, 3rd ed., Chapters 8 and 9, https://web.stanford.edu/~jurafsky/slp3/. Association\nfor Computational Linguistics*, pp. 5185–5198, https://www.aclweb.org/anthology/2020.acl-main.463\n\nWeek 10: Transformers I\nAlammar, Jay, 2018, ‘The Illustrated Transformer’, http://jalammar.github.io/illustrated-transformer/.\nManning, Vaswani and Huang, 2019, ‘Stanford CS224N: NLP with Deep\nLearning | Winter 2019 | Lecture 14 – Transformers and Self-Attention’,\nhttps://www.youtube.com/watch?v=5vcj8kSwBCY&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=14&ab_channel=stanfordonline.\nUszkoreit, Jakob, 2017, ‘Transformer: A Novel Neural Network\nArchitecture for Language Understanding’, Google AI Blog, 31 August, https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\nWeek 11: Transformers II\nAlammar, Jay, 2020, ‘How GPT3 Works - Visualizations and\nAnimations’, 27 July, https://jalammar.github.io/how-gpt3-works-visualizations-animations/\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin, 2017,\n‘Attention Is All You Need’, arXiv, http://arxiv.org/abs/1706.03762.\nJacob Devlin and Ming-Wei Chang, 2018, ‘Open Sourcing BERT:\nState-of-the-Art Pre-training for Natural Language Processing’, 2\nNovember, Google AI Blog, https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 2018,\n‘BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding’, arXiv, https://arxiv.org/abs/1810.04805.\nRush, Alexander, 2018, ‘The Annotated Transformer’, https://nlp.seas.harvard.edu/2018/04/03/attention.html\n\nWeek 12: Transformers III\nTom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah\nand Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav\nShyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel\nHerbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and\nAditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter\nand Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin\nand Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner\nand Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei,\n2020, ‘Language Models are Few-Shot Learners’, arXiv, https://arxiv.org/abs/2005.14165\n(Fun/horrifying) Hao, Karen, 2020, ‘The messy, secretive reality\nbehind OpenAI’s bid to save the world’, MIT Review, 17\nFebruary, https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/.\n\nAssessment\nLearning Diary (15 per cent)\nDate: Each week you will read relevant papers and books, engaging\nwith them by writing notes and completing exercises. You will use GitHub\nto manage these notes and exercises and email a link to me at the end of\neach week.\n\nPresentation I (15 per cent)\nDate: Roughly end of Week 4 (exact date determined by lab\npresentation cycle - it’ll be the end of a month and you’ll have at\nleast a month’s notice).\nRequirement: 10-15-minute presentation on what you’ve learned from\nSilge & Robinson.\n\nPresentation II (15 per cent)\nDate: Roughly end of Week 8, as above.\nRequirement: 10-15-minute presentation on an aspect of ethics,\nsociety, and NLP.\n\nPresentation III (15 per cent)\nDate: Roughly end of Week 12, as above.\nRequirement: 10-15-minute presentation on Hvitfeldt &\nSilge.\n\nFinal Paper (40 per cent)\nToward the mid-term break we will have a meeting to discuss the\ntopic of your final paper. It will be due on the last day of the exam\nperiod. This will be marked by me and reviewed by another DoSS\nprofessor.\n\n",
      "last_modified": "2022-05-02T13:00:33-04:00"
    },
    {
      "path": "reproducibility.html",
      "title": "Toronto Workshop on Reproducibility",
      "description": "An annual workshop focused on reproducibility in data science and statistics. First held 25-26 February 2021, and again 23-25 February 2022. Free and hosted via Zoom. Jointly hosted by CANSSI Ontario and the Data Sciences Institute. Supported by the Faculty of Information and the Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nOverview\n2022\n2021\nCode of conduct\n\n\n\n\nOverview\nThis conference brings together academic and industry participants on\nthe critical issue of reproducibility in applied statistics and related\nareas. The conference is free and hosted online. Everyone is welcome,\nyou don’t need to be affiliated with a university.\nThe conference has three broad areas of focus:\nEvaluating reproducibility: Systematically looking\nat the extent of reproducibility of a paper or even in a whole field is\nimportant to understand where weaknesses exist. Does, say, economics\nfall flat while demography shines? How should we approach these\nreproductions? What aspects contribute to the extent of\nreproducibility.\nPractices of reproducibility: We need new tools and\napproaches that encourage us to think more deeply about reproducibility\nand integrate it into everyday practice.\nTeaching reproducibility: While it is probably too\nlate for most of us, how can we ensure that today’s students don’t\nrepeat our mistakes? What are some case studies that show promise? How\ncan we ensure this doesn’t happen again?\n2022\nTimetable\nWednesday, 23 February 2022\nTime\nSpeaker\nTalk\n08:40-09:00\nLisa Strug, University of Toronto\nIntroduction and\nwelcome\n09:00-09:30\nBenjamin Haibe-Kains, University Health Network\nThe (Not-So-)Hard Path To\nTransparency and Reproducibility in AI Research\n09:30-10:00\nColm-cille Caulfield, University of Cambridge\nReproducibility in an\nUncertain World: How should academic data science researchers give\nadvice?\n10:00-10:30\nStephen Eglen, University of Cambridge\nEvaluating the\nreproducibility of computational results reported in scientific\njournals\n10:30-11:00\nValentin Danchev, University of Essex\nReproducibility and\nReplicability of Large Pre-trained Language Models\n11:00-11:30\nMonica Alexander, University of Toronto\nReproducibility in\nDemography: where are we at and where can we go?\n11:30-12:00\nBreak\n\n12:00-12:30\nAriel Mundo, University of Arkansas\nStatistics and\nreproducibility in biomedical research: Why we need both\n12:30-13:00\nShilaan Alzahawi, Stanford University\nLay perceptions of scientific\nfindings: Swayed by the crowd?\n13:00-13:30\nBreak\n\n13:30-14:00\nFernando Hoces de la Guardia, University of California,\nBerkeley\nSocial Sciences\nReproducibility Platform\n14:00-15:30\nBreak\n\n15:30-16:00\nCarl Laflamme, YCharOS\nAntibody Characterization\nthrough Open Science (YCharOS)\n16:00-16:30\nRobert Hanisch, National Institute of Standards and Technology and\nResearch Data Alliance\nReproducibility: A Metrology\nPerspective\n16:30-17:00\nYann Joly, McGill University\nIncentivizing open data\nsharing - what’s in it for me!?\nThursday, 24 February 2022\nTime\nSpeaker\nTalk\n08:30-09:00\nJulien Chiquet, Université Paris-Saclay\nComputo: a journal of the\nFrench Statistical Society promoting reproductibility\n09:00-09:30\nNick Radcliffe, Global Open Finance Centre at the University of\nEdinburgh\nGentest: Automatic Test\nGeneration for Data Science\n09:30-10:00\nMarkus Fritsch, University of Passau\nTowards reproducible GMM\nestimation\n10:00-10:30\nBreak\n\n10:30-11:00\nAneta Piekut, Sheffield Methods Institute, University of\nSheffield\nIntegrating reproducibility\ninto the curriculum of an undergraduate social sciences degree\n11:00-12:30\nBreak\n\n12:30-13:00\nJason Hattrick,-Simpers, University of Toronto\nTowards Trust and\nReproducibility in Materials AI\n13:00-13:30\nAya Mitani, University of Toronto\nReproducible, reliable,\nreplicable? In-class exercise using peer-reviewed studies\n13:30-14:00\nShannon Ellis, UC San Diego\nStructuring & Managing\nGroup Projects in Large-Enrollment Undergraduate Data Science\nCourses\n14:00-14:30\nMaria Tackett, Duke University\nKnit, Commit, and Push:\nTeaching version control in undergraduate statistics courses\n14:30-15:00\nBreak\n\n15:00-15:30\nLars Vilhuber, Cornell University\nTeaching for large-scale\nReproducibility Verification\n15:30-16:00\nMichael Geuenich, Lunenfeld Tanenbaum Research Institute and\nUniversity of Toronto\nWith great data come great\npipelines: creating flexible standardized pipelines for common\nbiomedical analysis tasks using Snakemake\n16:00-16:30\nParaskevi Massara, University of Toronto\nMOSS4Research: A maturity\nmodel to evaluate and improve reproducibility in research\nprojects\n16:30-17:00\nChris Kenny, Harvard University\nReproducible\nRedistricting\n17:00-17:30\nDewi Amaliah, Monash University\nReproducible Practice in\nTaming the Wild Data\nFriday, 25 February 2022\nTime\nSpeaker\nTalk\n09:00-09:30\nMarco Prado, University of Western Ontario\nReproducibility for Behavior\nExperiments in Basic Science\n09:30-10:00\nDavid Grubbs and Lara Spieker, CRC Press\nOn book publishing\n10:00-11:00\nJoelle Pineau, McGill University & Meta (Facebook) AI\nResearch\nImproving Reproducibility in\nMachine Learning Research\n11:00-11:30\nDebbie Yuster, Ramapo College of New Jersey\nInfusing Reproducibility into\nIntroductory Data Science\n11:30-12:00\nColin Rundel, Duke University\nTeaching Statistical\ncomputing with Git and GitHub\n12:00-12:30\nMine Çetinkaya,-Rundel, Duke University and RStudio\nReproducible authoring with\nQuarto\n12:30-13:00\nErin Heerey, Western University\nThe Experimenter in the\nRoom\n13:00-13:30\nJohn McLevey, University of Waterloo\nReproducibility and\nPrincipled Data Processing in Python\n13:30-14:00\nBreak\n\n14:00-14:30\nKevin Wilson, Brown University and Jake Bowers, University of\nIllinois at Urbana-Champaign\nSix Tips for Reproducible\nField Experiments\n14:30-15:00\nAbel Brodeur, University of Ottawa\nIntroducing the Institute for\nReplication\n15:00-15:30\nAllison Koenecke, Cornell University and Microsoft Research\nReproducible Retrospective\nAnalysis\n15:30-16:30\nMichael Hoffman, University Health Network and University of\nToronto\nReproducibility standards for\nmachine learning in the life sciences\nPresenter biographies and\nabstracts\nKeynotes\nJoelle Pineau\nTitle: Improving Reproducibility in Machine Learning Research\nFindings from the NeurIPS Reproduciblity Program and the ML\nReproducibility Challenge\nBiography: Joelle Pineau is an Associate Professor and William\nDawson Scholar at the School of Computer Science at McGill University,\nwhere she co-directs the Reasoning and Learning Lab. She is a core\nacademic member of Mila and a Canada CIFAR AI chairholder. She is also\nco-Managing Director of Facebook AI Research. She holds a BASc in\nEngineering from the University of Waterloo, and an MSc and PhD in\nRobotics from Carnegie Mellon University. Dr. Pineau’s research focuses\non developing new models and algorithms for planning and learning in\ncomplex partially-observable domains. She also works on applying these\nalgorithms to complex problems in robotics, health care, games and\nconversational agents. She serves on the editorial board of the Journal\nof Machine Learning Research and is Past-President of the International\nMachine Learning Society. She is a recipient of NSERC’s E.W.R. Steacie\nMemorial Fellowship (2018), a Fellow of the Association for the\nAdvancement of Artificial Intelligence (AAAI), a Senior Fellow of the\nCanadian Institute for Advanced Research (CIFAR), a member of the\nCollege of New Scholars, Artists and Scientists by the Royal Society of\nCanada, and a 2019 recipient of the Governor General’s Innovation\nAwards.\n\nMichael Hoffman\nTitle: Reproducibility standards for machine learning in the life\nsciences\nAbstract: To make machine-learning analyses in the life sciences\nmore computationally reproducible, we propose standards based on data,\nmodel and code publication, programming best practices and workflow\nautomation. By meeting these standards, the community of researchers\napplying machine-learning methods in the life sciences can ensure that\ntheir analyses are worthy of trust.\nBiography: Michael Hoffman creates predictive computational models\nto understand interactions between genome, epigenome, and phenotype in\nhuman cancers. His influential machine learning approaches have reshaped\nresearchers’ analysis of gene regulation. These approaches include the\ngenome annotation method Segway, which enables simple interpretation of\nmultivariate genomic data. He is a Senior Scientist at Princess Margaret\nCancer Centre and Associate Professor in the Departments of Medical\nBiophysics and Computer Science, University of Toronto. He was named a\nCIHR New Investigator and has received several awards for his academic\nwork, including the NIH K99/R00 Pathway to Independence Award, and the\nOntario Early Researcher Award.\n\nInvited talks\nAbel\nBrodeur\nTitle: Introducing the Institute for Replication\nBiography: Abel Brodeur is an associate professor in the department\nof economics at the University of Ottawa. He is the chair of the\nInstitute for Replication (I4R), which he founded in January 2022. I4R\nworks to improve the credibility of science by systematically\nreproducing and replicating research findings in leading academic\njournals.\n\nAllison Koenecke\nTitle: Reproducible Retrospective Analysis\nBiography: Allison Koenecke is a postdoc at Microsoft Research in\nthe Machine Learning and Statistics group, and starting Summer 2022 will\nbe an Assistant Professor of Information Science at Cornell University.\nHer research primarily spans two domains: algorithmic fairness in online\nservices, and causal inference in public health. Previously, she\nreceived her PhD from Stanford’s Institute for Computational &\nMathematical Engineering.\n\nAneta\nPiekut\nTitle: Integrating reproducibility into the curriculum of an\nundergraduate social sciences degree\nAbstract: While appreciation for reproducibility and research\ntransparency in social sciences research has grown substantially\nrecently, teaching research reproducibility is still less common,\nespecially at the undergraduate level. Crucially, teaching reproducible\nresearch to undergraduate students requires sequencing various open\nscience skills across the curriculum and normalising reproducible\nresearch for students. In the talk I will discuss a reproducibility\nassignment implemented in an undergraduate-level advanced Quantitative\nSocial Sciences course. As part of the assignment, students reproduced a\nmodel in a paper published in a high-impact social science journal,\nadded a small extension, and published it as a reproducible report\nonline. I will reflect on the lessons learnt from teaching several\ninteractions of the module and whether one stand-alone ‘replication\nproject’ module is enough to change students’ practice.\nBiography: Sociologist specialising in migration and ethnic studies,\nincluding measurement of attitudes, migrant integration and segregation.\nAt Sheffield Methods Institute, University of Sheffield, Aneta provides\ntraining to undergraduate and postgraduate students in advanced\nquantitative methods, survey methodology and mixed-method methodology.\nAneta is committed to teaching reproducible research methods; in 2020\nshe was Project TIER Fellow (https://www.projecttier.org/), and in 2021 joined its\nExecutive Committee.\n\nAriel Mundo\nTitle: Statistics and reproducibility in biomedical research: Why we\nneed both\nAbstract: The biomedical field still struggles at large to make\nresearch reproducible. In this talk, I argue that part of this problem\nis that most of us in biomedical research do not seem to realize the\nimportance of choosing appropriate Statistical models for our data, and\nhow this in turn enables reproducibility. Moreover, I also argue that we\nneed a “statistical rethinking” in biomedical research in order to\nestablish reproducibility as a core aspect of our work.\nBiography: Ariel Mundo is a Fulbright alum and PhD Candidate in the\nDepartment of Biomedical Engineering at the University of Arkansas. His\nwork focuses on the longitudinal study of changes in cancer metabolism\nusing optical and molecular tools, and the use of semi-parametric\nmethods to analyze such data. He is also an R enthusiast and avid\nreader.\n\nAya Mitani\nTitle: Reproducible, reliable, replicable? In-class exercise using\npeer-reviewed studies\nAbstract: I will share my experience in preparing and implementing\nan in-class exercise to reproduce the results from peer-reviewed\npublications in health science journals. The course, titled Analysis of\nCorrelated Data, enrolls 20 students mostly pursuing a Master of Science\ndegree in biostatistics. Challenges include finding a suitable clustered\nor longitudinal study that provides original data and translating the\ninformation given (and not given) in the “Methods” section into actual\ncode. Through this exercise, students learn whether the results are not\nonly reproducible but reliable, and whether the analysis can be\nreplicated on a different set of data. The goal through this exercise is\nto teach the students how to write an applied manuscript or report as\nmodern biostatisticians.\nBiography: I am an Assistant Professor in the Division of\nBiostatistics at the Dalla Lana School of Public Health (DLSPH) of the\nUniversity of Toronto. I obtained my Ph.D. in Biostatistics from Boston\nUniversity and did my postdoctoral research fellowship at Harvard T. H.\nChan School of Public Health. My research includes the development of\nstatistical methods for complex oral health data, multiple imputation\nfor missing data, modelling agreement in cancer screening studies, and\nbiased sampling designs in surveys and observational studies. At DLSPH,\nI teach Analysis of Correlated Data and Introduction to Joint Modeling\nin Health Research. I am passionate about incorporating good\nreproducible research practices into my teaching. In 2021, I co-founded\nthe Health Data Working Group at DLSPH to provide an accessible space\nfor students and researchers to learn about data and coding outside of\nthe classroom. I live in Etobicoke with my husband and two\nchildren.\n\nBenjamin Haibe-Kains\nTitle: The (Not-So-)Hard Path To Transparency and Reproducibility in\nAI Research\nAbstract: As artificial intelligence (AI) becomes a method of choice\nto analyze biomedical data, the field is facing multiple challenges\naround research reproducibility and transparency. Given the\nproliferation of studies investigating the applications of AI in\nresearch and clinical studies, it is essential for independent\nresearchers to be able to scrutinize and reproduce the results of a\nstudy using its materials, and build upon them in future studies.\nComputational reproducibility is achievable when the data can easily be\nshared and the required computational resources are relatively common.\nHowever, the complexity of AI algorithms and their implementation, the\nneed for specific computer hardware and the use of sensitive biomedical\ndata represent major obstacles in healthy-related AI research. In this\ntalk, I will describe the various aspects of an AI biomedical study that\nare necessary for reproducibility and the platforms that exist for\nsharing these materials with the scientific community.\nBiography: Dr. Benjamin Haibe-Kains is a Senior Scientist at the\nPrincess Margaret Cancer Centre (PM), University Health Network, and\nAssociate Professor in the Medical Biophysics department of the\nUniversity of Toronto. Dr. Haibe-Kains earned his PhD in Bioinformatics\nat the Université Libre de Bruxelles (Belgium). Supported by a Fulbright\nAward, he did his postdoctoral fellowship at the Dana-Farber Cancer\nInstitute and Harvard School of Public Health (USA). Dr. Haibe-Kains’\nresearch focuses on the integration of high-throughput data from various\nsources to simultaneously analyze multiple facets of carcinogenesis.\nDr. Haibe- Kains’ team is analyzing large-scale radiological and\n(pharmaco)genomic datasets to develop new prognostic and predictive\nmodels to improve cancer care.\n\nCarl Laflamme\nTitle: Antibody Characterization through Open Science (YCharOS)\nAbstract: Global sales of commercial antibodies are estimated at $2\nbillion per year with approximately half that money wasted on\nunderperforming reagents. Both public and private sectors agree that a\nrobust, independent, and scalable process to characterize commercial\nantibodies is required, but all attempts to find a solution have failed\ndue to the tangle of conflicting interests in both academia and\nindustry. YCharOS (Antibody Characterization using Open Science), in\ncollaboration with the Structural Genomics Consortium (SGC) and the\nMontreal Neurological Institute (The Neuro, McGill University) has\ncreated an open science ecosystem in which antibody manufacturers,\nknockout cell line providers, academics, pharma and granting agencies\ncontribute resources and knowledge to solve the antibody liability\ncrisis. We have already publicly shared the identification of hundreds\nof high-performing antibodies for dozens of neuroscience targets. We\nhave scaled up our platform, developed automation and expanded our team.\nWe now aim to characterize antibodies for the human proteome.\n\nChris Kenny\nTitle: Reproducible Redistricting\nAbstract: Modern redistricting is known for occurring behind closed\ndoors where incumbent politicians can work to advance their\nco-partisan’s interests. Recent advancements in political science and\nstatistical research have developed the tools to help resolve these\nproblems. I overview the R-package-based workflow that the ALARM Project\nand its members use for research, advocacy, and testimony to courts. Key\npackages developed for these purposes include redist, redistmetrics, and\ngeomander.\nBiography: Chris Kenny is a Ph.D. candidate in the Department of\nGovernment at Harvard University, studying American Politics and\nPolitical Methodology. He is currently the Political Science\nPre-Doctoral Fellow at the Harvard Election Law Clinic. His substantive\nfocus is on redistricting and gerrymandering. He primarily develops\nopen-source R tools for analyzing redistricting and voting rights in\ngeographic and contemporary contexts. He is an affiliate with the Center\nfor American Political Studies at Harvard University, The Institute for\nQuantitative Social Science, and the Algorithm-Assisted Redistricting\nMethodology (ALARM) Project.\n\nColin Rundel\nTitle: Teaching Statistical computing with Git and GitHub\n\nColm-cille Caulfield\nTitle: Reproducibility in an Uncertain World: How should academic\ndata science researchers give advice? open science-type\ninitiatives\n\nDavid Grubbs and Lara Spieker\nTitle: On book publishing\nAbstract: In this very practical and interactive workshop, four book\neditors from Chapman and Hall/CRC will discuss why you should consider\npublishing an R or Data Science book and why you should work with CRC.\nThe editors will go over the publishing process and provide best\npractices for shaping your ideas and submitting a book proposal; discuss\ntheir bestsellers and popular series as well as emerging topics and\ntrends. The lively discussion will provide plenty of opportunities for\nthe attendees to ask questions and discuss ideas.\n\nDebbie\nYuster\nTitle: Infusing Reproducibility into Introductory Data Science\nAbstract: In this talk, I will discuss the role of reproducibility\nin my Introduction to Data Science course. The course has no\nprerequisites, so many students are coding and analyzing data for the\nfirst time. They develop habits of reproducibility from the start: their\nanalyses are done within R Markdown documents, and GitHub is used to\nfacilitate both version control and collaboration among teammates.\nThrough scaffolded coding exercises, gradual onboarding to GitHub, and\nfocusing on a small subset of GitHub functionality, even beginner\nstudents can become adept at using these technologies. I will also\ndiscuss tips learned from teaching the course in a fully remote format,\nand will provide pointers to training resources for instructors who want\nto use similar tools and workflows in their own courses.\nBiography: Debbie Yuster is an Assistant Professor of Data Science\nand Mathematics at Ramapo College of New Jersey. She holds a Ph.D. in\nMathematics from Columbia University. Prior to joining Ramapo, Debbie\nserved as a math professor at SUNY Maritime College, earning the SUNY\nChancellor’s Award for Excellence in Teaching. Debbie served as a\nVisiting Data Science Scholar at the Wall Street Journal, and has\ncultivated industry partnerships leading to undergraduate research\nprojects. She also has an interest in K-12 STEM outreach, having worked\nwith secondary school teachers and students for many years.\n\nDewi Amaliah\nTitle: Reproducible Practice in Taming the Wild Data\nAbstract: I will talk about my experience in refreshing the wages\ndata from the prominent survey, NLSY79, which is used as an example of\nlongitudinal data in a textbook (Singer and Willet, 2003). The\nmotivation of this study is to demonstrate the steps (extracting,\ntidying, cleaning, and exploring) and clearly articulate the decision\nmade when data is refreshed from the raw (wild) to the textbook (tame)\ndata. All of those steps are documented to ensure reproducibility.\n\nErin Heerey\nTitle: The Experimenter in the Room\n\nFernando Hoces de la Guardia\nTitle: Social Sciences Reproducibility Platform Social Sciences\nReproducibility Platform\n\nKevin Wilson and Jake\nBowers\nTitle: Six Tips for Reproducible Field Experiments\n\nJason\nHattrick-Simpers\nTitle: Towards Trust and Reproducibility in Materials AI\nBiography: Jason Hattrick-Simpers is a Professor at the Department\nof Materials Science and Engineering, University of Toronto, and a\nResearch Scientist at CanmetMATERIALS. He graduated with a B.S. in\nMathematics and a B.S. in Physics from Rowan University and a Ph.D. in\nMaterials Science and Engineering from the University of Maryland. Prior\nto joining UofT Prof. Hattrick-Simpers was a staff scientist at the\nNational Institute of Standards and Technology (NIST) in Gaithersburg,\nMD where he co-developed tools for discovering novel corrosion\nresistance of alloys, developed active learning approaches to guide thin\nfilm and additive manufacturing alloy studies, and developed tools and\nbest practices to enable trust in AI within the materials science\ncommunity.\n\nJohn\nMcLevey\nTitle: Reproducibility and Principled Data Processing in Python\n\nJulien Chiquet\nTitle: Computo: a journal of the French Statistical Society\npromoting reproductibility\nAbstract: This talk will present Computo (https://computo.sfds.asso.fr/), an academic journal that\nhas just been born, which calls for higher standards in the publication\nof scientific results. In order to achieve this goal, Computo goes\nbeyond classical static publications by leveraging technical advances in\nliterate programming and scientific reporting. Computo focuses on\ncomputational and algorithmic methodological contributions to the field\nof statistics and machine learning. The journal is designed to allow\nauthors to demonstrate the usefulness of their methods for data\nanalysis, but also to promote the numerical illustration of theoretical\nproperties. In the era of the reproducibility crisis, Computo differs\nfrom other journals in the centrality given to the issues of\nreplicability and open science: - Computo is distributed solely online,\nfree for authors and readers; - It systematically makes available the\nexchanges between authors and reviewers, the latter being able to choose\nto remain anonymous; - Computo uses an original publication format that\nguarantees the reproducibility of results: articles are submitted and\npublished in the form of interactive documents (“notebook” integrating\ntext, code, equations and bibliographic references), associated with a\ngithub repository configured to demonstrate, dynamically and durably,\nthe reproducibility of the contribution. On the Computo submission page,\nwe offer various templates to prepare your submissions, as well as an\nexample of a finalized article and the associated repository.\nBiography: Julien Chiquet, editor of Computo, is a senior researcher\nin statistical learning. He is supported for this project by co-editors\nChloé Azencott, Pierre Neuvial and Nelle Varoquaux, all researchers in\nmachine learning and statistics\n\nLars\nVilhuber\nTitle: Teaching for large-scale Reproducibility Verification\nAbstract: We describe a unique environment in which undergraduate\nstudents from various STEM and social science disciplines are trained in\ndata provenance and reproducible methods, and then apply that knowledge\nto real, conditionally accepted manuscripts and associated replication\npackages. We describe in detail the recruitment, training, and regular\nactivities. While the activity is not part of a regular curriculum, the\nskills and knowledge taught through explicit training of reproducible\nmethods and principles, and reinforced through repeated application in a\nreal-life workflow, contribute to the education of these undergraduate\nstudents, and prepare them for post-graduation jobs and further\nstudies.\nBiography: Lars Vilhuber holds a Ph.D. in Economics from Université\nde Montréal, Canada, and is currently on the faculty of the Cornell\nUniversity Economics Department. He has interests in labor economics,\nstatistical disclosure limitation and data dissemination, and\nreproducibility and replicability in the social sciences. He is the Data\nEditor of the American Economic Association, and Managing Editor of the\nJournal of Privacy and Confidentiality.\n\nLisa\nStrug\nTitle: Introduction and overview\nBiography: Dr. Strug is Professor in the Departments of Statistical\nSciences, Computer Science and cross-appointed in Biostatistics at the\nUniversity of Toronto and is a Senior Scientist in the Program in\nGenetics and Genome Biology at the Hospital for Sick Children. Dr. Strug\nis the inaugural Director of the Data Sciences Institute (DSI), a\ntri-campus, multi-divisional, multi-institutional, multi-disciplinary\nhub for data science activity at the University of Toronto and\naffiliated Research Institutes. The DSI’s goal is to accelerate the\nimpact of data sciences across the disciplines to address pressing\nsocietal questions and drive positive social change. Dr. Strug holds\nseveral other leadership positions at the University of Toronto\nincluding the Director of the Canadian Statistical Sciences Institute\nOntario Region (CANSSI Ontario), and at the Hospital for Sick Children\nas Associate Director of the Centre for Applied Genomics and the Lead of\nthe Canadian Cystic Fibrosis Gene Modifier Consortium and the Biology of\nJuvenile Myoclonic Epilepsy International Consortium. She is a\nstatistical geneticist and her research focuses on the development of\nnovel statistical approaches to analyze and integrate multi-omics data\nto identify genetic contributors to complex human disease. She has\nreceived several honours including the Tier 1 Canada Research Chair in\nGenome Data Science.\n\nMarco Prado\nTitle: Reproducibility for Behavior Experiments in Basic\nScience\nBiography: Marco Prado is scientist at the Robarts Research\nInstitute and a full professor at the University of Western Ontario,\nwhere he holds a Canada Research Chair in Neurochemistry of Dementia. He\nis interested in understanding how neurochemical alterations in\nneurodegenerative diseases contribute to protein misfolding and\ncognitive dysfunction. He has made contributions to understanding\nmaladaptive signaling in Alzheimer’s and Prion diseases by investigating\nphysiological functions of the prion protein and in how molecular\nchaperones affect signaling and protein misfolding in neurodegenerative\ndiseases. He has developed multiple genetic mouse models of\nneurochemical dysfunction in dementia. Marco’s group combines the use of\nsophisticated touchscreen tests of high-level cognition and detailed\nbiochemical analysis to reveal several mechanisms regulating executive\nfunction and mechanisms of pathological changes in mouse models. He is\ncurrently spearheading with several colleagues an Open Science\nRepository (www.mousebytes.ca) for high-level cognitive data in mouse\nmodels of neurodegenerative disease. This effort will support a\ncommunity of more than 300 laboratories to increase reproducibility and\nreplicability of cognitive datasets in pre-clinical research. Marco\nPrado received several awards, including the Guggenheim Fellowship, for\nhis work and has published over 200 manuscripts.\n\nMaria Tackett\nTitle: Knit, Commit, and Push: Teaching version control in\nundergraduate statistics courses\nAbstract: In recent years there has been increased focus on\nincorporating the skills required to conduct well-documented and\nreproducible analyses in the undergraduate statistics curriculum.\nBecause data analysis is an iterative process, version control, a record\nof changes to a set of files over time, is a foundational part of a\nreproducible workflow. In this talk, I will describe how version control\nwith Git can be included as a learning objective in the first and second\nstatistics courses. I’ll discuss strategies for introducing version\ncontrol to students, incorporating it in individual and team-based\nassignments, and assessing students’ understanding. I’ll also share\nlessons learned and an example of how this can be implemented using\nRStudio and GitHub.\nBiography: Maria Tackett is an Assistant Professor of the Practice\nin the Department of Statistical Science at Duke University. Prior to\njoining the faculty at Duke, Maria earned a Ph.D. in Statistics from the\nUniversity of Virginia and worked as a statistician at Capital One. Her\nwork focuses on using active learning strategies to increase engagement\nin large undergraduate statistics courses, and understanding how\nclassroom practices impact students’ sense of community in these\ncourses. Maria is active in the statistics education community,\nincluding serving as the current Communications Officer for the ASA\nSection on Statistics and Data Science Education.\n\nMarkus Fritsch\nTitle: Towards reproducible GMM estimation\nAbstract: Generalized method of moments (GMM) estimation is a way\nforward in regression setups where endogeneity is present. A practically\nrelevant area of application is the estimation of linear dynamic panel\ndata models. This context forces the researcher to make many decisions\nthat seem marginal at first, but which often affect the estimation and\ninference dramatically. The decisions comprise the number and type of\nemployed moment conditions, their weighting scheme, how covariates\nand/or dummy variables are included, whether we iterate the estimation\nprocedure and/or bias-correct, etc. Due to the many possible choices,\nclear documentation and reproducibilty are vital for the communication\nof GMM estimation results. We provide guidelines for reproducible GMM\nestimation and demonstrate their relevance by replicating and extending\nseveral empirical applications.\nBiography: Markus Fritsch is Assistant Professor at the Chair of\nStatistics and Data Analytics of the University of Passau. He is the\ncreator of the CRAN package pdynmc. His research interest include Data\nScience & Statistical Learning, GMM estimation, Quantile regression,\nand reproducible Applied Statistics.\n\nMichael Geuenich\nTitle: With great data come great pipelines: creating flexible\nstandardized pipelines for common biomedical analysis tasks using\nSnakemake\nAbstract: Biomedical data analysis pipelines are becoming\nincreasingly complex as projects frequently involve the analysis of raw\ndata from distinct batches and experimental modalities. Work frequently\nstarts with processing and normalizing several large datasets in a\nvariety of ways, often requiring custom filtering approaches for each\nindividual dataset. Existing and novel analysis methods are then\nfrequently applied to the processed data using a variety of parameters\nprior to subsequent benchmarking, resulting in many individual analysis\nsteps that need to be tied together. Importantly, some data processing\nsteps are frequently dependent on the data itself, requiring inspection\nof preliminary results before being able to run a standardized pipeline\nin full. In addition, pre-processing steps are frequently revised as\npart of the iterative analysis workflow common to most projects, thus\nrequiring downstream analyses to be re-run as input data changes. These\nchallenges make it cumbersome and error prone to run individual analysis\nsteps manually. Workflow managers such as Snakemake allow for the\ncreation of reproducible and easily\nBiography: Michael is a PhD student in the computational track of\nthe molecular genetics department at the University of Toronto and at\nthe Lunenfeld Tanenbaum Research Institute with Kieran Campbell. His\nwork focusses on better understanding immune escape in pancreatic cancer\nusing machine learning tools and a diverse set of -omics data.\n\nMine Çetinkaya-Rundel\nTitle: Reproducible authoring with Quarto\nBiography: I am a Professor of the Practice and the Director of\nUndergraduate Studies at the Department of Statistical Science and an\naffiliated faculty in the Computational Media, Arts, and Cultures\nprogram at Duke University. My work focuses on innovation in statistics\nand data science pedagogy, with an emphasis on computing, reproducible\nresearch, student-centered learning, and open-source education. I work\non integrating computation into the undergraduate statistics curriculum,\nusing reproducible research methodologies and analysis of real and\ncomplex datasets. In addition to my academic position, I also work with\nRStudio, where I focus primarily on education for open-source R packages\nas well as building resources and tools for educators teaching\nstatistics and data science with R and RStudio.\n\nMonica Alexander\nTitle: Reproducibility in Demography: where are we at and where can\nwe go?\nBiography: Monica Alexander is an Assistant Professor in Statistical\nSciences and Sociology at the University of Toronto. Her research\nfocuses on developing statistical methods to help measure demographic\nand health outcomes. She received a PhD in Demography and Masters in\nStatistics from the University of California, Berkeley. She has worked\non research projects with organizations such as UNICEF, the World Health\nOrganization, the Bill and Melinda Gates Foundation, and the Human\nMortality Database.\n\nNick\nRadcliffe\nTitle: Gentest: Automatic Test Generation for Data Science\nAbstract: This talk will focus on reference tests—scripts that test\nthe ongoing correctness of scripts, programs and pipelines with a\nparticular focus on data science-oriented tasks. The TDDA library has\nlong offered support to allow humans to write useful tests for data\nscience workflows, with a focus on supporting tests for what might be\ncalled semantic/functional correctness, rather than syntactic/form\ncorrectness. New “Gentest” functionality in TDDA goes further by\nautomating large parts of test production. Using Gentest, researchers\ncan concentrate on developing robust/correct analysis pipelines,\nverifying them in the usual way (probably by hand), and then use Gentest\nto generate executable tests automatically. Although Gentest is written\nin Python, it can be also used to generate tests for R or almost any\nother language. If all goes well, this talk will include a demonstration\nof automatically generating tests for R scripts.\nBiography: Nick Radcliffe is the founder of the data science\nconsulting and software firm, Stochastic Solutions Limited, the Interim\nChief Scientist at the Global Open Finance Centre of Excellence, and a\nVisiting Professor in Maths and Stats at University of Edinburgh,\nScotland. His background combines theoretical physics, operations\nresearch, machine learning and stochastic optimization. Nick’s current\nresearch interests include a focus on test-driven data analysis, (an\napproach to improving correctness of analytical results that combines\nideas from reproducible research and test-driven development) and\nprivacy-respecting analysis. He is the lead author of the open-source\nPython tdda package, which provides practical tools for testing\nanalytical software and data, and also of the Miró data analysis\nsuite.\n\nParaskevi Massara\nTitle: MOSS4Research: A maturity model to evaluate and improve\nreproducibility in research projects.\nAbstract: Our ability to gather large amounts of data, store it and\nanalyze it efficiently has created new research opportunities in health\nsciences and it has led to novel practices. One such practice is the\ncreation of large datasets that can be used in multiple studies\neffectively increasing our research output. However, big data is no free\nlunch and it comes with its own challenges. On one hand, improper\nmanagement of data may lead to problems when communicating or sharing\ndata. Different terminology, inaccessible storage,\nethical/economic/social barriers may be some of the problems related to\nsharing the common large datasets. On the other hand, improper\nmanagement is not constrained only in data, but can extend to the\nanalysis as well, where processes or analytical tasks are not properly\ndocumented or permanently stored. These problems significantly inhibit\nthe reproducibility of studies, which in turn may make the verification\nof research results practically impossible, and they can also lead to\nwaste in terms of lost data, time, effort and funds. Other practical\ndomains, such as computer science or engineering, have long employed\nmethods to systematically document data and processing tasks to allow\nfor repetition and reproducibility. Based on such methods, we propose a\nnovel framework to evaluate the maturity of the reproducibility\npractices employed in the context of individual projects or within an\nentire research team. The framework consists of a self-assessment\nquestionnaire and a maturity model to allow teams to evaluate the\nmaturity of their responsibility practices and a guide on how to\nincrease their maturity level. The guide contains practices drawn from\nother domains to improve communication, collaboration and\nreproducibility.\nBiography: Paraskevi Massara is a PhD candidate supervised by Drs.\nElena Comelli and Robert Bandsma. Her research interests include growth\npattern detection in children in association with gut microbiome. She is\na coding enthusiast and an aspiring data science have extensive\npractical experience with programming, machine learning and statistics,\nand development and management platforms such as Github. She is a member\nof R ladies and Women Who Code. She is the recipient among others of\nOntario Graduate Scholarship, Peterborough Hunter Charitable Foundation\nGraduate Award, Connaught International Scholarship.\n\nRobert\nHanisch\nTitle: Reproducibility: A Metrology Perspective\nBiography: Dr. Robert J. Hanisch is the Director of the Office of\nData and Informatics in the Material Measurement Laboratory at NIST.\nPrior to this appointment (July 2014) he was a Senior Scientist at the\nSpace Telescope Science Institute (STScI), Baltimore, Maryland, and\nDirector of the US Virtual Astronomical Observatory. In the past\ntwenty-five years Dr. Hanisch has led many efforts in the astronomy\ncommunity in the area of information systems and services, focusing\nparticularly on efforts to improve the accessibility and\ninteroperability of data archives and catalogs. He was the first chair\nof the International Virtual Observatory Alliance Executive Committee\n(2002-2003) and continues as a member of the IVOA Executive. From 2000\nto 2002 he served as Chief Information Officer at STScI, overseeing all\ncomputing, networking, and information services for the Institute. Prior\nto that he had oversight responsibilities for the Hubble Space Telescope\nData Archive and led the effort to establish the Multimission Archive at\nSpace Telescope—MAST—as the optical/UV archive center for NASA\nastrophysics missions. He has served as chair of the Program Organizing\nCommittee for the Astronomical Data Analysis Software and Systems\n(ADASS) conferences, chair of the Astrophysics Data Centers Coordinating\nCommittee, and co-chair of the Decadal Survey Study Group on\nComputation, Simulation, and Data Handling. He is currently president of\nIAU Commission 5 (Data and Documentation), chair of the IAU Comm. 5\nWorking Group on Virtual Observatories, Data Centers, and Networks, and\nco-chair of the Comm. 5 Working Group on Libraries. He completed his\nPh.D. in Astronomy in 1981 at the University of Maryland, College Park,\nworking in the field of extragalactic radio astronomy with Prof. William\nErickson.\n\nShannon Ellis\nTitle: Structuring & Managing Group Projects in Large-Enrollment\nUndergraduate Data Science Courses\nAbstract: Computational notebooks are a popular tool for generating\ntechnical data science reports, as they allow for narrative text, code,\nand code outputs in a single explanatory document. Given their\npopularity, many data science courses utilize computational notebooks\nfor instruction, assignments, and projects, the output of which can be\nanalyzed to better understand student behavior and improve instruction.\nHere, we present the results from the analysis of 686 final group data\nscience projects from 8 iteractions of the undergraduate course COGS 108\nData Science in Practice to explain how students approach open-ended\ndata science projects and provide data science instructors with general\nrecommendations on structuring and managing reproducible data science\nprojects in large-enrollment data science courses.\nBiography: Shannon E. Ellis is an Assistant Teaching Professor at UC\nSan Diego in the Cognitive Science Department, where her primary focus\nis teaching programming and data science to thousands of undergraduate\nstudents each academic year. Prior to her arrival at UC San Diego,\nShannon received her Ph.D. in Human Genetics from the Johns Hopkins\nSchool of Medicine and completed a postdoctoral fellow in the Department\nof Biostatistics at the Johns Hopkins Bloomberg School of Public Health.\nShannon is particularly passionate about data science, ethical data\nanalysis, and education. She aims to ensure that data science education\nis accessible to everyone, with a particular focus on individuals from\nmarginalized groups who typically have not had access to such materials\nand training.\n\nShilaan Alzahawi\nTitle: Lay perceptions of scientific findings: Swayed by the\ncrowd?\nAbstract: Every day, important scientific findings are rejected at\nlarge. To increase public faith in science, some have proposed the use\nof crowd science. Drawing from theories on social norms and numerical\ncognition, we test whether crowd science improves lay perceptions of\nscientific findings. We run an experiment (N = 2,019; preregistration,\ndata, code, and materials at osf.io/vedb4) to study the effects of\nscientific findings emerging from a crowd of researchers (vs. a typical\nresearch collaboration) on lay consumers’ posterior beliefs, confidence\nin an aggregate effect size estimate, and ratings of credibility, bias,\nand error. We focus on crowdsourced data analysis: a crowd of scientists\nwho independently analyze the same data to estimate and report a\nparameter of interest. Contrary to our hypotheses, we do not find that\nconsistent crowd estimates increase the sway and credibility of\nscientific findings to lay consumers: instead, to our surprise, they\nlead to lower posterior beliefs and higher ratings of error. In the\nfuture, it is important for crowd scientists to consider how to tackle\nscience skepticism and effectively communicate variable crowd estimates\nto lay consumers.\nBiography: Shilaan Alzahawi is a Master student in Statistics at\nGhent University and a PhD candidate in Organizational Behavior at\nStanford University. Shilaan is interested in meta-science and\ninferential statistics, with a particular interest in the coordination\nand effectiveness of large-scale science collaborations.\n\nStephen Eglen\nTitle: Evaluating the reproducibility of computational results\nreported in scientific journals\nAbstract: A recent study (< http://dx.doi.org/10.1371/journal.pbio.3001107>)\nestimated that only 2% of biomedical articles shared code relating to\ncomputations. This lack of sharing of code inhibits reproducibility of\nfindings and reusability of methods. I will introduce our CODECHECK\nproject < https://codecheck.org.uk> that reviews computational\nfindings underlying research articles in biosciences. Compared to\ntraditional peer review, this review is open and interactive, with the\naim of helping all authors make their work reproducible. All code/data\nrequired to reproduce computational results, and the results themselves,\nare shared freely following FAIR guidelines. We hope our system will be\nused across multiple publishers and bring a cultural change towards more\ntransparent, open, and reusable computational workflows. This is joint\nwork with Daniel Nust.\nBiography: SJE is Professor of Computational Neuroscience, in the\nDepartment of Applied Mathematics and Theoretical Physics, University of\nCambridge. He has a long-standing interest in open science and\nreproducible research. He co-leads the CODECHECK project for\nreproducibility of computations in scientific publications (https://codecheck.org.uk). He is an associate editor for\nBiorXiv and is on advisory boards for F1000 Research and Gigabyte.\n\nValentin\nDanchev\nTitle: Reproducibility and Replicability of Large Pre-trained\nLanguage Models\nAbstract: A major recent development in artificial intelligence and\ndeep learning research are large language models (LLMs) (e.g., BERT,\nGPT-3, Gopher) that are trained on a massive amount of language data and\nare subsequently applied to a wide range of downstream tasks. Over the\nlast couple of years, LLMs have been adopted and have shown promise\nacross research domains, pointing to the importance of evaluating the\nscientific potential and challenges of these models through the lenses\nof research transparency, computational reproducibility, and\nreplicability. While challenges for reproducibility and replicability in\ndata-intensive computational applications are not new, pre-trained LLMs\nbuilt on deep learning approaches bring some novel epistemic challenges\nas well as related ethical and social risks. Specifically, the massive\nand often sensitive, publicly unavailable, and proprietary data sets on\nwhich these models are pre-trained; the scale of the models with\nhundreds of billions of parameters and associated computationally\nintensive infrastructure; and the pre-trained nature of the models\nforming a basis for subsequent applications in the context of restricted\naccess to many of the models, their software, and training procedures\ncan all pose challenges to research transparency, computational\nreproducibility, and replicability. I will discuss these challenges and\noutline possible improvements drawing on principles of responsible and\nreproducible research and on recent frameworks and practices in\ndata-intensive computational sciences aiming to securely access and\nmodel sensitive data at scale.\nBiography: Valentin Danchev is a Lecturer in Computational Social\nScience at the University of Essex and a Fellow of the Software\nSustainability Institute. He holds a DPhil from the University of Oxford\nand held postdoctoral positions at the University of Chicago and the\nStanford University School of Medicine. His research combines\ncomputational methods from data science and network analysis with\napproaches from reproducible research and metascience to study the\ntransparency, reproducibility, bias, and social impact of data-intensive\nresearch, with a current focus on evaluating and improving the\ntransparency and reproducibility of applications of data science,\nartificial inteligence, and machine learning in the social and health\nsciences. In another stream of research, he uses computational social\nscience and network analysis to examine health-related misinformation,\ndigital-health interventions, and inequality in network structures of\nglobal migration. He teaches data science with an emphasis on open\nreproducible workflows and responsible analysis of real-world data.\n\nYann Joly\nTitle: Incentivizing open data sharing - what’s in it for me!?\n\n2021\nTimetable\nThursday, 25 February, 2021\nTime\nSpeaker\nFocus\nRecording\n9:00-9:10am\nRohan Alexander, University of Toronto\nWelcome\n-\n9:10-9:20am\nRadu Craiu, University of Toronto\nOpening remarks\nhttps://youtu.be/JGGVEgMBURU\n9:20-9:30am\nWendy Duff, University of Toronto\nOpening remarks\nhttps://youtu.be/Z3aWU1A0FCw\n9:30-10:25am\nMine Çetinkaya-Rundel, University of Edinburgh\nKeynote - Teaching\nhttps://youtu.be/ANH2tv2vkew\n10:30-11:30am\nRiana Minocher, Max Planck Institute for Evolutionary\nAnthropology\nKeynote - Evaluating\nhttps://youtu.be/O3t8TwWeli0\n11:30-11:55am\nTiffany Timbers, University of British Columbia\nTeaching\nhttps://youtu.be/mh93W8XimOg\nNoon-12:25pm\nTyler Girard, University of Western Ontario\nTeaching\nhttps://youtu.be/k3qgmUAjIvA\n12:30-12:55pm\nShiro Kuriwaki, Harvard University\nPractices\nhttps://youtu.be/-J-eiPnmoNE\n1:00-1:25pm\nMeghan Hoyer, Washington Post & Larry Fenn\nAP\nPractices\nhttps://youtu.be/FFwMfNk83rc\n1:30-1:55pm\nTom Barton, Royal Holloway, University of London\nEvaluating\nhttps://youtu.be/YTdhcSDqFNQ\n2:00-2:25pm\nBreak\n-\n-\n2:30-2:55pm\nMauricio Vargas, Catholic University of Chile & Nicolas\nDidier Arizona State University\nEvaluating\nhttps://youtu.be/VpTavLYEMgg\n3:00-3:25pm\nJake Bowers, University of Illinois & The Policy\nLab\nPractices\nhttps://youtu.be/3N0YwJIbbHg\n3:30-3:55pm\nAmber Simpson, Queens University\nPractices\nhttps://youtu.be/uUfrcB6aynQ\n4:00-4:25pm\nGarret Christensen, US FDIC\nEvaluating\nhttps://youtu.be/595KkVKJ29w\n4:30-4:55pm\nYanbo Tang, University of Toronto\nPractices\nhttps://youtu.be/0x6gOkldOvk\n5:00-5:25pm\nLauren Kennedy, Monash University\nPractices\nhttps://youtu.be/HhfogRbgbA4\n5:30-6:00pm\nLisa Strug, University of Toronto & CANSSI Ontario\nClosing remarks\nhttps://youtu.be/B_9puTSp3f8\nFriday, 26 February, 2021\nTime\nSpeaker\nFocus\nRecording\n8:00-8:30am\nNick Radcliffe and Pei Shan Yu, Global Open Finance Centre of\nExcellence & University of Edinburgh\nPractices\nhttps://youtu.be/pWEc8XoIIKE\n8:30-9:00am\nJulia Schulte-Cloos, LMU Munich\nPractices\n-\n9:00-9:25am\nSimeon Carstens, Tweag/IO\nPractices\nhttps://youtu.be/fpoFzDvrJAA\n9:30-9:55am\nBreak\n-\n-\n10:00-10:55am\nEva Vivalt, University of Toronto\nKeynote - Practices\nhttps://youtu.be/0WZUzf2oSGY\n11:00-11:25am\nAndrés Cruz, Pontificia Universidad Católica de Chile\nPractices\nhttps://youtu.be/HjdPDEACxmA\n11:30-11:55am\nEmily Riederer, Capital One\nPractices\nhttps://youtu.be/BknQ0ZNkMNY\nNoon-12:25pm\nFlorencia D’Andrea, National Institute of Agricultural\nTechnology\nPractices\nhttps://youtu.be/9FVUIPfBeXw\n12:30-12:55pm\nJohn Blischak, Freelance scientific software developer\nPractices\nhttps://youtu.be/RrcaGukYDyE\n1:00-1:25pm\nShemra Rizzo, Genentech\nPractices\nhttps://youtu.be/rEYtB3CG76Q\n1:30-2:25pm\nBreak\n-\n-\n2:30-2:55pm\nWijdan Tariq, University of Toronto\nEvaluating\n-\n3:00-3:25pm\nSharla Gelfand, Freelance R Developer\nPractices\nhttps://youtu.be/G5Nm-GpmrLw\n3:30-3:55pm\nRyan Briggs, University of Guelph\nPractices\nhttps://youtu.be/_dgGbxItiB4\n4:00-4:25pm\nMonica Alexander, University of Toronto\nPractices\nhttps://youtu.be/yvM2C6aZ94k\n4:30-4:55pm\nAnnie Collins, University of Toronto\nPractices\nhttps://youtu.be/u4ibhN_nWyI\n5:00-5:25pm\nNancy Reid, University of Toronto\nPractices\nhttps://youtu.be/sIsOPuZOQL4\n5:30-6:00pm\nRohan Alexander, University of Toronto\nClosing remarks\nhttps://youtu.be/7LttFNOI6p8\nPresenter biographies and\nabstracts\nKeynotes:\nEva Vivalt\nBio: Eva Vivalt is an Assistant Professor in the Department of\nEconomics at the University of Toronto. Her main research interests are\nin cash transfers, reducing barriers to evidence-based decision-making,\nand global priorities research.\nAbstract: An overview of the role of forecasting and a new platform\nfor making them.\n\nMine\nÇetinkaya-Rundel\nBio: Mine Çetinkaya-Rundel is a Senior Lecturer in Statistics and\nData Science in the School of Maths at University of Edinburgh, and\ncurrently on leave as Associate Professor of the Practice in the\nDepartment of Statistical Science at Duke University as well as a\nProfessional Educator and Data Scientist at RStudio. She is the author\nof three open source statistics textbooks and is an instructor for\nCoursera. She is the chair-elect of the Statistical Education Section of\nthe American Statistical Association. Her work focuses on innovation in\nstatistics pedagogy, with an emphasis on student-centered learning,\ncomputation, reproducible research, and open-source education.\nAbstract: In the beginning was R Markdown. In this talk I will give\na brief review of teaching statistics and data analysis through the lens\nof reproducibility with R Markdown, and how to use this tool effectively\nin teaching to maintain reproducibility as the scope of your students’\nprojects and their experience grow.\n\nRiana\nMinocher\nBio: Riana Minocher is a doctoral student at the Max Planck\nInstitute for Evolutionary Anthropology in Leipzig. She is an\nevolutionary biologist with broad interests. She has worked on a range\nof projects on human and non-human primate behaviour and ecology. She is\nparticularly interested in the evolutionary processes that create and\nshape diversity between and within groups. Through her PhD research, she\nis keen on exploring the dynamics of cultural transmission and learning\nin human populations, to better understand the diverse patterns of\nbehaviour we observe.\nAbstract: Interest in improving reproducibility, replicability and\ntransparency of research has increased substantially across scientific\nfields over the last few decades. We surveyed 560 empirical,\nquantitative publications published between 1955 and 2018, to estimate\nthe rate of reproducibility for research on social learning, a large\nsubfield of behavioural ecology. We found supporting materials were\navailable for less than 30% of publications during this period. The\navailability of data declines exponentially with time since publication,\nwith a half-life of about six years, and this “data decay rate” varies\nsystematically with both study design and study species. Conditional on\nmaterials being available, we estimate that a reasonable researcher\ncould expect to successfully reproduce about 80% of published results,\nbased on our evaluating a subset of 40 publications. Taken together,\nthis indicates an overall success rate of 24% for both acquiring\nmaterials and recovering published results, with non-reproducibility of\nresults primarily due to unavailable, incomplete, or poorly-documented\ndata. We provide recommendations to improve the reproducibility of\nresearch on the ecology and evolution of social behaviour.\n\nInvited presentations:\nAmber\nSimpson\nBio: Amber Simpson is the Canada Research Chair in Biomedical\nComputing and Informatics and Associate Professor in the School of\nComputing (Faculty of Arts and Science) and Department of Biomedical and\nMolecular Sciences (Faculty of Health Sciences). She specializes in\nbiomedical data science and computer-aided surgery. Her research group\nis focused on developing novel computational strategies for improving\nhuman health. She joined the Queen’s University faculty in 2019, after\nfour years as faculty at Memorial Sloan Kettering Cancer Center in New\nYork and three years as a Research Assistant Professor in Biomedical\nEngineering at Vanderbilt University in Nashville. She is an American\nAssociation of Cancer Research award winner and the holder of multiple\nNational Institutes of Health grants. She received her PhD in Computer\nScience from Queen’s University.\nAbstract: The development of predictive and prognostic biomarkers is\na major area of investigation in cancer research. Our lab specializes in\nthe development of quantitative imaging markers for personalized\ntreatment of cancer. Progress in developing these novel markers is\nlimited by a lack of optimization, standardization, and validation, all\ncritical barriers to clinical use. This talk will describe our work in\nthe repeatability and reproducibility of imaging biomarkers.\n\nAndrés Cruz\nBio: Andrés Cruz is an adjunct instructor at Pontificia Universidad\nCatólica de Chile, where he teaches computational social science. He\nholds a BA and MA in Political Science, and is the co-editor of “R for\nPolitical Data Science: A Practical Guide” (CRC Press, 2020), an R\nmanual for social science students and practitioners.\nAbstract: inexact is an RStudio addin to supervise\nfuzzy joins. Merging data sets is a simple procedure in most statistical\nsoftware packages. However, applied researchers frequently face problems\nwhen dealing with data in which ID variables are not properly\nstandardized. For instance, politicians’ names can be spelled\ndifferently in multiple sources (press reports, official documents,\netc.), causing regular merging methods to fail. The most common approach\nto fix this issue when working with small and medium data sets is\nmanually fixing the problematic values before merging. However, this\nsolution is time-consuming and not reproducible. An RStudio addin called\n“inexact” was created to help with this. The package draws from\napproximate string matching algorithms, which quantify the distance\nbetween two given strings. When merging data sets with non-standardized\nID variables, inexact users benefit from automatic match\nsuggestions, while also being able to override the automatic choices\nwhen needed, using a user-friendly graphical user interface (GUI). The\noutput is simply code to perform the corrected merging procedure, which\nregisters the employed algorithm and any corrections made by the user,\nensuring reproducibility. A development version of inexact\nis available on GitHub.\n\nAnnie Collins\nBio: Annie Collins is an undergraduate student in the Department of\nMathematics specializing in applied mathematics and statistics with a\nminor in history and philosophy of science. In her free time, she\nfocusses her efforts on student governance, promoting women’s\nrepresentation in STEM, and working with data in the non-profit and\ncharitable sector.\nAbstract: We create a dataset of all the pre-prints published on\nmedRxiv between 28 January 2020 and 31 January 2021. We extract the text\nfrom these pre-prints and parse them looking for keyword markers\nsignalling the availability of the data and code underpinning the\npre-print. We are unable to find markers of either open data or open\ncode for 81 per cent of the pre-prints in our sample. Our paper\ndemonstrates the need to have authors categorize the degree of openness\nof their pre-print as part of the medRxiv submissions process, and more\nbroadly, the need to better integrate open science training into a wide\nrange of fields\n\nEmily Riederer\nBio: Emily Riederer is a Senior Analytics Manager at Capital One.\nHer team focuses on reimagining our analytical infrastructure by\nbuilding data products, elevating business analysis with novel data\nsources and statistical methods, and providing consultation and training\nto our partner teams.\nAbstract: Complex software systems make performance guarantees\nthrough documentation and unit tests, and they communicate these to\nusers with conscientious interface design. However, published data\ntables exist in a gray area; they are static enough not to be considered\na ‘service’ or ‘software’, yet too raw to earn attentive user interface\ndesign. This ambiguity creates a disconnect between data producers and\nconsumers and poses a risk for analytical correctness and\nreproducibility. In this talk, I will explain how controlled\nvocabularies can be used to form contracts between data producers and\ndata consumers. Explicitly embedding meaning in each component of\nvariable names is a low-tech and low-friction approach which builds a\nshared understanding of how each field in the dataset is intended to\nwork. Doing so can offload the burden of data producers by facilitating\nautomated data validation and metadata management. At the same time,\ndata consumers benefit by a reduction in the cognitive load to remember\nnames, a deeper understanding of variable encoding, and opportunities to\nmore efficiently analyze the resulting dataset. After discussing the\ntheory of controlled vocabulary column-naming and related workflows, I\nwill illustrate these ideas with a demonstration of the\nconvo R package, which aids in the creation, upkeep, and\napplication of controlled vocabularies. This talk is based on my related\nblog\npost and R\npackage.\n\nFlorencia D’Andrea\nBio: Florencia D’Andrea is a post-doc at the Argentine National\nInstitute of Agricultural Technology where she develops computer tools\nto assess the risk of pesticide applications for aquatic ecosystems. She\nholds a PhD in Biological Sciences from the University of Buenos Aires,\nArgentina, and is part of the ReproHack core-team and the R-Ladies\nglobal team. She believes that code and data should also be recognized\nas valuable products of scientific work.\nAbstract: Choose your own adventure to a reproducible scientific\narticle: learnings from ReproHack “I shared the code and data of my last\nscientific article, does it mean that it is reproducible?” One might\nthink that having access to the research data and the code used to\nanalyze that data would be enough to reproduce published results, but\noften this is much more involved. Is reproducibility dependent on the\nreviewer’s knowledge? What things do we not usually think about can\naffect reproducibility? Can the choice of how to capture the\ncomputational environment influence the experience of the reviewer? In\nthis talk, we are going to think together some of the necessary steps\nthat make someone else able to reproduce a scientific article or\nproject. I will share some thoughts from my experience in ReproHack and\nshow you how reviewing is a great practice to learn about\nreproducibility. What is ReproHack? Reprohack is a hackathon-style event\nfocused on the reproducibility of research results. These hackathons\nprovide a low-pressure sandbox environment for practicing reproducible\nresearch: Authors can practice producing reproducible research and\nreceive friendly feedback and appreciation of their efforts.\nParticipants can practice reviewing, learn about reproducibility best\npractices as well as common pitfalls from working with real-life\nmaterials rather than just dummy. They also get inspired and grow\nconfidence in working more openly themselves. Research Community\nbenefits from: Evaluating what best practice is in practice. More\npractice in both developing and reviewing materials.\n\nGarret\nChristensen\nBio: Garret Christensen received his economics PhD from UC Berkeley\nin 2011. He is an economist with the FDIC. Before that he worked for the\nCensus Bureau, and he was a project scientist with the Berkeley\nInitiative for Transparency in the Social Sciences and a Data Science\nFellow with the Berkeley Institute for Data Science.\nAbstract: Adoption of Open Science Practices is Increasing: Survey\nEvidence on Attitudes, Norms and Behavior in the Social Sciences. Has\nthere been meaningful movement toward open science practices within the\nsocial sciences in recent years? Discussions about changes in practices\nsuch as posting data and pre-registering analyses have been marked by\ncontroversy—including controversy over the extent to which change has\ntaken place. This study, based on the State of Social Science (3S)\nSurvey, provides the first comprehensive assessment of awareness of,\nattitudes towards, perceived norms regarding, and adoption of open\nscience practices within a broadly representative sample of scholars\nfrom four major social science disciplines: economics, political\nscience, psychology, and sociology. We observe a steep increase in\nadoption: as of 2017, over 80% of scholars had used at least one such\npractice, rising from one quarter a decade earlier. Attitudes toward\nresearch transparency are on average similar between older and younger\nscholars, but the pace of change differs by field and methodology.\nAccording with theories of normal science and scientific change, the\ntiming of increases in adoption coincides with technological innovations\nand institutional policies. Patterns are consistent with most scholars\nunderestimating the trend toward open science in their discipline.\n\nJake Bowers\nBio: Jake Bowers is a Senior Scientist at The Policy Lab and a\nmember of the Lab’s data science practice. Jake is Associate Professor\nof Political Science and Statistics at the University of Illinois\nUrbana-Champaign. He has served as a Fellow in the Office of Evaluation\nSciences in the General Services Administration of the US Federal\nGovernment and is Methods Director for the Evidence in Governance and\nPolitics network. Jake holds a PhD in Political Science from the\nUniversity of California, Berkeley, and a BA in Ethics, Politics and\nEconomics from Yale University.\nAbstract: For evidence-based public policy to grow in impact and\nimportance, practices to enhance scientific credibility should be\nbrought into governmental contexts and also should be modified for those\ncontexts. For example, few analyses of governmental data allow data\nsharing (in contrast with most scientific studies); and many analyses of\ngovernmental administrative data inform high stakes immediate decisions\n(in contrast with the slow accumulation of scientific knowledge). We\nmake several proposals to adjust scientific norms of reproducibility and\npre-registration to the policy context.\n\nJohn Blischak\nBio: John Blischak is a freelance scientific software developer for\nthe life sciences industry. He is the primary author of the R package\nworkflowr and the co-maintainer of the CRAN Task View on Reproducible\nResearch. He received his PhD in Genetics from the University of\nChicago.\nAbstract: The workflowr R package helps organize\ncomputational research in a way that promotes effective project\nmanagement, reproducibility, collaboration, and sharing of results.\nworkflowr combines literate programming (knitr and\nrmarkdown) and version control (Git, via git2r) to generate a website\ncontaining time-stamped, versioned, and documented results. Any R user\ncan quickly and easily adopt workflowr, which includes four\nkey features: (1) workflowr automatically creates a\ndirectory structure for organizing data, code, and results; (2)\nworkflowr uses the version control system Git to track\ndifferent versions of the code and results without the user needing to\nunderstand Git syntax; (3) to support reproducibility,\nworkflowr automatically includes code version information\nin webpages displaying results and; (4) workflowr\nfacilitates online Web hosting (e.g. GitHub Pages) to share results. Our\ngoal is that workflowr will make it easier for researchers\nto organize and communicate reproducible results. Documentation and\nsource code are available.\n\nJulia Schulte-Cloos\nBio: Julia Schulte-Cloos is a Marie Skłodowska-Curie funded research\nfellow at LMU Munich. She has earned her PhD in Political Science from\nthe European University Institute. Julia is passionate about developing\ntools and templates for generating reproducible workflows and creating\nreproducible research outputs with R Markdown.\nAbstract: We present a template package in R that allows users\nwithout any prior knowledge of R Markdown to implement reproducible\nresearch practices in their scientific workflows. We provide a single\nRmd-file that is fully optimized for two different output formats, HTML\nand PDF. While in the stage of explorative analysis and when focusing on\ncontent only, researchers may rely on the ‘draft mode’ of our template\nthat knits to HTML When in the stage of research dissemination and when\nfocusing on the presentation of results, in contrast, researchers may\nrely on the ‘manuscript mode’ that knits to PDF. Our template outlines\nthe basics for successfully writing a reproducible paper in R Markdown\nby showing how to include citations, figures, and cross-references. It\nalso provides examples for the use of ggplot2 to include\nplots, both in static and animated outputs, and it shows how to present\nthe most commonly used tables in scientific research (descriptive\nstatistics and regression tables). Finally, in our template, we discuss\nsome more advanced features of literate programming and helpful tweaks\nin R Markdown.\n\nLauren Kennedy\nBio: Lauren Kennedy is a lecturer in the Econometrics and Business\nStatistics department at Monash University. She works on applied\nstatistical problems in the social sciences using primarily Bayesian\nmethodology. Her most recent work is with survey data, particularly the\nuse of model and poststratify methods to make population and\nsubpopulation predictions.\nAbstract: Survey data is challenging to work with. It frequently\ncontains entry errors (either from respondent recollection or\ninterviewer entry) that are difficult to verify and identify. Survey\ndata is often received in a form that is sensible for the software for\nwhich entry is intuitive, which does not necessarily follow through to a\ndata structure that is intuitive to work with as an analyst. When we\nconsider the use of tools like multilevel regression and\npoststratification, our challenges compound. Even if the population data\nis precleaned before release, measurements and items in the sample need\nto be mapped to measurements and items in the population. In this talk\nwe discuss case studies of how and where these challenges appear in\npractice.\n\nLarry Fenn\nBio: Larry Fenn is a data journalist at the Associated Press. His\ninvestigative work has covered a broad range of topics, from guns to\neducation to housing policy. Prior to journalism, he was an adjunct\nlecturer at Hunter College for applied mathematics and statistics.\nAbstract: Please see Meghan Hoyer.\n\nMauricio Vargas Sepúlveda\nBio: Mauricio Vargas Sepúlveda loves working with data and\nstatistical programming, and is constantly learning new skills and\ntooling in his spare time. He mostly works in R due to its huge number\nof libraries and emphasis on reproducible analysis.\nAbstract: Evidence-based policymaking has turned into a high\npriority for governments across the world. The possibility of gaining\nefficiencies in the public expenditure and linking the policy design to\nthe desired outcomes have been presented as significant advantages for\nthe field of comparative policy. However, the same movement that\nsupports the use of evidence in public policy decision making has\nbrought a great concern about the sources of the supposed evidence. How\nshould policymakers evaluate the evidence? The possibilities are open\nand depend on the institutional arrangements that support governmental\noperation and the possibility of properly judging the nature of the\nevidence. The movement of science reproducibility could enlighten the\ndiscussion about the quality of the evidence by providing a structured\napproach towards the source’s validity based on the possibility of\nreproducing the logic and analysis proper of scientific communication.\nThis paper attempts to analyze the nature and quality of civil society\norganizations’ contributions to develop evidence for policymaking\nprocess from reproducibility perspective.\n\nMeghan Hoyer\nBio: Meghan Hoyer is Data Director at The Washington Post where she\nleads data projects and acts as a consulting editor on data-driven\nstories, graphics and visualizations across the newsroom. Before this\nshe helped lead the AP’s data journalism. Meghan earned a bachelor of\nscience in journalism at Northwestern University and an MFA in creative\nnonfiction writing at Old Dominion University.\nAbstract: This talk will cover AP DataKit, which is an open-source\ncommand-line tool designed to better structure and manage projects, and\nmore generally, talk about creating sane, reproducible workflows.\n\nMonica Alexander\nBio: Monica Alexander is an Assistant Professor in Statistical\nSciences and Sociology at the University of Toronto. She received her\nPhD in Demography from the University of California, Berkeley. Her\nresearch interests include statistical demography, mortality and health\ninequalities, and computational social science.\nAbstract: Sharing code for papers and projects is an important part\nof reproducible research. However, sometimes sharing code may be\ndifficult, if the researcher feels their code is ‘not good enough’ and\nmay reflect poorly on their broader research skills. This presentation\ncontains some brief reflections from research, consulting, and teaching\nexperiences that have led to overcoming my own barriers to sharing code\nand to help others do the same.\n\nNancy Reid\nBio: Nancy Reid is Professor of Statistical Sciences at the\nUniversity of Toronto and Canada Research Chair in Statistical Theory\nand Applications. Her main area of research is theoretical statistics.\nThis treats the foundations and properties of methods of statistical\ninference. She is interested in how best to use information in the data\nto construct inferential statements about quantities of interest. A very\nsimple example of this is the widely quoted ‘margin of error’ in the\nreporting of polls, another is the ubiquitous ‘p-value’ reported in\nmedical and health studies. Much of her research considers how to ensure\nthat these inferential statements are both accurate and effective at\nsummarizing complex sets of data.\nAbstract: Are p-values contributing to a crisis in replicability and\nreproducibility? This has been the topic of many dialogues, diatribes,\nand discussions among statisticians and scientists in recent years. I\nwill share my thoughts on the issues, with emphasis on the role of\ninferential theory in helping to clarify the arguments.\n\nNick\nRadcliffe\nBio: Nick Radcliffe is the founder of the data science consulting\nand software firm, Stochastic Solutions Limited, the Interim Chief\nScientist at the Global Open Finance Centre of Excellence, and a\nVisiting Professor in Maths and Stats at University of Edinburgh,\nScotland. His background combines theoretical physics, operations\nresearch, machine learning and stochastic optimization. Nick’s current\nresearch interests include a focus on test-driven data analysis, (an\napproach to improving correctness of analytical results that combines\nideas from reproducible research and test-driven development) and\nprivacy-respecting analysis. He is the lead author of the open-source\nPython tdda package, which provides practical tools for testing\nanalytical software and data, and also of the Miró data analysis\nsuite.\nAbstract: The Global Open Finance Centre of Excellence is currently\nengaged in analysis of the financial impact of COVID-19 on the citizens\nand businesses of the UK. This research uses non-consented but\nde-identified financial data on individuals and businesses, on the basis\nof legitimate interest. All analysis is carried out in a highly\nlocked-down analytical environment known as a Safe Haven. This talk will\nexplain our approach to the challenges of ensuring the correctness and\nrobustness of results in an environment where neither code nor input\ndata can be opened up for review and even outputs need to be subject to\ndisclosure control to reduce further any risks to privacy. Topics will\ninclude: testing input data for conformance and lack of personal\nidentifiers using constraints; multiple implementations and verification\nof equivalence of results; regression tests and reference tests;\nverification of output artefacts; verification of output disclosure\ncontrols; data provenance and audit trails; test-driven data\nanalysis—the underlying philosophy (and library) that we use to underpin\nthis work.\n\nNicolas\nDidier\nBio: Nicolas Didier is studying for a PhD in Public Administration\nand Policy at the Arizona State University. During his PhD studies and\nprevious studies, he has worked extensively on developing evidence that\naddresses policy in labour markets and public expenditure.\nAbstract: Please see Mauricio Vargas Sepúlveda.\n\nRyan Briggs\nBio: Ryan Briggs is a social scientist who studies the political\neconomy of poverty alleviation. Most of his research focuses on the\nspatial targeting of foreign aid. He is an Assistant Professor in the\nGuelph Institute of Development Studies and Department of Political\nScience at the University of Guelph. Before that, he taught at Virginia\nTech and American University.\nAbstract: It is hard to do research. One reason for this is that it\nhas a production function where one low quality input (among many high\nquality inputs) can poison a final result. This talk explains how such\n‘o-ring’ production functions work and draws out lessons for applied\nresearchers.\n\nSharla Gelfand\nBio: Sharla Gelfand is a freelance R and Shiny developer\nspecializing in enabling easy access to data and replacing manual,\nredundant processes with ones that are automated, reproducible, and\nrepeatable. They also co-organize R-Ladies Toronto and the Greater\nToronto Area R User Group. They like R (of course), dogs, learning\nSpanish, playing bass, and punk.\nAbstract: Getting stuck, looking around for a solution, and\neventually asking for help is an inevitable and constant aspect of being\na programmer. If you’ve ever looked up a question only to find some\nbrave soul getting torn apart on Stack Overflow for not providing a\nminimum working example, you know it’s also one of the most intimidating\nparts! A minimum working example, or a reproducible example as it’s more\noften called in the R world, is one of the best ways to get help with\nyour code - but what exactly is a reproducible example? How do you\ncreate one, and do it efficiently? Why is it so scary? This talk will\ncover what components are needed to make a good reproducible example to\nmaximize your ability to get help (and to help yourself!), strategies\nfor coming up with an example and testing its reproducibility, and why\nyou should care about making one. We will also discuss how to extend the\nconcept of reproducible examples beyond “Help! my code doesn’t work” to\nother environments where you might want to share code, like teaching and\nblogging.\n\nShemra Rizzo\nBio: Shemra Rizzo is a senior data scientist in Genentech’s\nPersonalized Healthcare group. Shemra’s role includes research on\nCOVID-19 using electronic health records, and the development of\ndata-driven approaches to evaluate clinical trial eligibility criteria.\nShemra obtained her PhD in Biostatistics from UCLA. Before joining\nGenentech, Shemra was an assistant professor of statistics at UC\nRiverside, where her research covered topics in mental health, health\ndisparities, and nutrition. In her free time, Shemra enjoys spending\ntime with her family and running.\nAbstract: Real world data for an emerging disease has unique\nchallenges. In this talk, I’ll describe how our group made sense of\ncomplex Electronic Health Records (EHR) data for COVID19 early in the\npandemic. I will share our experience working towards reliable,\nreplicable and reproducible studies using EHR licensed data.\n\nShiro Kuriwaki\nBio: Shiro Kuriwaki is a PhD Candidate in the Department of\nGovernment at Harvard University. His research focuses on democratic\nrepresentation in American Politics. In an ongoing project, he studies\nthe structure of voter’s choices across levels of government and the\npolitical economy of local elections, using cast vote records and\nsurveys. His other projects also help understand the mechanics of\nrepresentation, including: public opinion and Congress, modern survey\nstatistics and causal inference, and election administration. Prior to\nand during graduate school, he worked at the Analyst Institute in\nWashington D.C.\nAbstract: I show how new features of the dataverse R\npackage facilitate reproducibility in empirical, substantive projects.\nWhile packages and scripts make our code transparent and portable across\nforms, the import of large and complex datasets is often a nuisance in\nproject workflows that involve various data cleaning and wrangling\ntasks. And the GUI for Dataverse can be sometimes tedious to integrate\ninto code-based workflow. Will Beasley and I, along with multiple other\ncontributors, updated the dataverse R package for the first time since\n2017 with the goal of spreading its use in empirical workflow. In this\niteration, we make it easier to retrieve dataframes of various file\nformat and options for version specification and variable subsetting. I\nalso discuss the latest updates to pyDataverse, a independent\nimplementation in Python which is currently more advanced in its\nimplementation but focused on uploading and creating datasets to\ndataverse.\n\nSimeon Carstens\nBio: Simeon Carstens is a Data Scientist at Tweag I/O, a software\ninnovation lab and consulting company. Originally a physicist, Simeon\ndid a PhD and postdoc research in computational biology, focusing on\nBayesian determination of three-dimensional chromosome structures.\nAbstract: Data analysis often requires a complex software\nenvironment containing one or several programming languages,\nlanguage-specific modules and external dependencies, all in compatible\nversions. This poses a challenge to reproducibility: what good is a\nwell-designed, tested and documented data analysis pipeline if it is\ndifficult to replicate the software environment required to run it?\nStandard tools such as Python / R virtual environments solve part of the\nproblem, but do not take into account external and system-level\ndependencies. Nix is a fully declarative, open-source package manager\nsolving this problem: a program packaged with Nix comes with a complete\ndescription of its full dependency tree, down to system libraries. In\nthis presentation, I will give an introduction to Nix, show in a live\ndemo how to set up a fully reproducible software environment and compare\nNix to existing solutions such as virtual environments and Docker.\n\nTiffany Timbers\nBio: Tiffany Timbers is an Assistant Professor of Teaching in the\nDepartment of Statistics and an Co-Director for the Master of Data\nScience program (Vancouver Option) at the University of British\nColumbia. In these roles she teaches and develops curriculum around the\nresponsible application of Data Science to solve real-world problems.\nOne of her favourite courses she teaches is a graduate course on\ncollaborative software development, which focuses on teaching how to\ncreate R and Python packages using modern tools and workflows.\nAbstract: In the data science courses at UBC, we define data science\nas the study and development of reproducible and auditable processes to\nobtain value (i.e., insight) from data. While reproducibility is core to\nour definition, most data science learners enter the field with other\naspects of data science in mind, such as predictive modelling. This\nfact, along with the highly technical nature of the industry standard\nreproducibility tools currently employed in data science, present\nout-of-the gate challenges in teaching reproducibility in the data\nscience classroom. Put simply, students are not as intrinsically\nmotivated to learn this topic, and it is not an easy one for them to\nlearn. What can a data science educator do? Over several iterations of\nteaching courses focused on reproducible data science tools and\nworkflows, we have found that motivation, direct instruction and\npractice are key to effectively teach this challenging, yet important\nsubject. In this talk, I will present examples of how we deeply\nmotivate, effectively instruct and provide ample practice opportunities\nto our Master of Data Science students to effectively engage them in\nlearning about this topic.\n\nTom Barton\nBio: Tom Barton is a PhD student in Politics at Royal Holloway,\nUniversity of London. His PhD focuses on the impact of Voter\nIdentification laws on political participation and attitudes. More\ngenerally his interests include elections, public opinion (particularly\nsocial values) and quantitative research methods.\nAbstract: I reproduce Surridge, 2016, ‘Education and liberalism:\npursuing the link’, Oxford Review of Education, 42:2,\npp. 146-164, using the 1970 British Cohort Study (BCS70), instead using\na difference-in-difference regression approach with more waves of data.\nI find that whilst there is evidence for both socialisation and\nself-selection models, self-selection dominates the link between social\nvalues and university attendance. This is counter to what Surridge\n(2016) concluded. The need for re-specification was two-fold, first\nSurridge’s methodology did not fully test for causality and secondly\nlater waves have data have become available since.\n\nTyler Girard\nBio: Tyler Girard is a PhD Candidate in political science at the\nUniversity of Western Ontario (London, Ontario, Canada). His\ndissertation research seeks to explain the origins and diffusion of the\nglobal financial inclusion agenda by focusing on the role of ambiguous\nideas in mobilizing and consolidating transnational coalitions. More\ngenerally, his work also explores new approaches to conceptual\nmeasurement in international relations.\nAbstract: In what ways can we incorporate reproducible practices in\npedagogy for social science courses? I discuss how individual and group\nexercises centered around the replication of existing datasets and\nanalyses offer a flexible tool for experiential learning. However,\nmaximizing the benefits of such an approach requires customizing the\nactivity to the students and the availability of instructor support. I\noffer several suggestions for effectively using replication exercises in\nboth undergraduate and graduate level courses.\n\nWijdan Tariq\nBio: Wijdan Tariq is an undergraduate student in the Department of\nStatistical Sciences at the University of Toronto.\nAbstract: I undertake a narrow replication of Caicedo, 2019, ‘The\nMission: Human Capital Transmission, Economic Persistence, and Culture\nin South America’, Quarterly Journal of Economics, 134:1,\npp. 507-556. Caicedo reports of a remarkable, religiously inspired human\ncapital intervention that took place in remote parts of South America\n250 years ago and whose positive economic effects, he claims, persist to\nthis day. I replicate some of the paper’s key results using data files\nthat are available on the Harvard Dataverse portal. I discuss some\nlessons learned in the process of replicating this paper and share some\nreflections on the state of reproducibility in economics.\n\nYanbo\nTang\nBio: Yanbo Tang is a PhD candidate at the University of Toronto in\nthe Department of Statistical Sciences, under the joint supervision of\nNancy Reid and Daniel Roy. He is interested in the study and application\nof methods in higher order asymptotics and statistical inference in the\npresence of many nuisance parameters. Nowadays, he works under the\ncareful gaze of his pet parrot.\nAbstract: Hypothesis testing results often rely on simple, yet\nimportant assumptions about the behavior of the distribution of p-values\nunder the null and alternative. We show that commonly held beliefs\nregarding the distribution of p-values are misleading when the variance\nor location of the test statistic are not well-calibrated or when the\nhigher order cumulants of the test statistic are not negligible. We\nfurther examine the impact of having these misleading p-values on\nreproducibility of scientific studies, with some examples focused on\nGWAS studies. Certain corrected tests are proposed and are shown to\nperform better than their traditional counterparts in certain\nsettings.\n\nCode of conduct\nCode\nThe organizers of the Toronto Workshop on Reproducibility are\ndedicated to providing a harassment-free experience for everyone\nregardless of age, gender, sexual orientation, disability, physical\nappearance, race, or religion (or lack thereof).\nAll participants (including attendees, speakers, sponsors and\nvolunteers) at the Toronto Workshop on Reproducibility are required to\nagree to the following code of conduct.\nThe code of conduct applies to all conference activities including\ntalks, panels, workshops, and social events. It extends to\nconference-specific exchanges on social media, for instance posts tagged\nwith the identifier of the conference (e.g. #TOrepro on Twitter), and\nreplies to such posts.\nOrganizers will enforce this code throughout and expect cooperation\nin ensuring a safe environment for all.\nExpected Behaviour\nAll conference participants agree to:\nBe considerate in language and actions, and respect the boundaries\nof fellow participants.\nRefrain from demeaning, discriminatory, or harassing behaviour and\nlanguage. Please refer to ‘Unacceptable Behaviour’ for more\ndetails.\nAlert Rohan Alexander - rohan.alexander@utoronto.ca - or Kelly Lyons - kelly.lyons@utoronto.ca - if you notice someone in\ndistress, or observe violations of this code of conduct, even if they\nseem inconsequential. Please refer to the section titled ‘What To Do If\nYou Witness or Are Subject To Unacceptable Behaviour’ for more\ndetails.\nUnacceptable Behaviour\nBehaviour that is unacceptable includes, but is not limited to:\nStalking\nDeliberate intimidation\nUnwanted photography or recording\nSustained or willful disruption of talks or other events\nUse of sexual or discriminatory imagery, comments, or jokes\nOffensive comments related to age, gender, sexual orientation,\ndisability, race or religion\nInappropriate physical contact, which can include grabbing, or\nmassaging or hugging without consent.\nUnwelcome sexual attention, which can include inappropriate\nquestions of a sexual nature, asking for sexual favours or repeatedly\nasking for dates or contact information.\nIf you are asked to stop harassing behaviour you should stop\nimmediately, even if your behaviour was meant to be friendly or a joke,\nit was clearly not taken that way and for the comfort of all conference\nattendees you should stop.\nAttendees who behave in a manner deemed inappropriate are subject to\nactions listed under ‘Procedure for Code of Conduct Violations’.\nAdditional Requirements for Conference\nContributions\nPresentation slides and posters should not contain offensive or\nsexualised material. If this material is impossible to avoid given the\ntopic (for example text mining of material from hate sites) the\nexistence of this material should be noted in the abstract and, in the\ncase of oral contributions, at the start of the talk or session.\nProcedure for Code of Conduct Violations\nThe organizing committee reserves the right to determine the\nappropriate response for all code of conduct violations. Potential\nresponses include:\na formal warning to stop harassing behaviour\nexpulsion from the conference\ncancellation or early termination of talks or other contributions to\nthe program\nWhat To Do If You Witness or Are Subject To Unacceptable\nBehaviour\nIf you are being harassed, notice that someone else is being\nharassed, or have any other concerns relating to harassment, please\ncontact Rohan Alexander - rohan.alexander@utoronto.ca, or Kelly Lyons - kelly.lyons@utoronto.ca.\nWe will take all good-faith reports of harassment by Toronto Workshop\non Reproducibility participants seriously.\nWe reserve the right to reject any report we believe to have been\nmade in bad faith. This includes reports intended to silence legitimate\ncriticism.\nWe will respect confidentiality requests for the purpose of\nprotecting victims of abuse. We will not name harassment victims without\ntheir affirmative consent.\nQuestions or concerns about the Code of Conduct can be addressed to\nrohan.alexander@utoronto.ca.\nAcknowledgements\nParts of the above text are licensed CC BY-SA 4.0. Credit to SRCCON.\nThis code of conduct was based on that developed for useR! 2018 which\nwas a revision of the code of conduct used at previous useR!s and also\ndrew from rOpenSci’s code of conduct.\n\n\n\n\n\n\n",
      "last_modified": "2022-05-02T13:00:34-04:00"
    },
    {
      "path": "sta304.html",
      "title": "Surveys, Sampling, and Observational Data",
      "description": "STA304 is an upper-level undergraduate course at the University of Toronto's Department of Statistical Sciences.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nHow to succeed\nHow we’ll work\nAdvice from past\nstudents\nAcknowledgements\nSyllabus\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nSummary\nQuiz\nTutorial\nPaper #1\nPaper #2\nPaper #3\nPaper #4\nFinal Paper\n\nOther\nLearning objectives\nCommunication\nAccommodations\nwith regard to assessment\nMinimum submission\nrequirement\nRe-grading\nPlagiarism and\nintegrity\nLate policy\nWriting\nAccessibility needs\nIntellectual Property\nStatement\n\n\nPreamble\n\n\nOverview\n\nThe best thing about being a statistician, is that you get to play in\neveryone’s backyard.\nJohn Tukey\n\nThe work of applied statisticians, regardless of their specific job\ntitle and area of application, is the most important and exciting work\nin the world right now. The ability to gather data, analyse it, and\ncommunicate your understanding of the underlying process is incredibly\nvaluable. In this course you will learn and apply the essentials of\nthis.\nWe focus on surveys, sampling and observational data. The very stuff\nof statistical science! We will approach these topics from a practical\nperspective. You will actually run surveys and learn how messy it is to\nput one together. You will learn how to think about sampling, how to\nimplement it, and why the details matter. You will forecast an election.\nAnd you will conduct original research. More generally, you will learn\nhow to obtain and analyse data and use it to make sensible claims about\nthe world.\nTo work as an applied statistician requires you to be able to, as\npart of a small team:\nGather data in less-than-perfect settings.\nEfficiently prepare and clean data toward some purpose.\nAnalyse it in a reproducible, thorough, modern, and\nstatistically-mature manner.\nCommunicate your analysis to stakeholders including colleagues and\nclients with and without formal statistical training.\nYou likely have some of these skills already. This course will\nfurther develop them. At the end of the course you will have a portfolio\nof work focused on surveying, sampling, and observational data, that you\ncould show off to a potential employer.\nEach week you will read relevant papers and books, engage with them\nthrough discussion with each other, myself, and the TA. You will bring\nthis all together and show off how much you have learnt through\npractical, on-going, assessment.\nIt is important to recognise that putting together everything that\nyou have learnt to this point in this way will be difficult. It is not\npossible to cover everything that you will need to know. You should\nproactively identify and address aspects where you are weak through\nseeking additional information and resources. This course acts as a\nguide as to what is important, it does not contain everything that is\nimportant.\nThis course is different to many other courses at the University of\nToronto. At the end of this course, you will have a portfolio of work\nthat you could show off to a potential employer. You will have developed\nthe skills to work successfully as an applied statistician or data\nscientist. And you will know how to fill gaps in your knowledge\nyourself. A lot of scholarships and jobs these days ask for GitHub and\nblog links etc to show off a portfolio of your work. This is the class\nthat gives you a chance to develop these. It’s very important to having\nsomething to show that needs to go beyond what is done in a normal\nclass.\nHow to succeed\nIn this course you will work in a self-directed, open-ended manner.\nIdentify relevant areas of interest and then learn the skills that you\nneed to explore those areas.\nTo successfully complete this course, you should expect to spend a\nlarge portion of your time reading and writing (both code and text).\nDeeply engage with the materials. Find a small study group and keep each\nother motivated and focused. At the start of the week, read the course\nnotes, all compulsory materials and some recommended materials based on\nyour interest. After doing that, but before the ‘lecture’ time you\nshould complete the weekly quiz. During ‘lectures’ I’ll live-code,\ndiscuss materials in the course notes, talk about an experiment, and\nyou’ll have a chance to discuss the materials with me.\nYou need to be more active in your learning in this course than\nothers - read the notes and related materials - and then go out there\nand teach yourself more and apply it. You will not be spoon-fed in this\ncourse. Each week try to write reproducible, understandable, R code\nsurrounded by beautifully crafted text that motivates, backgrounds,\nexplains, discusses, and criticizes. Make steady progress toward the\nassessment.\nThis is not a ‘bird course’. Typically, after the term is finished,\nstudents say that the course is difficult but rewarding. The TAs and I\nare always available to answer any questions. Please come to office\nhours!\nHow we’ll work\nThis webpage will provide almost all the guiding materials that you\nneed and links to the relevant parts of the notes. The course notes are\navailable here: https://www.tellingstorieswithdata.com. Those contain\nnotes and other material that you could go over. We’ll use Quercus\nreally only for assessment submission and grading.\nA rough weekly flow for the course would be something like:\nRead the week’s course notes.\nRead/watch/listen to the required materials.\nAttend the lecture.\nAttend the lab.\nComplete the weekly quiz.\nMake progress on a paper.\nAdvice from past students\nSuccessful past students have the following advice (completely\nunedited by me):\n“Start reading and writing on a weekly basis, watch some videos on R\nand RMD but more importantly learn how to use Google.”\n“It is not a wise idea to take this course if you did not take any\nother STA 300 level course before.”\n“Start early, find a group of people you trust enough to divide the\nwork up fairly. Let people work to their strengths (people who know R\nshould do the modelling, good writers should write most of the reports,\netc.)”\n“Not to worry if you don’t do well on the first problem set—the\nnature of the course is to build up skills overtime, and it’s meant to\nbe challenging in the beginning. In the end, it is worth it because you\nlearn very valuable applicable skills on how to write professional\nreports.”\n“Work on your writing and direction following skills.”\n“Look at the rubric. There were times that I lost marks because I\ndidn’t follow the rubric properly. Go to office hours, they are very\nuseful as you can ask your own question and also get answers to\nquestions other people ask and you didn’t think of. Also, do the\nassignments to the best of your ability. You will lose marks if you\ndon’t put in effort and the only person you’re hurting is\nyourself.”\n“During lectures, focus more on the why the prof is doing what he’s\ndoing. When he runs certain commands in R, figure out why that sequence\nof code gives what you want, because it’ll help adapt his code into your\nassignment code. just remembering what he’s doing in lecture becomes\nuseless really quickly since the thought process matters more. also,\nstart everything early.”\n“Do this course when you really want to learn something and have a\nlot of time to working on it.”\n“you need to be very skillful in RStudio and latex. Otherwise you\nwould be struggling.”\n“Try to incorporate the feedback given and read a looottttttttt.\nAlso start early on the problem sets because they tend to take a lot of\ntime. Don’t give up!”\n“-Find a good group for problem sets”\n“If the assignments stay the same, I would tell students to approach\nthis class from the perspective of ‘storytelling with statistics’ rather\nthan a statistics course. You need to use R, and Markdown, and have a\nsolid understanding of concepts like regression and sampling, but more\nimportantly you need to be able to interpret results and write about\nthem in a way coherent and professional way.”\n“do your readings”\n“Definitely get ready to write reports”\n“Do not take sta304 with Prof Rohan, it is pretty tough”\n“Start your work a bit earlier, make sure to follow the format\nexpected and the rubric exactly.”\n“Read course material. Figure out WHY this paper/video is being\nshown to you and what you generally learn from it. Surround yourself\nwith people dedicated to putting in the effort to understand material\nand who are thorough in their work so you can discuss content and/or\nwork together.”\n“1. Be prepared to work extremely hard (8-11 hours a week). 2. Learn\nRStudio before course begins–STA130 is ideal preparation. 3. Start\nproblem sets as soon as they are released.”\n“learn to code early and extensively use the office hours with the\nprof.”\n“This course requires lots of time dedicated and is not an”easy bird\ncourse” but is an incredibly rewarding course if one wants to learn how\nstatistics is applied in the real world.”\nAcknowledgements\nThank you to the following people for generously providing comments,\nreferences, suggestions, and thoughts that directly contributed to this\noutline: Bethany White, Dan Simpson, Jesse Gronsbell, Kelly Lyons,\nLauren Kennedy, Monica Alexander and Uzair Mirza. Thank you especially\nto Samantha-Jo Caetano who influenced all aspects of this and co-taught\nthe first version in Fall 2020.\nSyllabus\n2020.\n2022.\nContent\n(Exact coverage will change based on how the class progresses.)\nWeek 1\nContent:\nIntroduction\nSeveral\nend-to-end worked examples\n\nWeek 2\nContent:\nR\nessentials\nReproducible\nworkflows\n\nWeek 3\n‘Communicating’.\nContent:\nWriting\nStatic\ncommunication\n\nWeek 4\n‘Interactive communication’.\nContent:\nHow to make a website and use Shiny.\n\nWeek 5\n‘Gathering data’.\nContent:\nSampling, using APIs, scraping, OCR, semi-structured datasets, and\ntext.\n\nWeek 6\n‘Hunting data’.\nContent:\nExperiments, sampling and surveys, and A/B testing.\nDesign of surveys, sources of bias, randomized response\nsurveys.\n\nWeek 7\n‘Cleaning and preparing data’.\nGuest lecture: Chris Henry, Bank of Canada\nChristopher Henry (Chris) is a Senior Economist at the Bank of\nCanada. He serves as lead economist for the consumer survey research\nprogram on the Currency Department’s Economic Research and Analysis\nteam. Chris first joined the Bank as a Research Assistant in 2012, and\nrecently rejoined in 2021 after completing his PhD in Economics. In his\nrole, Chris contributes to the design, implementation, and analysis of a\nrange of surveys that measure the use of cash and alternative methods of\npayment. He holds an PhD in Economics from Université Clermont Auvergne\n(France), and an MSc in Mathematics from McMaster University.\n\nContent:\nWorkflow for cleaning data.\nEffective naming, checks, and testing.\n\nWeek 8\n‘Lost due to sickness’\nContent:\nBrief overview of GSS data.\n\nWeek 9\n‘Storing and retrieving data’ and ‘disseminating and protecting\ndata’.\nContent:\nR packages for data, and documentation including datasheets.\nPersonally identifying information, hashing and salting, GDPR and\nHIPPA, simulated data, and differential privacy.\n\nWeek 10\n‘Multilevel regression with post-stratification’\nContent:\nMRP\n\nWeek 11\n‘IJALM - It’s Just A Linear Model’.\nContent:\nOverview\n\nGuest lecture: Sue Ince\nSue Ince has many years experience in research and forecasting in\nNorth America and the U.K., with a statistics background and very strong\nquantitative and research design skills. Sue was the principal and\nco-founder of Epic Consulting and directed large-scale projects for\nmajor corporations and small and medium enterprises. Sue specialized in\nsegmentation, multivariate analysis and data mining integrating primary\nand secondary research with client’s internal sales and marketing data.\nHer career spans from the age of slide rules, log tables and graph paper\nto digital computing. In every age and whatever the analytical tools\navailable it is critical to be able to communicate the meaning of data\nto an audience who often have poor statistical literacy. Good data\nstorytelling is a very important skill for statisticians. Sue holds an\nB.Sc. Social Sciences; Combined Honours: Economics & Politics,\nStatistics, University of Southampton, England and was active\nprofessional member of Canada’s Market Research community before her\nretirement. Sue presented papers at research conferences in Canada and\nin Europe, lectured on Quantitative Methods in the Federated Press\nMarket Courses and guest lectured at George Brown and Seneca Colleges on\nmarket research.\n\nRecording: https://youtu.be/aDBY7-F_8D0\nWeek 12\n\n\n\n\nAssessment\nSummary\nItem\nWeight (%)\nDue date\nQuiz\n20\nWeekly before the lecture\nTutorial\n20\nWeekly the day before the tutorial\nPaper 1\n25\nEnd of Week 3\nPaper 2\n25\nEnd of Week 6\nPaper 3\n25\nEnd of Week 8\nPaper 4\n25\nEnd of Week 10\nFinal Paper (initial submission)\n1\nMiddle of Week 12\nFinal Paper (peer review)\n4\nEnd of Week 12\nFinal Paper\n25\nTwo weeks after that\nYou must submit Paper 1. And you must submit the Final Paper.\nBeyond that, you have scope to pick an assessment schedule that works\nfor you. We will take your best 3 of the 11 tutorials, or your best 8 of\n11 quizzes for that 20 per cent—whichever results in a better grade for\nyou (i.e. you can choose to do either quizzes or tutorials). And we will\ntake your two best papers from Papers 1-4 for that 50 per cent (25 per\ncent for each). The remainder is made up of 1 per cent for submitting a\ndraft of the Final Paper, 4 per cent for peer reviewing other people’s\ndrafts of the Final Paper, and 25 per cent for the Final Paper.\nAdditional details:\nQuiz questions are drawn from those in the Quiz section that follows\neach chapter of Telling Stories with Data. Almost all of them\nare multiple choice, and you should expect to know the mark within two\ndays of submission.\nTutorial questions are drawn from those in the Tutorial section that\nfollows each chapter of Telling Stories with Data. The general\nexpectation (although this differs from week to week) is about two pages\nof written content, which the tutor will read, discuss with you, and\nthen provide a mark. You should expect to know the mark within three\ndays of the tutorial.\nIn general papers require a considerable amount of work, and are due\nafter the material has been covered in quizzes and tutorials (i.e. you\nwould draw on knowledge tested in the quizzes, and potentially material\ncould be re-used from the tutorial material). In general, they require\noriginal work to some extent. Papers are taken from the Papers appendix\nof Telling Stories with Data and students have access to the\ngrading rubrics before submission.\nQuiz\nYou should choose to do either tutorials or quizzes.\nDue date: Weekly before the lecture.\nWeight: 20 per cent. Only best eight out of eleven count and only if\nthat is better for you than counting tutorials.\nTask: Please complete a weekly quiz in Quercus.\nTutorial\nYou should choose to do either tutorials or quizzes.\nDue date: Weekly the day before the tutorial.\nWeight: 20 per cent. Only best three out of eleven count and only if\nthat is better for you than counting quizzes.\nTask: Please complete a tutorial question and submit it via\nQuercus.\nRubric:\n0 - Any typos, major grammatical errors, other table stakes issues\nfor this level.\n0.25 - Grammatical errors, if relevant: tables/graphs not properly\nlabeled, no references, other aspects that affect credibility. Too\nshort.\n0.6 - Makes some interesting and relevant points, related to course\nmaterial (including required materials), but lacking in terms of\nstructure and story/argument.\n0.80 - Interesting paper that is well-structured, coherent, and\ncredible.\n1 - As with 0.80, but exceptional in some way.\n\nPaper #1\nYou must submit this paper.\nTask: ‘Mandatory Minimums’ (details will be added to Quercus).\nDue date: End of Week 3.\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncount).\nPaper #2\nDue date: End of Week 6.\nTask: ‘The Short List’ (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #3\nDue date: End of Week 8.\nTask: TBA (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nPaper #4\nDue date: End of Week 10.\nTask: TBA (details will be added to Quercus).\nWeight: 25 per cent (for Papers #1-#4 the best two of four\ncounts).\nFinal Paper\nTask: TBA (details will be added to Quercus).\nYou must submit this paper.\nDue dates:\nInitial submission: Middle of Week 12.\nPeer review: End of Week 12.\nFinal Paper: Two weeks after that.\n\nWeight: 30 per cent\nInitial submission: 1 per cent\nPeer review: 4 per cent\nFinal Paper: 25 per cent\n\nOther\nLearning objectives\nDesign a survey or sample that appropriately gathers information of\ninterest.\nCarry out a variety of statistical analyses in R to make inference\non the data collected from a survey/sample.\nIdentify and implement different sampling techniques and different\nstudy designs and the trade-offs involved in each.\nIdentify sources of bias within a study and comment on a study’s\ndesign, including weaknesses, strengths, and appropriate analyses.\nClearly communicate results of statistical analyses to technical and\nnon-technical audiences.\nCommunication\nIf you have a question, there is a decent chance that others have the\nsame question or, at least, will benefit from the answer. Please post\nall questions to Piazza so that everyone in the course can benefit from\nyour questions and our answers. You are encouraged to post answers to\nthe questions of other students, where appropriate. Of course, if you\nhave a concern of a personal nature then please email the TAs or me and\nyou should begin your subject line with the course code ‘STA304’, and\nthen an appropriate subject.\nEmails and the message board are not checked or responded to by\neither the TA or me after hours or on the weekend.\nPlease be polite. We continue to be in a pandemic.\nAccommodations with\nregard to assessment\nYou do not need to reveal your personal or medical\ninformation to me. I understand that illness or personal emergencies can\nhappen from time to time. The following accommodations to assessment\nrequirements exist to provide for those situations.\nStraight-forward (will automatically apply to all students - there’s\nno need to ask for these):\nQuiz: Worst three quizzes are dropped.\nTutorial: Worst eight tutorials are dropped.\nPapers #1-#4: Worst two are dropped.\nSo for those (with the exception of Paper #1), if you have a\nsituation, then just don’t submit.\nSlightly more involved:\nPaper #1: I’m open to a day without penalty to account for\nsituations. Beyond that it begins to slow down the class. You must\nsubmit something for Paper #1.\nPeer review: No accommodation or late submission is possible for\nthis because it would hold up the rest of the class. If you cannot\nsubmit then email me before the deadline and the weight will be shifted\nto the final paper.\nFinal paper: The final paper is a critical piece of assessment. It’s\nalso up against deadlines for submission of grades. Extensions for valid\nreasons may be granted for a maximum of three days, however this isn’t\npossible for all students (i.e. there may be restrictions around\ngraduating students). Hence, the exact extension needs to be at my\ndiscretion. To be considered, an extension request must be sent to rohan.alexander@utoronto.ca by the business day before\nthe due date so there is time to get advice from the Department and your\ncollege about your particular circumstance.\nMinimum submission\nrequirement\nIf you are going to not be able to submit at least two problem sets,\nand/or be unable to submit the final paper then it would be unfair on\nthe other students to allow you to pass the course. Please ensure you\nand your registrar get in touch with me as early as possible if this may\nbe the case for you.\nRe-grading\nRequests to have your work re-graded will not be accepted within 24\nhours of the release of grades. This is to give you a chance to reflect.\nSimilarly, requests to have your work re-graded more than seven days\nafter the release of the grades will not be accepted. This is to ensure\nthe course runs smoothly.\nInside that 1-7 day period if you would like to request a re-grade,\nplease email rohan.alexander@utoronto.ca with a subject line that\nstarts with ‘STA304’. You must specify where the marking error was made\nin relation to the marking guide. Your entire assessment will be\nre-marked and it is possible that your grade could reduce.\nPlagiarism and integrity\nPlease do not plagiarize. In particular, be careful to acknowledge\nthe source of code - if it’s extensive then through proper citation and\nif it’s just a couple of lines from Stack Overflow then in a comment\nimmediately next to the code.\nYou are responsible for knowing the content of the University of\nToronto’s Code of Behaviour on Academic Matters.\nAcademic offenses include (but are not limited to) plagiarism,\ncheating, copying R code, communication/extra resources during closed\nbook assessments, purchasing labour for assessments (of any kind).\nAcademic offenses will be taken seriously and dealt with accordingly. If\nyou have any questions about what is or is not permitted in this course,\nplease contact me.\nPlease consult the University’s site on Academic Integrity http://academicintegrity.utoronto.ca/. Please also see\nthe definition of plagiarism in section B.I.1.(d) of the University’s\nCode of Behaviour on Academic Matters http://www.governingcouncil.utoronto.ca/Assets/Governing+Council+Digital+Assets/Policies/PDF/ppjun011995.pdf.\nPlease read the Code. Please review Cite it Right and if you require\nfurther clarification, consult the site How Not to Plagiarize http://advice.writing.utoronto.ca/wp-content/uploads/sites/2/how-not-to-plagiarize.pdf.\nLate policy\nYou are expected to manage your time effectively. If no extension has\nbeen granted and no accommodation applies, then the late submission of\nan assessment item carries a penalty of 10 percentage points per day to\na maximum of one week after which it will no longer be accepted, e.g. a\nproblem set submitted a day late that would have otherwise received 8/10\nwill receive 7/10, if that same problem set was submitted two days late\nthen it would receive 6/10.\nWriting\nPapers and reports should be well-written, well-organized, and easy\nto follow. They should flow easily from one point to the next. They\nshould have proper sentence structure, spelling, vocabulary, and\ngrammar. Each point should be articulated clearly and completely without\nbeing overly verbose. Papers should demonstrate your understanding of\nthe topics you are studying in the course and your confidence in using\nthe terms, techniques, and issues you have learned. As always,\nreferences must be properly included and cited. If you have concerns\nabout your ability to do any of this then please make use of the writing\nsupport provided to the faculty, colleges and the SGS Graduate Centre\nfor Academic Communication.\nAccessibility needs\nStudents with diverse learning styles and needs are welcome in this\ncourse. In particular, if you have a disability/health consideration\nthat may require accommodations, please feel free to approach me and/or\nAccessibility Services at 416 978 8060 or visit\nstudentlife.utoronto.ca/as.\nIntellectual Property\nStatement\nCourse material that has been created by your instructor is the\nintellectual property of your instructor and is made available to you\nfor your personal use in this course. Sharing, posting, selling, or\nusing this material outside of your personal use in this course is not\npermitted under any circumstances and is considered an infringement of\nintellectual property rights.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:35-04:00"
    },
    {
      "path": "teaching.html",
      "title": "Teaching",
      "description": "My teaching is informed not only by my time in academia, but also by my experience working at my own start-up and in government. My approach is best characterised as practical, research-based, and emphasising workflow. I am an [RStudio Certified Tidyverse Trainer](https://education.rstudio.com/trainers) and I enjoy teaching students from a wide range of backgrounds. I co-lead the development of a package to help students learn R, available here: [DoSS Toolkit](https://www.dosstoolkit.com). My book, *[Telling Stories with Data](https://www.tellingstorieswithdata.com/)* supports my teaching.\n",
      "author": [],
      "contents": "\n\nContents\nCourse material\nTeaching experience\n\nCourse material\nI have designed and taught the following courses:\nWorlds Become Data\nSurveys, Sampling and Observational\nData\nExperimental Design\nEthics and Data\nScience\nNatural Language\nProcessing\nFoundations of Data\nSciences\nThe Other Course\nHistory of Statistics\nand Data Sciences\nTeaching experience\nUniversity of Toronto\nInstructor, ‘STA304: Surveys, Sampling and Observational Data’,\nDepartment of Statistical Sciences, Winter 2022.\nInstructor, ‘INF312: Worlds Become Data’, Winter 2022.\nInstructor, ‘INF2178: Experimental Design for Data Science’, Faculty\nof Information, Winter 2021\nInstructor, ‘STA304: Surveys, Sampling and Observational Data’,\nDepartment of Statistical Sciences, Fall 2020, evaluations\nInstructor, ‘INF2178: Experimental Design for Data Science’, Faculty\nof Information, Winter 2020, evaluations\nAustralian National\nUniversity\nTutor, Macroeconomics 3, Semester 2, 2017, evaluations\nTutor, Microeconomics 3, Semester 1, 2017, evaluations\nTutor, Behavioural Economics, Semester 2, 2015, evaluations\nTutor, Business Economics, Semester 1, 2015, evaluations\nTutor, Microeconomics 1, Semester 1, 2013, evaluations\nTutor, Foundations of Economic and Financial Models, Semester 2,\n2012\nUniversity of Queensland\nTutor, Microeconomic Policy, Semester 2, 2008\nTutor, Microeconomic Theory, Semester 1, 2008\nTutor, Introductory Microeconomics, Semester 2, 2007\nTutor, Introductory Microeconomics, Semester 1, 2007\nShort courses and workshops\nInstructor, Improving Representation of non-representative samples:\nMultilevel Regression with Post-stratification\nUniversity of Toronto, Department of Sociology, Social Science\nMethods Week 2021, 28 April 2021.\n\nInstructor, Gathering data\nWilfrid Laurier University, Laurier Institute for the Study of\nPublic Opinion and Policy, 15 January 2021, https://youtu.be/XzZbEh6aO40.\n\nInstructor, Getting started with R\nUniversity of Toronto, Undergraduate Global Society for Genetics and\nGenome Biology, 22 December 2020.\n\nInstructor, Gathering Data from Messy Sources\nUniversity of Toronto, Independent Summer Statistics Community, 22\nMay 2020.\n\nInstructor, Getting\nstarted with MRP\nAustralian National University, 3 December 2019.\n\nInstructor, Introduction to Blogdown\nAustralian National University, RSE, 21 July 2017.\n\nInstructor, Introduction to LaTeX\nAustralian National University, RSE, 13 September 2017.\nAustralian National University, RSE, 3 May 2016.\n\n",
      "last_modified": "2022-05-02T13:00:35-04:00"
    },
    {
      "path": "the_other_course.html",
      "title": "The Other Course",
      "description": "This is a course that improves your skills in data science and gives you the space to write a paper within certain guardrails.\n",
      "author": [],
      "contents": "\n\nContents\nPreamble\nOverview\nFAQ\nCourse learning\nobjectives\nPre-requisites\nAcknowledgements\n\nContent\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\n\nAssessment\nLearning diary\nPresentation I\nPresentation II\nPresentation III\nFinal Paper\n\n\nPreamble\nOverview\nThe course will be an enormous amount of work and cause you a large\namount of stress because it is likely your first opportunity to do\nunstructured original research. This is unfortunate, but there’s little\nway around it. All I can tell you is that having done this course, it’ll\nbe easier in the future. And pressure makes diamonds.\nThe purpose of this course is to write an original research paper,\nand in the process of that, to learn some useful skills. The paper will\nincorporate relevant literature, detailed data collection processes, be\nreproducible, use technically and statistically sound methodology, and\npresent the outcomes in an informative manner. The work is divided into\ntwo parts, a report describing the relevant background and technical\nprocesses (an R Markdown produced pdf) and an interactive layer (either\nShiny or an R Package).\nThe purpose of this course is to explore the technical aspects\nrequired to design and complete an end-to-end data science project,\nsimilar to those that students are likely to encounter in a professional\nenvironment. This course will require students to:\nGather data through scraping and the use of APIs.\nDesign supporting architecture to allow the data to gather over\ntime.\nDevelop machine learning models describing the statistical\nrelationship between variables within the dataset.\nTest the outcomes with new data to examine machine learning\nprediction veracity.\nPresent the outcomes of a highly specific concept in a meaningful\nmanner to a non-technical audience.\nEssentially this course provides students with the freedom to conduct\noriginal research on a topic of interest to them within certain\nguidelines.\nFAQ\nCan I audit this course? No. It’s a reading course so the concept of\nauditing doesn’t make sense.\nCan I attend lectures? No. There are no lectures. Students update\ntheir GitHub repo on a weekly basis and we meet the next day to talk\nthrough things.\nCourse learning objectives\nCollect real-world data and design systems to allow for the dataset\nto continuously grow.\nRefine R skills.\nClean, manage, analyze, and make predictions with data towards the\nproject goal.\nExplore and implement modelling options and explore relevant\nassumptions.\nExplore relationships within data\nDesign an interactive Shiny app or R Package for presentation of the\nresults and to allow the model to be deployed and used by others.\nHave a high-quality project to show the culmination of\nlearning.\nPre-requisites\nYou need to have taken ‘The Course’ or equivalent, such that you’ve\ntaken courses such that you’ve covered everything through to (but not\nincluding) ‘Enrichment’ of Telling Stories with Data.\nAcknowledgements\nThanks to the following who helped develop this course: Thomas\nWilliam Rosenthal.\nContent\nWeek 1\nTasks:\nCreate research plan.\nConduct initial literature review.\nAddress any weaknesses in version control.\nReadings:\nKing, Gary, ‘How to Write a Publishable Paper as a Class Project’,\nhttps://gking.harvard.edu/papers.\nShapiro, Jesse, ‘Four Steps to an Applied Micro Paper’, https://www.brown.edu/Research/Shapiro/pdfs/foursteps.pdf.\nRiederer, Emily, ‘RMarkdown Driven Development (RmdDD)’, https://emilyriederer.netlify.com/post/rmarkdown-driven-development/.\nMiyakawa, Tsuyoshi, ‘No raw data, no science: another possible\nsource of the reproducibility crisis’, Molecular Brain, https://doi.org/10.1186/s13041-020-0552-2.\nBryan, Jenny, Happy Git and GitHub for the useR, https://happygitwithr.com.\nWeek 2\nTasks:\nContinue literature review.\nIdentify relevant data.\nMake first Shiny app.\nSetup GitHub Repo, with appropriate folder structure and\nREADME.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters 2-5.\nJesse Shapiro, ‘Code and Data for the Social Sciences: A\nPractitioner’s Guide’, https://web.stanford.edu/~gentzkow/research/CodeAndData.xhtml\nWeek 3\nTasks:\nGather data:\nBuild initial webscrapers.\nBuild simulated dataset.\n\nFinalize literature review.\nBegin automating.\nReadings:\nCouch, Simon, ‘Running R Scripts on a Schedule with GitHub Actions’,\nhttps://blog.simonpcouch.com/blog/r-github-actions-commit/.\nWickham, Hadley, 2020, Mastering Shiny, Chapters 2-5\nWeek 4\nTasks:\nDevelop basic infrastructure for housing data.\nSet-up GitHub actions to automate gathering and cleaning.\nEstablish data pipeline to update analysis dataset.\nWrite tests against the simulated clean dataset.\nWeek 5\nTasks:\nMake second Shiny app.\nBuild first R package.\nBegin cleaning dataset toward passing tests.\nContinue automating data gathering.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters 8-9, https://mastering-shiny.org/action-feedback.html.\nWickham, Hadley and Jenny Bryan, R Packages, Chapter 2, https://r-pkgs.org/whole-game.html.\nWeek 6\nTasks:\nFinish any data pipeline/architecture development.\nPrepare data for modelling:\nEDA.\nFully incorporate all datasources.\nFurther cleaning if necessary.\n\nDetermine features of interest.\nContinue developing statistics skills.\nFamiliarize with tidymodels.\nReadings:\nKuhn, Max, and Julia Silge, 2021, Tidy Modeling with R,\nChapters 1-5.\nWickham, Hadley, and Garrett Grolemund, 2017, R for Data\nScience, Chapters 2-8.\nGareth M. James, Daniela Witten, Trevor Hastie, and Robert\nTibshirani, 2021, An Introduction to Statistical Learning,\nSecond Edition, Chapters 1-4.\nWeek 7\nTasks:\nBuild model with tidymodels or alternative\napproach.\nBuild a second R package that is more involved.\nContinue developing statistics skills, including Bayesian\nmethods.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R,\nChapters 6-7.\nWickham, Hadley, and Garrett Grolemund, 2017, R for Data\nScience, Chapters 22-25.\nGareth M. James, Daniela Witten, Trevor Hastie, and Robert\nTibshirani, 2021, An Introduction to Statistical Learning,\nSecond Edition, Chapters 5-7.\nMcElreath, Richard, 2020, Statistical Rethinking, Second\nedition, Chapters 1-4.\nWeek 8\nTasks:\nContinue machine learning development\nExplore, script, and compare different machine learning algorithm\nperformance\nFinalize model development and evaluate results.\nBuild third Shiny app.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R,\nChapters 8-9.\nWickham, Hadley, 2020, Mastering Shiny, Chapters\n10-12.\nMcElreath, Richard, 2020, Statistical Rethinking, Second\nedition, Chapters 5-6.\nWeek 9\nTasks:\nContinue improving model and pipeline, especially model evaluation\nand refinement with data augmentation.\nContinue developing statistics skills.\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R,\nChapters 10-12.\nMcElreath, Richard, 2020, Statistical Rethinking, Second\nedition, Chapters 7-8.\nWeek 10\nTasks:\nBegin write-up of paper, especially data and model sections.\nBegin developing R package or Shiny app\nReadings:\nKuhn, Max and Julia Silge, 2021, Tidy Modeling with R,\nChapters 13-14.\nMcElreath, Richard, 2020, Statistical Rethinking, Second\nedition, Chapters 11-13.\nWeek 11\nTasks:\nContinue write-up, especially results and discussion sections.\nFinish developing R package or Shiny app.\nReadings:\nWickham, Hadley, 2020, Mastering Shiny, Chapters\n13-16.\nMcElreath, Richard, 2020, Statistical Rethinking, Second\nedition, Chapters 14-16.\nWeek 12\nFinalise all apsects.\nTasks:\nAs needed.\nAssessment\nLearning diary\nTask: Each week you will read relevant papers and books, engaging\nwith them by writing notes and completing exercises. You will use GitHub\nto manage these notes and exercises and email a link to me at the end of\neach week. Additionally, reflect on what went well, what has room for\nimprovement, and consider ‘lessons learned’ during the week.\nDate: At the end of the week please send me a link to the GitHub repo\nthat contains this diary.\nWeight: 15 per cent.\nPresentation I\nTask: 10-15-minute presentation on what you’ve learned about the\nliterature and plans.\nDate: Roughly end of Week 4 (exact date determined by lab\npresentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nPresentation II\nTask: 10-15-minute presentation on what you’ve learned about the\ndata.\nDate: Roughly end of Week 8 (exact date determined by lab\npresentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nPresentation III\nTask: 10-15-minute presentation on what you’ve learned about the\nmodel.\nDate: Roughly end of Week 12 (exact date determined by lab\npresentation cycle— the last Friday of the month).\nWeight: 15 per cent.\nFinal Paper\nTask: A fully reproducible paper and associated Shiny app or R\nPackage. Toward the mid-term break we will have a meeting to discuss the\ntopic of your final paper. It will be due on the last day of the exam\nperiod. This will be marked by me and reviewed by another professor.\nDate: Second last day of exam period.\nWeight: 40 per cent.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:36-04:00"
    },
    {
      "path": "toronto_data_workshop-stipends.html",
      "title": "Toronto Data Workshop Stipends",
      "author": [],
      "contents": "\nFor their support of these stipends we thank: Dean Wendy Duff\nand the Faculty of Information; and Department Chair Radu Craiu and the\nDepartment of Statistical Sciences.\nCall for applications\n16 June 2020\nKelly Lyons and Rohan Alexander are announcing three research\nstipends, each of $1,000, for University of Toronto students or recent\ngraduates who identify as a member of a visible minority group,\nracialized group, or as a person of colour. The successful applicants\nwill be invited to prepare a research paper on a topic of their choice\nunder the supervision of a faculty mentor, and will be given the\nopportunity to present their paper at a meeting of the Toronto Data\nWorkshop that suits their research timetable.\nIf you are interested in applying for this training opportunity\nplease email rohan.alexander@utoronto.ca, by the end of Tuesday 30\nJune 2020, attaching a single PDF that contains:\nA brief (1 page) overview of what your paper will be about. Some\naspect of this paper should involve real-world data and quantitative\nanalysis. Strong applications will include: a specific and important\nresearch question; evidence of some developed ideas around data sources\nand methodology; and a clear motivation.\nYour CV. Strong applications will demonstrate potential through\ntheir grades, and by reference to projects on GitHub or similar.\nThe name of a University of Toronto faculty member who has agreed to\nsupervise this work.\nYou are welcome to find your own supervisor for this training\nopportunity, but if you do not have a faculty supervisor already, and do\nnot feel comfortable asking someone, then any of the following current\nor future faculty are more than happy to supervise you, and you should\nget in touch with one that matches your interests:\nJesse Gronsbell\n(Statistics)\nKelly Lyons\n(Information)\nLiza\nBolton (Statistics)\nMonica Alexander\n(Statistics and Sociology)\nRohan Alexander\n(Information and Statistics)\nVianey Leos Barajas\n(Statistics and Environment)\nIf you have any questions about your application, then please email\nrohan.alexander@utoronto.ca before the closing\ndate.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:36-04:00"
    },
    {
      "path": "toronto_data_workshop.html",
      "title": "Toronto Data Workshop",
      "description": "We share best practice for data science, and are especially interested in the data munging/cleaning/prep/comms stages that folks typically don't talk about. We meet for an hour each week and are interested in anything that is data-focused across academia and industry. Typically, Fridays at noon (Toronto time) via Zoom, with most talks recorded and shared. All welcome. Free. Sign up [here](https://forms.gle/sXbEixoa1iJR4Q7A8).\n",
      "author": [],
      "contents": "\n\nContents\nOverview\nCurrent schedule\nPast schedules\n\n\n\n\nOverview\nThe Toronto Data Workshop (TDW) brings together academia and industry\nto consider, collate, share, and disseminate best practices in doing\ndata science, especially in the data-centric steps of a data science\nproject: collection; cleaning; storage; retrieval; dissemination;\nprotection; and communication. We meet weekly for an hour and aim to\nhave a roughly even split of participants from academia and industry\nover the course of each term. For an invitation please sign up here. Anyone is welcome\nto attend - you don’t need to be affiliated with the university.\nCurrent organizing committee:\nAmy Farrow,\nKelly\nLyons,\nLorena Almaraz De La Garza, and\nRohan Alexander.\nPast committee members:\nFaria Khandaker.\nThe TDW is a joint initiative between the Faculty of Information and\nthe Department of Statistical Sciences at the University of Toronto and\nwe especially thank Dean Wendy Duff and Chair Radu Craiu for their\nsupport.\nCurrent schedule\nWinter 2022\n\n\n\nDate\nSpeaker\n\nFri 28 Jan 2022, noon - 1pm\nAshok Chaurasia, University of Waterloo\nhttps://youtu.be/qFCHjNH9HLc\nFri 4 Feb 2022, noon - 1pm\nNick Huntington-Klein, Seattle University\nhttps://youtu.be/dOJvE3C2KrY\nFri 11 Feb 2022, noon - 1pm\nSilvia Canelón, University of Pennsylvania\nhttps://youtu.be/4M8Op1oCN5U\nFri 18 Feb 2022, noon - 1pm\nVincent Arel-Bundock, Université de Montréal\nhttps://youtu.be/zrBhtXwZnB8\nFri 25 Feb 2022, noon - 1pm\nToronto\nWorkshop on Reproducibility\n\nFri 4 Mar 2022, noon - 1pm\nMaria Kamenetsky, University of Wisconsin-Madison\nhttps://youtu.be/cjpoa59-obU\nFri 11 Mar 2022, noon - 1pm\nIrena Papst, McMaster University\nhttps://youtu.be/Oxk5Dulhnpw\nFri 18 Mar 2022, noon - 1pm\nMay Chan and Ramses Van Zon, U of T Libraries and SciNet,\nrespectively.\nhttps://youtu.be/92vir6ZX1mg\nThu 24 Mar 2022, 5pm - 6pm\nEmi Tanaka, Monash University\nhttps://youtu.be/sFdZb89Th9g\nFri 1 Apr 2022, noon - 1pm\nBrittany Witham, Geopolitica\nhttps://youtu.be/x7ldixTA1aE\nFri 28 Jan 2022, noon - 1pm, Ashok Chaurasia,\nUniversity of Waterloo, ‘Multiple Imputation: Old and New Combining\nRules for Statistical Inference’\nDr. Ashok Chaurasia is an Assistant Professor (of Statistics) in the\nSchool of Public Health Sciences at University of Waterloo. His\nbackground/training is in Statistics, with research interests in topics\nof Missing Data, Data Imputation, Model Selection, and Longitudinal Data\nAnalysis Methodology.\nFri 4 Feb 2022, noon - 1pm, Nick Huntington-Klein,\nSeattle University\nI am an economics professor at Seattle University, with research that\nfocuses on higher education, econometrics, and metascience.\nFri 11 Feb 2022, noon - 1pm, Silvia Canelón,\nUniversity of Pennsylvania, ‘Topic: Lessons Learned from EHR\nResearch’\nSilvia Canelón is a postdoctoral research scientist in the Department of\nBiostatistics, Epidemiology, and Informatics at the University of\nPennsylvania where she applies biomedical informatics to population\nhealth research. She uses R to work on projects that develop novel data\nmining methods to extract pregnancy-related information from Electronic\nHealth Records (EHR) and that study the relationship between environment\nand disease.\nFri 18 Feb 2022, noon - 1pm, Vincent Arel-Bundock,\nUniversité de Montréal, ‘What modelsummary taught me\nabout R package development’\nI am a political science professor at the Université de Montréal.\nFri 25 Feb 2022, noon - 1pm, Reading week\nbreak\nFri 4 Mar 2022, noon - 1pm, Maria Kamenetsky,\nUniversity of Wisconsin-Madison, ‘Spatial clustering’\nI am a PhD candidate in Epidemiology at the University of\nWisconsin-Madison, where I also completed my MS in Statistics. My\nresearch focuses on methods in spatial epidemiology, specifically\nworking on statistical methods and applications in spatial cluster\ndetection.\nFri 11 Mar 2022, noon - 1pm, Irena Papst, McMaster\nUniversity, ‘Some or all of: COVID-19 data, modelling, experiences\nusing models to help guide pandemic response’\nI’m a postdoctoral fellow in McMaster’s Mathematics & Statistics\ndepartment, where I work on mathematical modelling, especially of\ninfectious disease dynamics. I did my PhD in Cornell’s Center for\nApplied Mathematics. I care deeply about reproducible research, clear\nscientific communication, good teaching, and big salads.\nFri 18 Mar 2022, noon - 1pm, May Chan and Ramses Van\nZon\nThu 24 Mar 2022, 5pm - 6pm, Emi Tanaka, Monash\nUniversity, ‘An anthology of experimental designs’\nDr. Emi Tanaka is an assistant professor in statistics at Monash\nUniversity whose primary interest is to develop impactful statistical\nmethods and tools that can readily be used by practitioners. Her\nresearch area include data visualisation, mixed models and experimental\ndesigns, motivated primarily by problems in bioinformatics and\nagricultural sciences. She is currently the President of the Statistical\nSociety of Australia Victorian Branch and the recipient of the\nDistinguished Presenter’s Award from the Statistical Society of\nAustralia for her delivery of a wide-range of R workshops.\nFri 1 Apr 2022, noon - 1pm, Brittany Witham,\nGeopolitica, ‘Data science at a startup’\nOriginally from Melbourne, Australia, Brittany received her B.A. in\nInternational Studies from the University of Saskatchewan and started\nher career in economic development, equipping her with comprehensive\nknowledge of foreign direct investment and international business early\nin her career. She went on to obtain an M.A. in European and Russian\nAffairs from the University of Toronto in 2018, where she first\ndiscovered the potential of programming for political science and became\nfascinated with artificial intelligence (AI). Over the past three years,\nBrittany has worked in many facets of the AI industry, from leading\nresearch and development of new AI products for video game developers to\nbuilding automated data pipelines for business intelligence and managing\nsoftware engineering and client engagement teams. In that time, she has\nhoned technical skills in full-stack development, machine learning, and\ndata engineering. She recently struck out on her own to launch an online\nglobal event monitoring tool and deliver novel solutions to clients in\nthe political risk and social enterprise sectors. Brittany is a firm\nbeliever in the potential for data-driven technologies for geopolitics\nand is excited to contribute to the many discoveries to be made in this\nspace.\nPast schedules\nFall 2021\n\n\n\nThis term is mostly a special series of talks featuring University of\nToronto speakers on the relationship between data science and their\nother field of expertise.\nDate\nSpeaker\n\nFri 24 Sep 2021, noon - 1pm\nKaren Chapple, Geography, planning, cities\nhttps://youtu.be/rNRwOStrb9o\nFri 1 Oct 2021, noon - 1pm\nSpecial on 2021 Canadian Election\nhttps://youtu.be/pCwJXgR7V5k\nFri 8 Oct 2021, noon - 1pm\nFedor Dokshin, Sociology\nhttps://youtu.be/QjTsDbH6MxM\nFri 15 Oct 2021, noon - 1pm\nDrew Stommes, Yale University\n-\nFri 22 Oct 2021, noon - 1pm\nTegan Maharaj, Information\nhttps://youtu.be/SP3bZ3uHyTg\nFri 29 Oct 2021, noon - 1pm\nJosh Speagle, Astronomy\nhttps://youtu.be/fHk3Fy1TxQY\nFri 5 Nov 2021, noon - 1pm\nYun William Yu, Math\nhttps://youtu.be/-1jpjM2nP2Y\nFri 12 Nov 2021, noon - 1pm\nAnn Glusker, Berkeley\nhttps://youtu.be/139xCz-e0tg\nFri 19 Nov 2021, noon - 1pm\nRadu Craiu, Statistical Sciences\nhttps://youtu.be/B7EKLFotknU\nFri 26 Nov 2021, noon - 1pm\nKieran Campbell, Biomedicine\nhttps://youtu.be/PuQhyGj3G3o\nFri 3 Dec 2021, noon - 1pm\nLeanne Trimble, Libraries\nhttps://youtu.be/rxnShSHwBXU\nFri 10 Dec 2021, noon - 1pm\nNathan Taback, Teaching\nhttps://youtu.be/99pOuO_TD5w\nFriday, 24 September 2021, noon - 1pmKaren Chapple, Department of Geography and\nPlanning/School of CitiesKaren Chapple is the inaugural\nDirector of the School of Cities and Professor of Geography and Planning\nat the University of Toronto. Her research uses data science methods to\nidentify and predict gentrification and displacement in cities. She is\nProfessor Emerita at the University of California, Berkeley, where she\nhelped to launch the undergraduate data science program.\nFriday, 1 October 2021, noon - 1pmSpecial meeting on 2021 Canadian Election\nDiscussion and presentations by:\nProfessor David\nAndrews on elections forecasting.\nProfessor Daniel Rubenson on\nthe Canadian Election Study.\nJohnson Vo on his model of the 2021 election.\nEric Zhu, Brian Diep, Ashely (Jing Yuan) Zhang, Kristin (Xi Yu\nHuang), and Tanvir Hyder on their model of the 2021 election.\n\nFriday, 8 October 2021, noon - 1pmFedor Dokshin, Department of SociologyFedor Dokshin is an Assistant\nProfessor of Sociology at the University of Toronto. He is a\ncomputational social scientist with research interests in social\nnetworks, organizations, and energy and the environment. Across these\ndomains, Fedor leverages data science methods and novel data sources to\nimprove existing measurement strategies.\nFriday, 15 October 2021, noon - 1pmDrew Stommes, Department of Political Science, Yale\nUniversityDrew Stommes is a doctoral\ncandidate in the Department of Political Science at Yale University,\nwhere he researches democracy, political violence, and quantitative\nmethods. He will talk about a recent working paper, ‘On the\nreliability of published findings using the regression discontinuity\ndesign in political science’.\nFriday, 22 October 2021, noon - 1pmTegan Maharaj, Faculty of Information\nI study AI systems and “what goes into” them, e.g. their real-world\ndeployment context, and the effects that has on learning behaviour and\ngeneralization. I do that because I want to be able to use AI systems\nresponsibly for problems I think are important, like impact and risk\nassessments for climate change, AI alignment, ecological management and\nother common-good problems. My website is: http://www.teganmaharaj.com/.\nFriday, 29 October 2021, noon - 1pmJosh Speagle, Astronomy & Astrophysics, Dunlap\nInstitute, Statistical SciencesJosh is a Banting &\nDunlap Postdoctoral Fellow at the University of Toronto whose research\nfocuses on using astrostatistics and “data science” to understand how\ngalaxies like our own Milky Way form, behave, and evolve.\nFriday, 5 November 2021, noon - 1pmYun William Yu, Math Department, UofT; UTSC Computer\n& Mathematical SciencesYun\nWilliam Yu is an assistant professor in the math department at UofT\nwhose research focuses on algorithmic methods for computational biology\nand medical informatics.\nFriday, 12 November 2021, noon - 1pmAnn Glusker, Doe Library, University of California\nBerkeley\nDr Ann Glusker is Librarian for Sociology, Demography, Public Policy,\nPsychology (fall 2021) & Quantitative Research at the Doe Library,\nUniversity of California, Berkeley. She will discuss a recently released\nreport\n‘Supporting Big Data Research at the University of California,\nBerkeley’. This report provides insights on researcher practices and\nchallenges in six thematic areas: data collection & processing;\nanalysis: methods, tools, infrastructure; research outputs;\ncollaboration; training; and balancing domain vs data science\nexpertise.\nFriday, 19 November 2021, noon - 1pmRadu Craiu, Statistical Sciences @ U of TDr. Radu V. Craiu is\nProfessor and Chair of Statistical Sciences at the University of\nToronto. His main research interests are in computational methods in\nstatistics, especially, Markov chain Monte Carlo algorithms (MCMC),\nBayesian inference, copula models, model selection procedures and\nstatistical genetics.\nFriday, 26 November 2021, noon - 1pmKieran Campbell, Lunenfeld Tanenbaum Research\nInstituteDr. Kieran Campbell is an\ninvestigator at the Lunenfeld-Tanenbaum Research Institute and an\nassistant professor at the Departments of Molecular Genetics and\nStatistical Sciences, University of Toronto. His research focusses on\nBayesian models and machine learning for high dimensional biomedical\ndata, including single-cell and cancer genomics. Recently, he has led\nefforts to develop statistical machine learning methodology to integrate\nsingle-cell RNA and DNA sequencing data to uncover the effects of tumour\nclonal identity on gene expression, as well as methods to automatically\ndelineate the tumour microenvironment from single-cell RNA-sequencing\ndata. Such findings can improve our understanding of cancer progression\nand of why certain tumours are resistant to therapies, leading to\nrelapse.\nFriday, 3 December 2021, noon - 1pmLeanne Trimble, UofT Libraries\nLeanne Trimble is a data librarian at the Map & Data Library,\nUniversity of Toronto Libraries.\nFriday, 10 December 2021, noon - 1pmNathan Taback, Departments of Statistical\nSciencesNathan Taback is the\ndirector of Data Science programs and an Associate Professor, Teaching\nStream in the Department of Statistical Sciences, and Computer Science\n(cross-appointed) at the University of Toronto. He currently serves as a\nSpecial Advisor to the Dean of Arts and Science on Computational and\nData Science Education.\nSummer 2021\n\n\n\nDate\nSpeaker\nTopic\nRecording\nFri 21 May 2021, noon-1pm\nDavid Shor, OpenLabs\nPolitical data science.\nhttps://youtu.be/_IEPKapa9_0\nFri 28 May 2021, noon-1pm\nSamantha Pierre, University of Toronto\nThe Effects of a Tony Award.\nhttps://youtu.be/rFojvBN0qGk\nFri 4 June 2021, noon-1pm\nHeather Krause, We All Count\nEquity in data.\nhttps://youtu.be/Yu_l8MpKK-E\nFri 11 June 2021, noon-1pm\nLaura Bronner, Data scientist\nQuantitative editing.\nhttps://youtu.be/LI5m9RzJgWc\nFri 18 June 2021, noon-1pm\nJacob Matson, Simetric, Inc.\nFrom data to dashboard.\nhttps://youtu.be/U8-6QKtWXCQ\nFri 25 June 2021, noon-1pm\nLaura Derksen, University of Toronto Mississauga (jointly\nhosted with the UTM Collaborative Digital Research Space.)\nEffect of Wikipedia\nhttps://youtu.be/Coz-HFesTsw\nFri 2 July 2021, noon-1pm\nZachary McCaw, Google\n-\n-\nFri 16 July 2021, noon-1pm\nKamilah Ebrahim, University of Toronto\nTrust in contact tracing apps.\nhttps://youtu.be/f_3bpEeRdhI\nFri 23 July 2021, noon-1pm\nAnnie Collins & Rohan Alexander, University of\nToronto\nReproducibility of COVID-19 pre-prints\nhttps://youtu.be/_ncpTbhe8qA\nFri 30 July 2021, noon-1pm\nKeli Chiu, University of Toronto\nDetecting and explaining sexist and racist text with GPT-3\nhttps://youtu.be/xmmoVD5zTOQ\nFri 6 August 2021, 12:30-1:30pm\nIjeamaka Anyene, Kaiser Permanente Division of\nResearch\nTaking the next step past standard charts.\nhttps://youtu.be/LlVf8foXUmM\nFri 13 August 2021, noon-1pm\nStudents from the Independent Summer Statistics Community\nAnalysis of Toronto data\nhttps://youtu.be/zkuMedB23f8\nFri 20 August 2021, noon-1pm\nStudents from Vianey Leos\nBarajas’ research group, University of Toronto\nSharks, lizards, and basketball!\nhttps://youtu.be/p697exbcMZE\nFriday, 21 May 2021, Noon - 1pmDavid Shor, OpenLabs, \nBio: David is an American data\nscientist who tries to elect Democrats. He is known for analyzing\npolitical polls and currently serves as head of data science with\nOpenLabs, a progressive nonprofit, and also as a Senior Fellow with the\nCenter for American Progress Action Fund.\nTopic: Political data science.\nRecording: https://youtu.be/_IEPKapa9_0\nFriday, 28 May 2021, Noon - 1pmSamantha Pierre, University of Toronto, \nBio: Samantha is a fourth-year statistics student studying at the\nUniversity of Toronto. Throughout the past year she has combined her\nlove for theatre and statistics to analyze trends in the theatre\ncommunity. She volunteers as a member of PAIR-CG to create a\nrepresentational framework for the international theatre community. She\ncurrently works at WOMBO, an app developed by former U of T students, as\nhead of music content.\nTopic: And The Nominees Are… An Empirical Study of the Effects of a Tony\nAward Win and Nomination on a Show’s Success.\nRecording: https://youtu.be/rFojvBN0qGk\nFriday, 4 June 2021, Noon - 1pmHeather Krause, We All Count, \nBio: Heather remains unconvinced.\nAs a statistician with decades of global experience working on complex\ndata problems and producing real-world knowledge, she has developed the\nData Equity Framework to address the equity issues in data products and\nresearch projects. Her emphasis is on combining strong statistical\nanalysis with clear and meaningful communication. She is currently\nworking on implementing tools for equity and ethics in data. As the\nfounder of two successful data science companies, she attacks the\nlargest questions facing societies today, working with both civic and\ncorporate organizations to improve outcomes and lives. Her relentless\npursuit of clarity and realism in these projects pushed her beyond pure\nanalysis to mastering the entire data ecosystem including award-winning\nwork in data sourcing, modeling, and data storytelling, each\nincorporating bleeding edge theory and technologies. Heather is the\nfounder of We All Count, a project for equity in data working with teams\nacross the globe to embed a lens of ethics into their data products from\nfunding to data collection to statistical analysis and algorithmic\naccountability. Her unique set of tools and contributions have been\nsought across a range of clients from MasterCard and Volkswagen to the\nUnited Nations, the Syrian Refugee Resettlement Secretariat, Airbnb, and\nthe Bill and Melinda Gates Foundation. She is on the Data Advisory Board\nof the UNHCR.\nTopic: Equity in Data (or, how not to accidentally use data like a\nracist, sexist, colonialist, etc).\nRecording: https://youtu.be/Yu_l8MpKK-E\nFriday, 11 June 2021, Noon - 1pmLaura Bronner, Data scientist, \nBio: Laura is a data\nscientist, who most recently worked as the quantitative editor at\nFiveThirtyEight. More generally, she is a data scientist with an\ninterest in causal inference, political science and quantitative text\nanalysis. Before FiveThirtyEight, she was a Senior Analyst at the\nAnalyst Institute, designing and analyzing field experiments for the\n2018 election cycle. In September 2018, she completed a PhD in Political\nScience at the London School of Economics’ Department of\nGovernment.\nTopic: Quantitative editing.\nRecording: https://youtu.be/LI5m9RzJgWc\nFriday, 18 June 2021, Noon - 1pmJacob Matson, Simetric, \nBio: Jacob is VP\nof Finance & Operations at Simetric,\nInc..\nTopic: From data ask to dashboard.\nRecording: https://youtu.be/U8-6QKtWXCQ\nFriday, 25 June 2021, Noon - 1pmLaura Derksen, University of Toronto Mississauga, \nBio: Laura is\nthe Amgen Canada Professor in Health System Strategy at the University\nof Toronto Mississauga and assistant professor in Strategic Management\nat the Rotman School of Management. Her research interests are\ndevelopment and global health education, information and networks.\nTopic: The impact of student access to Wikipedia. Recording: https://youtu.be/Coz-HFesTsw\nFriday, 2 July 2021, Noon - 1pmZachary McCaw, Google\nBio: Zachary McCaw is a data scientist at Google.\nFriday, 16 July 2021, Noon - 1pmKamilah Ebrahim, University of Toronto, \nBio: Kamilah Ebrahim received a B.A. in Economics from the University of\nWaterloo in 2019 and is currently pursuing a Masters of Information in\nHuman Centred Data Science at the University of Toronto. Kamilah is a\n2020-21 Graduate Fellow at the University of Toronto Centre for Ethics\nfocusing on the intersection between race, economics and data monopolies\nin Canada. Prior to joining the University of Toronto she held roles at\nthe United Nation Economic and Social Commission for Asia and the\nPacific (UN ESCAP), as well as the Canadian federal government.\nTopic: Trust in contact tracing apps.\nRecording: https://youtu.be/f_3bpEeRdhI\nFriday, 23 July 2021, Noon - 1pmAnnie Collins & Rohan Alexander, University of\nToronto\nBio: Annie Collins is an undergraduate student at the University of\nToronto specializing in applied mathematics and statistics with a minor\nin history and philosophy of science. In her free time, she focusses her\nefforts on student governance, promoting women’s representation in STEM,\nand working with data in the non-profit and charitable sector. Rohan\nAlexander is an assistant professor at the University of Toronto in\nInformation and Statistical Sciences, and a faculty affiliate at the\nSchwartz Reisman Institute for Technology and Society. He holds a PhD in\nEconomics from the Australian National University.\nTopic: Reproducibility of COVID-19 pre-prints.\nRecording: https://youtu.be/_ncpTbhe8qA\nFriday, 30 July 2021, Noon - 1pmKeli Chiu, University of Toronto\nBio: Keli Chiu is a recent graduate\nof master in Information at the University of Toronto with the\nconcentration in Human-Centred Data Science. Prior to pursuing her\nmaster in the information fields, she worked as a web developer and fell\nin love with data. Her research interests are natural language\nprocessing applications, text analysis and ethics in AI and machine\nlearning. She received rstudio::global Diversity Scholarships in the\nyear of 2021.\nTopic: Detecting sexist and racist text contents with explanations\naccompanied with GPT-3\nRecording: https://youtu.be/xmmoVD5zTOQ\nFriday, 6 August 2021, 12:30pm - 1pmIjeamaka Anyene, Kaiser Permanente Division of\nResearch, \nBio: Ijeamaka is a\ndata analyst working in healthcare research. She specializes in using R\nand SAS for data analysis, epidemiological research, and data\nvisualizations. She is also passionate about computational art,\nknowledge sharing / dissemination, and how to mix the two.\nTopic: Taking the next step past standard charts.\nRecording: https://youtu.be/LlVf8foXUmM\nFriday, 13 August 2021, Noon - 1pmStudent groups from the Independent Summer Statistics\nCommunity, University of Toronto\n‘Prospective Analytics’ comprised of Ashley Zhang, Eric Zhu, Muhammad\nTsany and Sergio Zheng Zhou.\n‘Statistically Significant’ comprised of Aliza Lakho, Chloris Jiang,\nJanhavi Agarwal, and José Casas on whether young professionals should\nmove to Toronto.\n‘Point Zero Five’ comprised of Pan Chen, Xiaoxuan Han, Yi Qin, and Yini\nMao on the livability of Toronto for newcomers.\nRecording: https://youtu.be/zkuMedB23f8\nFriday, 20 August 2021, Noon - 1pmStudents from Vianey Leos Barajas’ research group,\nUniversity of Toronto\nBio: Jessica Long, Simone Collier, Vinky Wang, Sophie Berkowitz, and\nYun-Hsiang Chan are undergraduate students at the University of\nToronto.\nTopic: The presentations will use statistical model to analyzing shark,\nlizard, and basketball movement data. The data was collected through\ndrones, accelerometers or video tracking software.\nRecording: https://youtu.be/p697exbcMZE\nWinter 2021\n\n\n\nThanks to Paul Hodgetts for the\nJays-inspired sticker.\nDate\nSpeaker\nTopic\nRecording\nThu 14 Jan, 4:30-5:30pm\nAndrew Miles, University of Toronto (jointly hosted with\nthe UTM Collaborative Digital Research Space.)\nCode, plots, and values\nhttps://youtu.be/mdjOoKT-f7E\nWed 20 Jan, 4:30-5:30pm\nZia Babar, University of Toronto\nDerivative data security.\nhttps://youtu.be/fdVZqvECXXQ\nThu 28 Jan, 4:30-5:30pm\nIrene Duah-Kessie, University of Toronto\nBias and fairness in health.\nhttps://youtu.be/xwWvOeSXu5o\nThu 4 Feb, 4:30-5:30pm\nKathy Ge, Uber\nExperimentation and product design.\nhttps://youtu.be/UYzXElJTovg\nThu 11 Feb, 4:30-5:30pm\nGarrick Aden-Buie, R Studio\nUsing R Markdown.\nhttps://youtu.be/Hl798H6J-bg\nMon 15 Feb, Noon-1:00pm\nEmily Riederer, Capital One\nObservational causal inference.\nhttps://youtu.be/VP3BBZ7poc0\nThu 18 Feb, 4:30-5:30pm\nAnnie Collins, Haoluan Chen, Isaac Ehrlich, Mariam Walaa, Marija\nPejcinovska, Mathew Wankiewicz, Michael Chong, Paul Hodgetts, Rohan\nAlexander, Samantha-Jo Caetano, Shirley Deng, and Yena Joo,\nUniversity of Toronto\nDoSS toolkit launch.\nhttps://youtu.be/aeAXvW3K_wU\nThu 25 Feb, 9:00-5:30pm\nVarious\nToronto\nWorkshop on Reproducibility\nSee here.\nFri 26 Feb, 9:00-5:30pm\nVarious\nToronto\nWorkshop on Reproducibility\nSee here.\nThu 4 Mar, 4:30-5:30pm\nPetros Pechlivanoglou, The Hospital for Sick Children (SickKids)\nResearch Institute\nSimulation and retrospective data for health economic decision\nmaking.\nhttps://youtu.be/-aZjLCPsO_w\nThu 11 Mar, 4:30-5:30pm\nLucas Cherkewski, Canadian Digital Service\nUsing publicly-available data.\nhttps://youtu.be/6vDedpF0lfg\nMon 15 Mar, 4:00-5:00pm\nTodd Feathers, Freelance reporter\nAlgorithmic fairness in universities. (jointly hosted with Maryclare Griffin)\nhttps://youtu.be/Hw5viOofnC0\nThu 18 Mar, 4:30-5:30pm\nSofia Ruiz Suarez, National University of Comahue\nAnimal tracking data.\nhttps://youtu.be/GMi5nLl4wos\nThu 25 Mar, 4:30-5:30pm\nAlex Cookson, Muse\nThe power of great datasets.\nhttps://youtu.be/E2aRKZczqKY\nThu 1 Apr, 4:30-5:30pm\nVik Pant, Natural Resources Canada\nIntegrating science & policy through DS & AI.\n-\nThu 8 Apr, 4:30-5:30pm\nFaria Khandaker, University of Toronto\n’Mining Process Models from Email Data.\nhttps://youtu.be/2M32PbclTnE\nThu 15 Apr, 4:30-5:30pm\nEmily A. Sellars, Yale University\nData issues in Mexican demographic history.\n\nThu 22 Apr, 4:30-5:30pm\nAimee Schwab-McCoy, Creighton University, Ashley Juavinett,\nUC San Diego, Chris Papalia, St. Andrew’s College,\nSamantha-Jo Caetano, University of Toronto\nPanel on teaching data-focused topics.\n\nThursday, 14 January, 4:30-5:30pmAndrew Miles, University of TorontoJointly hosted with Elizabeth Parke and the UTM Collaborative\nDigital Research Space.Andrew Miles is Assistant\nProfessor of Sociology at the University of Toronto and Director of the\nMorality, Action, and Cognition Lab.\nTopic: Code, plots, and values.\nRecording: https://youtu.be/mdjOoKT-f7E\nWednesday, 20 January, 4:30-5:30pmZia Babar, University of Toronto\nZia Babar obtained his PhD from the University of Toronto where his\nresearch studies focused on the analysis and design of data-centered\ninformation systems for enabling enterprise transformation. He is\nengaged in a multi-year research engagement with IBM Research Labs and\nis a startup technical mentor at WeWork Labs. He is the organizer of\ntechnology meetup groups in both Toronto and Waterloo, and a course\ninstructor at the Faculty of Information, University of Toronto.\nZia will provide a background on data security approaches, and a\ndemonstration of machine learning and deep learning techniques that can\nbe used for providing derivative data security.\nThursday, 28 January, 4:30-5:30pmIrene Duah-Kessie, University of Toronto\nIrene Duah-Kessie is a graduate of the University of Toronto’s Master of\nScience in Sustainability Management program. Throughout her studies,\nIrene published her research on racial income inequality in Toronto with\nthe Wellesley Institute and is currently a part of the Turtle Island\nJournal of Indigenous Health Editorial Team. Irene is a Project Manager\nat Across Boundaries leading an initiative to address food security and\nmental health challenges in Toronto’s Black community. She is also the\nfounder of Rise In STEM, a grassroots organization that aims to increase\naccess to STEM learning opportunities in Black and marginalized\ncommunities.\nTopic: Exploring algorithmic bias and fairness and its impact on health\noutcomes faced by racialized communities.\nThursday, 4 February, 4:30-5:30pmKathy Ge, Uber\nKathy is a data scientist with Uber Eats primarily focused on the\nshopping experience including ranking and recommendations throughout the\norder flow. She received her M.Sc. in Computer Science and B.Sc in\nComputer Science and Statistics from the University of Toronto.\nTopic: How data insights and experimentation help drive product design\nand intelligent recommendations on the Uber Eats platform.\nThursday, 11 February, 4:30-5:30pmGarrick Aden-Buie, R StudioGarrick is a Data Science\nEducator at RStudio who lives in sunny St. Petersburg, Florida. His\npassion is combining creative coding with programming education, using\ncode to build tools that teach coding to new and advanced R users alike.\nLike tidyexplain: a project that used ggplot2 and gganimate to reimagine\ndatabase operations as colorful flying boxes instead of the typical Venn\ndiagrams. Garrick has developed a number of open source addins and\npackages for RStudio—such regexplain, shrtcts and rsthemes—and is always\neasily distracted by projects that combine R Markdown and online\nlearning or teaching.\nTopic: Using R Markdown in general and in some specific projects.\nMonday, 15 February, Noon-1:00pmEmily Riederer, Capital OneEmily is a Senior\nAnalytics Manager at Capital One. Emily’s team focuses on reimagining\nanalytical infrastructure by building data products, elevating business\nanalysis with novel data sources and statistical methods, and providing\nconsultation and training to partner teams.\nTopic: Causal\ndesign patterns for data analysts.\nThursday, 18 February, 4:30-5:30pmSpecial guest Bethany White (Department of Statistical\nSciences).Annie Collins, Haoluan Chen, Isaac Ehrlich, Mariam Walaa, Marija\nPejcinovska, Mathew Wankiewicz, Michael Chong, Paul Hodgetts, Rohan\nAlexander, Samantha-Jo Caetano, Shirley Deng, and Yena Joo,\nUniversity of Toronto\nUniversity of Toronto DoSS toolkit launch.\nThe DoSS toolkit is a series of self-paced lessons that students can go\nthrough ahead of class, to achieve badges for various levels of\naccomplishment with R. Instructors can use the badges to work out the\nlevel of the class and either direct students to the toolkit to address\ndeficiencies or cover missing aspects themselves.\nThursday, 25 February, 9:00-6:30pmVarious speakersToronto\nWorkshop on Reproducibility\nFriday, 26 February, 8:00-6:00pmVarious speakersToronto\nWorkshop on Reproducibility\nThursday, 4 March, 4:30-5:30pmPetros Pechlivanoglou, The Hospital for Sick Children\n(SickKids) Research Institute\nPetros Pechlivanoglou, PhD, is a Scientist at The Hospital for Sick\nChildren (SickKids) Research Institute and an Assistant Professor at the\nUniversity of Toronto, Institute of Health Policy Management and\nEvaluation. He studied economics in his native country, Greece,\neconometrics at the University of Groningen, the Netherlands and\nobtained a PhD in health econometrics from the same university. He\ncompleted a post-doctoral fellowship at the University of Toronto,\nwithin the Toronto Health Economics and Technology Assessment (THETA)\nCollaborative where he focused on methodological aspects around the\napplication of decision analysis in health-care policy.\nPetros will talk about marrying simulation modeling and retrospective\ndata for health economic decision making.\nThursday, 11 March, 4:30-5:30pmLucas Cherkewski, Canadian Digital ServiceLucas Cherkewski is a policy\nadvisor at the Canadian Digital Service (CDS). He helps delivery teams\nimprove government services. From that experience, he advises on\nstructural changes to make better services the default. This work\nincludes plenty of data-enabled research and analysis—Lucas is in a\nhappy place when his work leads him to spend an afternoon poking around\na dataset, trying to better understand government so he can help change\nit.\nLucas will talk about a few of these small CDS research projects, using\npublicly-available data to better understand the government’s\noperations.\nMonday, 15 March, 4:00-5:00pmTodd Feathers, Freelance reporter\nJointly hosted with Maryclare\nGriffin, University of Massachusetts Amherst.Todd Feathers is a freelance\njournalist covering artificial intelligence, surveillance, and the\ntechnologies changing our world. He spent years at daily newspapers\nreporting on politics, criminal justice, and health care. On every beat,\nnew tech is solving problems and creating them. His goal is to use data,\nscientific research, and inside sources to cut through the hype and\nexamine what our gadgets and algorithms really do. Writing in Vice,\nOneZero, The Wall Street Journal, and others.\nTodd will talk about ‘Major\nUniversities are Using Race as a “High Impact Predictor” of Student\nSuccess’ published in The Markup on 2 March 2021.\nThursday, 18 March, 4:30-5:30pmSofia Ruiz-Suarez, National University of ComahueSofia Ruiz-Suarez holds\nan undergraduate degree in mathematics from the University of Buenos\nAires and now is a PhD candidate at the institute for Research on\nBiodiversity and Environment. She also teaches mathematics at the\nUniversity of Comahue and leads R-Ladies at her local city. Her research\nis focused on Bayesian statistics with applications in animal behaviour\nand movement.\nSofia will talk about animal tracking data. She will explain how sensors\nare used to track animal movement and activities, the characteristics of\nthis type of data and how to deal with it.\nThursday, 25 March, 4:30-5:30pmAlex Cookson, MuseAlex Cookson is a Data\nScientist at Muse, where he helps\nmake the most of their data. In his spare time, you can find him\nparticipating in Tidy Tuesday or thinking up cool datasets to explore.\nAnd when he’s not doing that, he’s probably cycling around Toronto or\ndoting on his two cats, Tom Tom and Ruby.\nAlex will explore the power of great datasets, and discuss the\nimportance of interesting, fun datasets as a way to guide and motivate\nlearning R.\nThursday, 1 April, 4:30-5:30pmVik Pant, Natural Resources Canada.\nDr. Vik Pant is the Chief Scientist and Chief Science Advisor of Natural\nResources Canada (NRCan). He leads the Office of the Chief Scientist at\nNRCan and reports directly to the Deputy Minister. His office oversees\nthe development and implementation of evidence-based science policy\nacross NRCan sectors and agencies. His office also manages NRCan’s\nenterprise-wide technology strategy and portfolio of science products.\nHe also runs the Digital Accelerator, which is an innovation platform\nfor designing and launching AI-driven software products in NRCan. Vik is\nalso the Founder of Synthetic Intelligence Forum, which is a leading\ncommunity of practice focused on the industrial application of\nArtificial Intelligence (AI). He earned a doctorate from the Faculty of\nInformation (iSchool) in the University of Toronto, a master’s degree in\nbusiness administration with distinction from the University of London,\na master’s degree in information technology from Harvard University,\nwhere he received the Dean’s List Academic Achievement Award, and an\nundergraduate degree in business administration from Villanova\nUniversity. Vik serves as an Adjunct Professor in the Faculty of\nInformation (iSchool) at the University of Toronto.\nVik will discuss supporting the Integration of Science and Policy\nthrough Data Science and Artificial Intelligence.\nThursday, 8 April, 4:30-5:30pmFaria Khandaker, University of Toronto\nFaria is a 2nd year student of the Information Systems and Design\nConcentration at the Faculty of Information and is one of the co-hosts\nof the Toronto Data Workshop. She holds an Honour’s Bachelor of Science\nDegree in Anthropology and Human Biology from the University of Toronto\nScarborough. Since starting her masters, she became interested in\nresearch related to data-driven decision making within organizations.\nUnder the supervision of Professor Arik Senderovich, she is researching\ntopics related to the application of Machine Learning within the field\nof Process Mining and exploring various methodologies for gaining\ninsights from email driven business processes.\nFaria will discuss mining process models from email data.\nThursday, 15 April, 4:30-5:30pmEmily A. Sellars, Yale UniversityEmily A. Sellars is an assistant\nprofessor in the Department of Political Science at Yale University.\nBefore coming to Yale, she was an assistant professor in the Bush School\nof Government and Public Service at Texas A&M University and a\npostdoctoral scholar at the University of Chicago’s Harris School of\nPublic Policy. She received her Ph. D. in Political Science and\nAgricultural and Applied Economics from the University of\nWisconsin–Madison in 2015. Her research interests are at the\nintersection of political economy and development economics. Her\nresearch examines the political economy of emigration and\npopulation.\nEmily will discuss missing data and mis-measurement in Mexico’s 1900\ncensus and the Historical Archive of Localities (AHL).\nThursday, 22 April, 4:30-5:30pmAimee Schwab-McCoy, Creighton University,\nAshley Juavinett, UC San Diego, Chris\nPapalia, St. Andrew’s College, Samantha-Jo\nCaetano, University of TorontoAimee Schwab-McCoy is\nan Assistant Professor of Statistics at Creighton University. Ashley Juavinett is a\nneuroscientist, an educator, and a writer, currently working as an\nAssistant Teaching Professor at UC San Diego. Chris Papalia is a\nMathematics and Science Teacher and Head of House at St. Andrew’s\nCollege. Samantha-Jo Caetano is an Assistant Professor, Teaching Stream,\nat the University of Toronto.\nPanel on teaching data-focused topics.\nFall 2020\n\n\n\nThanks to Hidaya Ismail for the\nbrilliant maple leaf and dinosaur hex stickers.\nDate (Toronto time)\nSpeaker\nTopic\nRecording\nThu, 3 Sep, 4-5pm\nErik Drysdale (The Hospital for Sick Children)\nUsing hospital data\n\nTue, 8 Sep, 3:30-4:30pm\nSophie Bennett (Industry data scientist)\nUK A levels algorithm issues (jointly hosted with SRI)\n\nThu, 10 Sep, 4-5pm\nA Mahfouz, Diego Mamanche Castellanos, Hidaya Ismail, Ke-Li Chiu\n& Paul Hodgetts (University of Toronto)\nVarious R packages and research developed by students\n\nThu, 17 Sep, 4-5pm\nAmber Simpson (Queen’s University)\nCancer and AI\n\nThu, 24 Sep, 4-5pm\nChelsea Parlett-Pelleriti (Chapman University)\nTalking to non-statisticians about statistics\n\nThu, 1 Oct, 4-5pm\nFlorence Vallée-Dubois (Université de Montréal)\nCanadian demographics by riding (1991-2015)\n\nThu, 8 Oct, 4-5pm\nYim Register (University of Washington Data Lab)\nSelf-advocacy within machine learning systems\n\nThu, 22 Oct, 4-5pm\nJeff Waldman, Leanne Trimble, Leslie Barnes, & Lisa Strug\n(University of Toronto)\nPanel on data-focused resources at U of T\n\nThu, 29 Oct, 4-5pm\nFei Chiang (McMaster University)\nData currency and applications\n\nThu, 5 Nov, 4-5pm\nAndrew Whitby (Industry data scientist)\nCensuses\n\nMon, 9 Nov, 4-5pm\nTom Cardoso (Globe and Mail)\nBias Behind Bars\n\nThu, 12 Nov, 4-5pm\nKevin Armstrong (University of Toronto)\nMeasuring poverty for NGOs\n\nThu, 19 Nov, 4-5pm\nMichael Chong (University of Toronto)\nHigh-throughput Bayesian modelling workflow\nhttps://youtu.be/xM1vf_KT76g\nThu, 26 Nov, 4-5pm\nPostponed\n\n\nThu, 3 Dec, 5-6pm\nMonica Alexander (University of Toronto)\nUsing Facebook advertising data to estimate migration\nhttps://youtu.be/xM1vf_KT76g\nThu, 10 Dec, 4-5pm\nShabrina Mardevi (United Nations Population Fund &\nUniversity of Toronto) & Romesh Silva (United Nations\nPopulation Fund)\nPopulation data estimation\nhttps://youtu.be/kfmKusnGDLI\nThu, 17 Dec, 4-5pm\nLiza Bolton (University of Toronto), Maria Tackett\n(Duke University), Nathalie Moon (University of\nToronto), Teon Brooks (Mozilla Firefox)\nPanel on teaching data-focused topics\nhttps://youtu.be/c3R6pZisvm0\nThursday, 3 September 2020, 4-5pmSpecial guests Dean Wendy Duff (Faculty of Information) and\nDepartment Chair Radu Craiu (Department of Statistical\nSciences).Erik Drysdale (The Hospital for Sick Children)Erik works as a Machine Learning\nSpecialist at the Hospital for Sick Children (SickKids) for the\nGoldenberg Lab and AI in Medicine (AIM) initiative. His professional\nresponsibilities include the development and training of the machine\nlearning models for various pediatric data science projects. His\nresearch interests are focused on the intersection of statistics and\nmachine learning methods such as high-dimensional inference, survival\nanalysis, and optimization methods. Erik will talk about the challenges\nof applying ML in hospital data and why statistics still matters in\nML.\nTuesday, 8 September 2020, 3:30-4:30pmJointly hosted with Gillian Hadfield and the Schwartz Reisman Institute for\nTechnology and Society.Sophie Bennett (Industry data scientist)Sophie Bennett holds\nan undergraduate degree in Experimental Psychology from the University\nof Oxford and a PhD in Neuroscience from King’s College. She is the lead\ndata scientist at Up Learn, a London-based online learning platform\nspecialising in A levels. In this role, she conducts evaluations of\ncourse effectiveness and uses data to improve instruction and curriculum\ndesign. She is passionate about increasing the use of responsible\nevidence and statistics to guide social policy, and, in her spare time,\nenjoys working with publicly available datasets to explore London\ndemographics, social issues and infrastructure. Sophie will discuss A\nLevels, Ofqual and algorithms.\nThursday, 10 September 2020, 4-5pmToronto Data Lab launch event.A Mahfouz (University of Toronto)Diego Mamanche Castellanos (University of\nToronto)Hidaya Ismail (University of Toronto)Ke-Li Chiu (University of Toronto)Paul Hodgetts (University of Toronto)\nVarious Toronto Data Lab projects will be presented including\narxivdl, aRianna, cesR, and\nmore!\nThursday, 17 September 2020, 4-5pmAmber Simpson (Queen’s University)Dr. Simpson is the Canada Research\nChair in Biomedical Computing and Informatics and Associate Professor in\nthe School of Computing (Faculty of Arts and Science) and Department of\nBiomedical and Molecular Sciences (Faculty of Health Sciences). She\nspecializes in biomedical data science and computer-aided surgery. Her\nresearch group is focused on developing novel computational strategies\nfor improving human health. Dr Simpson will discuss cancer and AI.\nThursday, 24 September 2020, 4-5pmChelsea Parlett-Pelleriti (Chapman University)Chelsea is a PhD\ncandidate and full-time instructional faculty at Chapman University\nwhere her research focuses on using novel statistical and Machine\nLearning methods (mostly Bayesian statistics, IRT models, and\nclustering) to behavioral data. As an instructor she teaches Python, R\nand Data Science, and loves using novel technology (like TikTok, Twitch,\nand flipped classes) to better engage and inspire students. Chelsea will\ndiscuss talking to non-DS team members about DS topics.\nThursday, 1 October 2020, 4-5pmFlorence Vallée-Dubois (Université de Montréal)Florence Vallée-Dubois\nis a Ph.D. candidate at the department of political science of the\nUniversity of Montreal. She is also a member of the Centre for the Study\nof Democratic Citizenship and Canada Research Chair in Electoral\nDemocracy. Her research interests focus on Quebec and Canadian politics,\npolitical behaviour and quantitative methods. Her doctoral project\nfocuses on the political behaviour and democratic representation of\nseniors in Canada. Florence will discuss Canadian Demographics by\nElectoral Riding (1991-2015).\nThursday, 8 October 2020, 4-5pmYim Register (University of Washington Data Lab)Yim Register (they/them)\nis a radical optimist, child advocate, and PhD student at the University\nof Washington Data Lab exploring what self-advocacy looks like within\nmachine learning systems. They study how empowering novices with Data\nScience knowledge can impact their participation and joy in an AI-driven\nworld! Their passion project right now is writing a book called Life\nLessons from Algorithms, a book that teaches how machine learning\nalgorithms work through trauma recovery skills. Yim will discuss\nself-advocacy within machine learning systems.\nThursday, 22 October 2020, 4-5pmPanel discussion on data-focused resources at the University of\nToronto.Jeff Waldman (University of Toronto)Leanne Trimble (University of Toronto)Leslie Barnes (University of Toronto)Lisa Strug (University of Toronto)\nJeff Waldman is the Manager, Institutional Data Governance; Leslie\nBarnes is the Digital Scholarship Librarian at UTL; Leanne Trimble is\nthe Data and Statistics Librarian at UTL; Lisa Strug is a Senior\nScientist in the Program of Genetics and Genome Biology, Associate\nDirector of The Centre for Applied Genomics, Professor of Statistical\nSciences and Biostatistics at the University of Toronto, and Director of\nCANSSI Ontario.\nThursday, 29 October 2020, 4-5pmFei Chiang (McMaster University)Fei Chiang is an\nAssociate Professor in the Department of Computing and Software (Faculty\nof Engineering), the Director of the Data Science Research Group, and a\nFaculty Fellow at the IBM Centre for Advanced Studies. She served as an\ninaugural Associate Director of the MacData Institute. Her research\ninterests and industrial experience is in data management, spanning data\ncleaning, data quality, data privacy, data fusion, and database systems.\nProfessor Chiang will discuss data currency and its applications.\nThursday, 5 November 2020, 4-5pmAndrew Whitby (Industry data scientist)Andrew is a data scientist and\neconomist currently looking for his next challenge. He is particularly\ninterested in the economics of technology, creativity, innovation and\ngrowth. He wrote The Sum of the People: How the Census Has Shaped\nNations from the Ancient World to the Modern Age which was published in\nMarch 2020. Previously, he worked as a Data Scientist at the World Bank,\nand at Nesta, the UK’s innovation think tank. His academic background\ncombines economics, statistics and computer science. He completed his\ndoctoral research in the Department of Economics at the University of\nOxford. Andrew will discuss censuses.\nMonday, 9 November 2020, 4-5pmTom Cardoso (Globe and Mail)Tom\nCardoso is a crime and justice reporter and data journalist for The\nGlobe and Mail. Tom will discuss his Bias\nBehind Bars series of articles which show Black and Indigenous\ninmates in Canada are more likely to get worse scores than white\ninmates, based solely on their race.\nThursday, 12 November 2020, 4-5pmKevin Armstrong (University of Toronto)\nKevin Armstrong is a Masters of Information student at the University of\nToronto, and a data consultant for ‘Women’s Integrated Sexual Health’\n(WISH)\n- a three-year program delivering integrated health care in 16 countries\nin Africa and South Asia. Kevin will discuss methods for measuring\npoverty and use cases for NGOs.\nThursday, 19 November 2020, 4-5pmMichael Chong (University of Toronto)Michael is a PhD student\nin the Department of Statistical Sciences at the University of Toronto\nbuilding models for demographic estimation. Previously, he completed his\nBSc in Integrated Science at McMaster University. Michael will discuss\nlessons from a high-throughput Bayesian modelling workflow\nThursday, 26 November 2020, 4-5pmPostponed\nThursday, 3 December 2020, 5-6pmMonica Alexander (University of Toronto)Monica Alexander is\nan Assistant Professor in Statistical Sciences and Sociology at the\nUniversity of Toronto. She received her PhD in Demography from the\nUniversity of California, Berkeley. Her research interests include\nstatistical demography, mortality and health inequalities, and\ncomputational social science. Monica will talk about using Facebook\nadvertising data to estimate migration. A recording of the talk is\navailable here: https://youtu.be/xM1vf_KT76g.\nThursday, 10 December 2020, 4-5pmShabrina Mardevi (United Nations Population Fund and\nUniversity of Toronto)Romesh Silva (United Nations Population Fund)\nShabrina is a Masters of Information student at the University of\nToronto and a Population Data Estimation and Analysis Intern at the\nUnited Nations Population Fund. Romesh holds a PhD in Demography from\nthe University of California, Berkeley, and is a Technical Specialist,\nHealth & Social Inequalities, at the United Nations Population\nFund.\nThursday, 17 December 2020, 4-5pmPanel discussion on teaching data-focused topics.Liza Bolton (University of Toronto)Maria Tackett (Duke University)Nathalie Moon (University of Toronto)Teon Brooks (Mozilla Firefox)Liza\nBolton is an Assistant Professor, Teaching Stream, at the University\nof Toronto. Maria Tackett is\nan Assistant Professor of the Practice in the Department of Statistical\nScience at Duke University. Nathalie\nMoon is an Assistant Professor, Teaching Stream, University of\nToronto. Teon L. Brooks, holds a\nPhD in experimental psychology from NYU, and now works as a data\nscientist for Mozilla Firefox. He also\nserves as the technical advisor and President of BrainWaves, an NIH-funded\nproject to teach experimentation and cognitive neuroscience to high\nschool students in NYC, and has co-founded Computation in Education Labs\n(CIEL), a nonprofit that aims to\nfurther the mission of the BrainWaves project while focusing on data\nscience and computational thinking.\nSummer 2020\nThursday, 21 May 2020, 4-5pmRohan Alexander (University of Toronto,\nInformation)Rohan is a post-doctoral fellow at the\nFaculty of Information, University of Toronto. He holds a PhD in\nEconomics from the Australian National University. He will talk about\ngetting data from PDFs into R, with an application to the Kenyan\ncensus.\nThursday, 28 May 2020, 4-5pmShiro Kuriwaki (Harvard University, Government)Shiro is a Ph.D. Candidate\nat the Department of Government, Harvard University. His research\nfocuses on democratic representation in American Politics, for instance\ncast vote records, public opinion, survey methods, and applied\nstatistics more generally. Shiro will bring together best practices for\norganizing data and code in the social sciences that experts have\nproposed with some of his own experience. He will propose a\nproject-oriented workflow that adopts a minimal and consistent file\norganization structure within a single project, using RStudio Projects\nand GitHub. He will then discuss how to organize multiple projects that\nshare common components, and propose the use of custom R packages to\nshare code and Dataverse to share large datasets. He will use some of\nhis own projects involving the Cooperative Congressional Election Study\n(CCES), one of the largest political surveys of American Politics, as a\ndemonstration.\nRecording available here.\nThursday, 4 June 2020, 4-5pmMarija Pejcinovska (University of Toronto, Statistical\nSciences)\nMarija is a second-year Ph.D. student in Statistics at the University of\nToronto. Her research interests are in applied statistics, specifically\nthe application of Bayesian methods to data and modeling challenges that\narise in demography, public health, and certain areas of the social\nsciences. Marija will talk about a current project with the World Health\nOrganization (WHO) focused on estimating global maternal mortality to\nshare her R workflow and the different tools and packages she’s found\nhelpful in the data processing stage. More specifically, she’ll be\nsharing a few ways of dealing with text and date data in R.\nThursday, 11 June 2020, 4-5pmHarrison Jones (Deloitte)Harrison\nis a Manager at Deloitte in Toronto, where he focuses on data analytics\nand machine learning in the property & casualty insurance, life\ninsurance, health insurance, pensions, and the public sector. Harrison\nwill talk about using R with actuarial data.\nThursday, 18 June 2020Cancelled in support of the Black Lives Matter movement\nand to provide an opportunity for reflection and learning. We also announced\nstipends in support of University of Toronto students or recent\ngraduates who identify as a member of a visible minority group,\nracialized group, or as a person of colour.\nThursday, 25 June 2020, 4-5pmA Mahfouz (University of Toronto, Information)\nA is a Master of Information student at the University of Toronto with a\nbackground in geography. Their prior work has been largely concerned\nwith data pipelines. A will talk about geographic data cleaning,\nextracting mappable data from Google Directions API results in\nPython.\nSlides available here.\nThursday, 2 July 2020, 4-5pmHeather McBrien (University of Toronto, Statistical\nSciences)\nHeather just graduated from the Statistics BSc program at the University\nof Toronto, and is interested in modelling in population health\nresearch, particularly using novel data sources to answer questions\nwhere traditional data is lacking. Heather will talk about how the data\nthat we collect can bias the results that we obtain and our knowledge of\nthe problem.\nSlides available here.\nThursday, 9 July 2020, 4-5pmRoxanne Chui (University of Toronto, Information)\nRoxanne is an emerging anthropological data science professional. She\ndid her BSc program in Forensic anthropology and worked in the\npharmaceutical industry before doing her Masters in data science. She is\npassionate about excavating context from data for predicting future\npatterns of human behaviour. Roxanne will talk about an EDA approach to\nTokyo AirBnB datasets and pattern discovery in listing prices using R -\n‘What do we have here among millions of observations?’\nSlides available here.\nThursday, 16 July 2020, 4-5pmCasey Breen (University of California, Berkeley,\nDemography)\nCasey is a PhD student in the Demography Department at Berkeley. He\npreviously worked at the Institute for Social Research and Data\nInnovation, home of IPUMS. Casey will talk about CenSoc, which is a project to\nlink 1940 Census data with Social Security Administration mortality\nrecords in the US.\nThursday, 23 July 2020, 11am-noonMarta Kołczyńska (Institute of Political Studies of the\nPolish Academy of Sciences)Marta is an Assistant\nProfessor at the Institute of Political Studies of the Polish Academy of\nSciences and a visiting researcher in the Probabilistic Machine Learning\nGroup, Department of Computer Science, Aalto University. Her research\ninterests include comparative analyses of political attitudes and\nbehavior across nations and over time, as well as the methodology of\ncomparative research, in particular cross-national surveys. Marta will\ntalk about cleaning survey data, in particular a project in which she\ngathers political trust items from different cross-national survey\ndatasets to model time trends, and the tools she has developed to\nfacilitate this work.\nThursday, 30 July 2020, 4-5pmAlex Luscombe (University of Toronto, Criminology and\nSociolegal Studies)Alexander McClelland (Carleton University, Criminology\nand Criminal Justice)Alex Luscombe is a PhD student in\nthe Centre for Criminology & Sociolegal Studies at the University of\nToronto and a Junior Fellow at Massey College. Alexander McClelland is\nan Assistant Professor at the Institute of Criminology and Criminal\nJustice, Carleton University. They will talk about Policing the Pandemic,\nwhich is a project that was launched on 4 April, 2020, to track and\nvisualize the massive and extraordinary expansions of police power in\nresponse to the COVID-19 Pandemic and the unequal patterns of\nenforcement that may arise as a result.\nSlides available here.\nThursday, 6 August 2020, 4-5pmSharla Gelfand (Freelance R Developer)Sharla is a freelance R developer\nspecializing in enabling easy access to data and replacing manual,\nredundant processes with ones that are automated, reproducible, and\nrepeatable. They will talk about creativity in R. Slides available here.\nThursday, 13 August 2020, 4-5pmRichard Iannone (R Studio)Rich is a Software Engineer at R\nStudio. Rich will talk about pointblank,\nwhich is an R package that allows workflows involving nice and easy data\nvalidation in reproducible documents.\nThursday, 20 August 2020, 4-5pmAije Egwaikhide (IBM)\nAije Egwaikhide holds an undergraduate degree in Economics and\nStatistics from the University of Manitoba, and a post-graduate degree\nin Business Analytics from St. Lawrence College, Kingston. She works at\nIBM where she is a Lead Data Scientist on the System Enablement group.\nAije will talk about preparing data for optical character recognition\n(OCR).\nWinter 2020\nNoon, Friday, 24 January 2020Steven\nPimentel (U of T, business intelligence)\nNoon, Friday, 31 January 2020Arik\nSenderovich (U of T, Information)\nNoon, Friday, 7 February 2020Kathy\nChung (U of T, Records of Early English Drama)\nNoon, Friday, 14 February 2020Josh\nHarris (KOHO)\nNoon, Friday, 28 February 2020Eugene Joh\n(St. Michael’s Hospital)\nNoon, Friday, 6 March 2020Fatemeh\nNargesian (University of Rochester, Computer Science)\nFall 2019\nNoon, Thursday, 26 September 2019Periklis Andritsos\n(ODAIA & U of T, Information)\nNoon, Thursday, 10 October 2019Hassan Teimoori\n(Deloitte, Omnia AI)Ludovic Rheault (U of\nT, Political Science)\nNoon, Wednesday, 16 October 2019Lauren\nKennedy (Columbia University)\nNoon, Thursday, 24 October 2019Sharla Gelfand (Freelance R and\nShiny developer)\nNoon, Thursday, 7 November 2019Maria D’Angelo\n(Delphia)Hareem Naveed\n(Munich Re)\nNoon, Thursday, 21 November 2019Michelle\nAlexopoulos (U of T, Economics)Paraskevi\nMassara (U of T, Medicine)\nIf you would like to receive invitations to the series, then you can\nsubscribe here.\n\n\n\n",
      "last_modified": "2022-05-02T13:00:37-04:00"
    }
  ],
  "collections": ["posts/posts.json"]
}

---
title: "Foundations of data sciences"
description: |
  The data sciences have a common concern: How can others be confident that our statistical approaches have been brought to bear on appropriate datasets? This course focuses on the 'data' of the data sciences. It develops in students an appreciation for the many ways in which dealing with a dataset can get out-of-hand, and establishes approaches to ensure data science is conducted in ways that engenders trusted findings.
output:
  distill::distill_article:
    toc: true
    toc_depth: 3  
---

## Preamble 

### Overview

The course will be an enormous amount of work and cause you some amount of stress. This is unfortunate, but there's little way around it. All I can tell you is that having done this course, it'll be easier in the future.

The purpose of this course is to develop students who appreciate, and can iterate on, the foundations of the data sciences.

This course will require students to:

- actively read and consider a large amount of literature;
- actively learn the statistical programming language R and apply it to real-world conditions;
- gather, clean, and prepare their own datasets; and
- develop killer statistics skills.

Essentially this course provides students with everything that they need to know to be able to do the most exciting thing in the world: use data to tell convincing stories.


### FAQ

- Can I audit this course? Sure, but it's pointless, because the only way to learn this stuff is to do the work.
- What is a tutorial? You write a paper. Then you send it to your tutor. The next day you have a meeting, 'tutorial', where you discuss it with them.
- Why is there so much assessment? The only way to learn is to actually do the work, and students only do the work when they are assessed. It's unfortunate, but there's no way around it.

### Learning objectives

The purpose of the course is to develop the core skills common to all of the data sciences across academia and industry. By the end of the course, you should be able to:

1. Engage critically with ideas and readings in data science.
2. Conduct research in data science in a reproducible and ethical way.
3. Write and present your research.
4. Understand what constitutes ethical high-quality data science practice, especially reproducibility and respect for those that underpin our data.
5. Respectfully identify strengths and weaknesses in the data science research conducted by others.
6. Develop the ability to appropriately choose and apply statistical models to real-world situations.
7. Conduct all aspects of the typical data science workflow including deployment.
8. Reflect effectively on your own learning and professional development.

### Pre-requisites

- None.


### Textbook

Alexander, 2022, *Telling Stories with Data*, CRC Press.



## Content

### Week 1

'Drinking from a fire hose'.

- Content:
  - Several end-to-end worked examples, and develop essential skills in R.

### Week 2

'Science-ing'.

- Content: 
  - Establish a workflow for data sciences, including R Markdown, R Projects, Git and GitHub. 
  - Put in place a framework for writing papers.

### Week 3

'Communicating'.

- Content: 
  - How to effectively use graphs, tables, and maps.
  - How to make a website and use Shiny.

### Week 4

'Gathering data'.

- Content: 
  - Using APIs, scraping, OCR, semi-structured datasets, and text.

### Week 5

'Hunting data'.

- Content: 
  - Experiments, sampling and surveys, and A/B testing.

### Week 6

'Cleaning data'.

- Content: 
  - Workflow for cleaning data. 
  - Effective naming, checks, and testing.

### Week 7

'Store, retrieve, disseminate and protect'.

- Content: 
  - R packages for data, and documentation including datasheets.

### Week 8

'Share, but not too much'.

- Content: 
  - Personally identifying information, hashing and salting, GDPR and HIPPA, simulated data, and differential privacy.


### Week 9

'Whoops, I forgot EDA'.

- Content: 
  - Coming to terms with a dataset and understanding what is in it.

### Week 10

'IJALM - It's Just A Linear Model'.

- Content: 
  - Simple linear regression, multiple linear regression, logistic regression, Poisson regression.

### Week 11

'Lorem ipsum'.

- Content: 
  - Dealing with text-scale datasets and trying to make sense of them using statistical approaches.

### Week 12

'Deployment'

- Content: 
  - R packages for models, Shiny, and Plumber and model APIs


## Assessment

### Summary


| Item 								| Weight (%) | Due date |
| ------------- | -------------:| -----:|
| Weekly quiz 						| 10 		 | Weekly before the lecture |
| Tutorial 						| 10 		 | Weekly before the lecture |
| Professional conduct			| 1 		 | Anytime during the teaching term |
| Paper 1 							| 25 		 | End of Week 3 |
| Paper 2 							| 25 		 | End of Week 6 |
| Paper 3 							| 25 		 | End of Week 9 |
| Final Paper (initial submission)  | 1 		 | End of Week 12 |
| Final Paper (peer review) 		| 3 		 | Three days after that |
| Final Paper 						| 25 		 | Ten days after that |



### Weekly quizzes

- Due date: Weekly before the lecture.
- Weight: 10 per cent (only best eight out of twelve count.)
- Task: Please complete a weekly quiz in Quercus.
- Questions: The questions that form the quiz are drawn from those in the Quiz sections of *Telling Stories with Data*.


### Tutorial

- Due date: Weekly before the lecture.
- Weight: 10 per cent (only best five out of twelve count.)
- Task: Please complete a tutorial question and submit it via Quercus.
- Questions: Tutorial questions are drawn from those in the Tutorials sections of *Telling Stories with Data*.


### Professional conduct

- Due date: Anytime during the teaching term.
- Weight: 1 per cent
- Task: We (optionally) use Slack to interact in this class. At some point during the teaching term, please use Slack to answer another student's question or otherwise similarly be generally helpful in a professional manner. When you do that, please share the comment into the 'Professional conduct' channel and @ me (hover on the message, click share message, type in the channel 'profession_conduct', add a message that @'s me, and click 'share'). You'll get the full mark just for one helpful interaction. (If you are opting out of using Slack - which is entirely fine - then instead, at some point in the term send me an email with a link that is relevant to the course materials and that I should add to the course notes. Please be clear that this is your 'professional conduct' submission by stating that in the subject line.)


### Paper #1

- Due date: End of Week 3.
- Weight: 25 per cent (for Papers #1-#3 the best two of three count).
- Task: ['Mandatory minimums'](https://www.tellingstorieswithdata.com/papers.html#mandatory-minimums)



### Paper #2

- Due date: End of Week 6.
- Weight: 25 per cent (for Papers #1-#3 the best two of three counts).


### Paper #3

- Due date: End of Week 9.
- Weight: 25 per cent (for Papers #1-#3 the best two of three counts).



### Final Paper

- Due dates: 
  - Initial submission: End of Week 12.
  - Peer review: Three days after that.
  - Final Paper: Ten days after that.
- Weight: 29 per cent (4 per cent of this is for initial submission and peer review conducted a week before).
  - Initial submission: 1 per cent
  - Peer review: 3 per cent
  - Final Paper: 25 per cent




---
title: "INF2178: Experimental Design"
description: |
  INF2178 is a masters-level course at the University of Toronto's Faculty of Information.
output:
  distill::distill_article:
    toc: true
    toc_depth: 3  
---

**The following is tentative. There will be major changes through to 11 January 2021, and minor changes after that.**

## Preamble

### Syllabus

**TBA - released on 11 January 2021.**

### Overview

Experimental design has a long and robust tradition within traditional applications such as agriculture, medicine, physics, and chemistry. It allows us to speak of causality with confidence. Typically, these are situations in which control groups can be established, randomization is appropriate, and ethical concerns can be assuaged. Unfortunately, such a set-up is rarely possible in the full extent of the modern applications where we want to understand causality.

```{r  out.width = "40%"}
knitr::include_graphics("https://imgs.xkcd.com/comics/statistics.png")
```
Source: https://xkcd.com/2400/

This course covers the traditional approaches and statistical methods, but focuses on what to do when traditional experimental design methods cannot be implemented or are not appropriate (i.e. what feels like most of the time these days). We cover experiments in their modern guise especially the concerns that we might have when we can run them; but also methods that can provide some causal understanding even when we cannot conduct traditional experiments. Importantly, these approaches do not rely on 'big data' or fancy statistics, but instead on thoroughly interrogating the data that are available to get understanding through as simple means as possible.

This is a hands-on course in which you will conduct research projects using real-world data. This means that you will: obtain and clean relevant datasets; develop your own research questions; use the statistical techniques that you are introduced to in class to answer those questions; and finally communicate your results in a meaningful way. This course is designed around approaches that are used extensively in academia, government, and industry. Furthermore, it includes many aspects, such as data cleaning and preparation, that are critical, but rarely taught. 

This course is different to many other courses at the University of Toronto. At the end of this course, you will have a portfolio of work that you could show off to a potential employer. You will have developed the skills to work successfully as an applied statistician or data scientist. And you will know how to fill gaps in your knowledge yourself.



### How to succeed

In this course you will work in a self-directed, open-ended manner. Identify relevant areas of interest and then learn the skills that you need to explore those areas. 

To successfully complete this course, you should spend all your time reading and writing (both code and text). Deeply engage with the materials. Find a small study group and keep each other motivated and focused. At the start of the week, read the course notes, all compulsory materials and some recommended materials based on your interest. After doing that, but before the 'lecture' time you should complete the weekly quiz. During 'lectures' I'll live-code, discuss materials in the course notes, talk about an experiment, and you'll have a chance to discuss the materials with me. 

You need to be more active in your learning in this course than others - read the notes and related materials - and then go out there and teach yourself more and apply it. You will not be spoon-fed in this course. Each week try to write reproducible, understandable, R code surrounded by beautifully crafted text that motivates, backgrounds, explains, discusses and criticizes. Make steady progress toward the assessment. This is not a 'bird course'. Similar courses that I've taught in past have a dropout/failure rate of 17-52 per cent.


### How we'll work

This webpage will provide almost all the guiding materials that you need and links to the relevant parts of the notes. The course notes are available here: https://www.tellingstorieswithdata.com. Those contain notes and other material that you could go over. There is a course Slack for discussion. We'll use Quercus really only for assessment submission and grading. I expect you to work professionally, and so we'll try to use professional tools to the extent possible. 


### Advice from past students

Successful past students have the following advice (completely unedited by me):

- 'Start reading and writing on a weekly basis, watch some videos on R and RMD but more importantly learn how to use Google.'
- 'Start early, find a group of people you trust enough to divide the work up fairly. Let people work to their strengths (people who know R should do the modelling, good writers should write most of the reports, etc.)'
- 'Not to worry if you don't do well on the first problem set—the nature of the course is to build up skills overtime, and it's meant to be challenging in the beginning. In the end, it is worth it because you learn very valuable applicable skills on how to write professional reports.'
- 'Work on your writing and direction following skills.'
- 'Look at the rubric. There were times that I lost marks because I didn't follow the rubric properly. Go to office hours, they are very useful as you can ask your own question and also get answers to questions other people ask and you didn't think of. Also, do the assignments to the best of your ability. You will lose marks if you don't put in effort and the only person you're hurting is yourself.'
- 'During lectures, focus more on the why the prof is doing what he's doing. When he runs certain commands in R, figure out why that sequence of code gives what you want, because it'll help adapt his code into your assignment code. just remembering what he's doing in lecture becomes useless really quickly since the thought process matters more. also, start everything early. '
- 'Do this course when you really want to learn something and have a lot of time to working on it.'
- 'you need to be very skillful in RStudio and latex. Otherwise you would be struggling.'
- 'Try to incorporate the feedback given and read a looottttttttt. Also start early on the problem sets because they tend to take a lot of time. Don’t give up!'
- 'Find a good group for problem sets'
- 'If the assignments stay the same, I would tell students to approach this class from the perspective of 'storytelling with statistics' rather than a statistics course. You need to use R, and Markdown, and have a solid understanding of concepts like regression and sampling, but more importantly you need to be able to interpret results and write about them in a way coherent and professional way.'
- 'do your readings'
- 'Definitely get ready to write reports'




## Content

**The following is tentative and will update as we go through the term. Weeks 11 and 12 will be adjusted to make space for the content in earlier weeks to the extent necessary.**

Each week you should go through the course notes and all compulsory materials. During the lecture I will live-code various aspects. I will also discuss a case study, typically a paper. During the lab, a TA will either lead small group discussions or similarly lead other work. The lecture will be recorded and posted here, but again, it's not enough to just watch that - you need to read and write yourself.

### Week 1

12 January 2021, 'Drinking from a fire hose'.

- Lecture: [Hello world!](https://www.tellingstorieswithdata.com/01-02-hello_world.html), [R Essentials](https://www.tellingstorieswithdata.com/01-03-r_essentials.html), [R Desirables](https://www.tellingstorieswithdata.com/01-04-r_desirables.html), [Graphs and Tables](https://www.tellingstorieswithdata.com/02-01-graphs.html).
- Case Study: [Fisher's Lady Tasting Tea](https://www.tellingstorieswithdata.com/03-05-rcts.html#case-study---fishers-tea-party).
- Lab: Go through DoSS Toolkit 'White' and 'Yellow' and discuss any issues with the TA.


### Week 2

19 January 2021, 'Science-ing'.

- Lecture: Writing, https://www.tellingstorieswithdata.com/01-06-workflow.html, https://www.tellingstorieswithdata.com/01-05-reproducibility.html.
- Case Study: Tuskegee Syphilis Study.
- Lab: Go through DoSS Toolkit 'Green' and discuss any issues with the TA.

### Week 3

26 January 2021, 'Why, if ever I did fall off---which there's no chance of---but if I did--'.

- Lecture: Experiments, and treatment effects.
- Case Study: The Oregon Health Insurance Experiment in the United States (https://www.povertyactionlab.org/evaluation/oregon-health-insurance-experiment-united-states)
- Lab: 
  - Please pretend that you work as a junior analyst for a large consulting firm. Further, pretend that your consulting firm has taken a contract to put together a facial recognition model for the Canada Border Services Agency’s Inland Enforcement branch. Write five or six points with regard to your thoughts on this matter. What would you do and why? Then split into small groups and compare your points with others. Do you think the model would end up being implemented?
  - With the help of the TA, please conduct 'face-to-face' surveys (via Zoom). For this exercise, you will be randomly split into groups of two. You have two minutes in each group and will then be swapped to another group. One person is to survey the other person asking the following questions: i) 'What is your gender?', ii) 'What is your age?', iii) 'What is your marital status?', iv) 'What is your income?', v) 'If an election were held today who would you vote for?'. After one person is done, then switch roles. When you are the questioner you should record all responses using a small CSV (but not the person's name please). When you are the respondent you are welcome to not respond. You will cycle through this multiple times. At the end, please write a small reflection about: 1) as a respondent, how you felt answering these questions and the implications that you think this feeling may have for how survey questions are answered more generally; and 2) as a questioner, how difficult it was to code responses and the implications this may have for the dataset that we analyse.


### Week 4

2 February 2021, '(Data) hunter-gatherer'.

- Lecture: [Scraping](https://www.tellingstorieswithdata.com/03-02-scraping.html), surveys, open data, etc.
- Case Study: Student Coaching: How Far Can Technology Go? (https://www.povertyactionlab.org/evaluation/student-coaching-how-far-can-technology-go)
- Lab: 
  - Please pretend you work for Netflix and you want to know more about why people subscribe (or don't!) when prices change. Please design an experiment, discuss its key features and how you would implement it. Please pay special attention to sampling issues. Then simulate an outcome.
  - Following the guidance of the TA, please scrape some data and discuss some ethical considerations around the dataset that you created. You may like to write a short blog post discussing the difference between data being public but scattered, and a consolidated dataset being public with reference to Kirkegaard and Bjerrekær, 2016, and Politou, Alepis, and Patsakis, 2018 (if you do that please do email a link to me out of interest).


### Week 5

9 February 2021, 'IJALM - It's Just A Linear Model'.

- Lecture: Linear and logistic regression and `tidymodels`
- Case Study: Alain Cohn, Michel André Maréchal, David Tannenbaum, Christian Lukas Zünd, 2019, 'Civic honesty around the globe'
- Lab: 
  - Pretend that you work for Loblaws as a data scientist and it is late March 2020. As part of normal monitoring, you have noticed that purchases of flour and pasta have increased substantially. You had been planning to increase the price of these items in April as part of a trial, but now your manager is not sure whether it is appropriate to conduct the trial. Please write five or six points with regard to your thoughts on this matter. What would you do and why? 
  - Analyse the Toronto AirBNB dataset with guidance from the TA.
  

### Reading Week

```{r  out.width = "60%"}
knitr::include_graphics("images/book_week.jpg")
```

### Week 6

23 February 2021, 'Celestial Navigation'.

- Lecture: Simulation, power, RCTs and A/B testing.
- Case Study: Upworthy A/B tests of headlines.
- Lab: 
  - Following the guidance of the TA, please use Blogdown to create a simple website and then design and execute a simple A/B test for your website using Netlify.
  
  

### Week 7

2 March 2021, 'Post Hoc, Ergo Propter Hoc'.

- Lecture: DAGs, confounding, selection bias, and measurement bias. Factorial designs, Latin Squares, blocking, and the other classics. Simpson's paradox, Berkson's paradox.
- Case Study: Joshua Kalla and David Broockman, 2016, 'Campaign Contributions Facilitate Access to Congressional Officials: A Randomized Field Experiment'
- Lab: 
  - Following the guidance of the TA, please look back on the case studies that we've covered so far. Please break up into small groups and create DAGs for each. Then write some notes about the potential for confounding, selection bias and measurement bias. Pick one person in your group to make a brief 2-minute presentation about what you did.

### Week 8

9 March 2021, 'Such a shame they'll never meet'.

- Lecture: Diff in diff and regression discontinuity.
- Case Study: Tamar Oostrom, 2020, 'Funding of Clinical Trials and Reported Drug Efficacy'
- Lab: 
  - Following the guidance of the TA, please read McClelland, Alexander, 2019, '"Lock This Whore Up": Legal Violence and Flows of Information Precipitating Personal Violence against People Criminalised for HIV-Related Crimes in Canada', *European Journal of Risk Regulation*, 10 (1), pp. 132-147. Then look at Policing the Pandemic - https://www.policingthepandemic.ca/. Look into how they gathered their dataset and what it took to put this together. What is in the dataset and why? What is missing and why? How could this affect the results? How might similar biases enter into other datasets that you have used or read about? Put together a brief model. You may like to write a short blog post about the biases and influences that are in this dataset (if you do that please do email a link to me out of interest). 


### Week 9

16 March 2021, 'Why does it always rain on me?'.

- Lecture: Instrumental variables.
- Case Study: James H. Ware, 1989, 'Investigating Therapies of Potentially Great Benefit: ECMO'.
- Lab: 
  - Following the guidance of the TA, please read and discuss: Pouwels, Koen B, Thomas House, Emma Pritchard, Julie V Robotham, Paul J Birrell, Andrew Gelman, Karina-Doris Vihta, Nikola Bowers, Ian Boreham, Heledd Thomas, James Lewis, Iain Bell, John I Bell, John N Newton, Jeremy Farrar, Ian Diamond, Pete Benton, Ann Sarah Walker, and COVID-19 Infection Survey team, 2020, 'Community prevalence of SARS-CoV-2 in England during April to November 2020: Results from the ONS Coronavirus Infection Survey', *The Lancet Public Health*, December 10, https://www.thelancet.com/journals/lanpub/article/PIIS2468-2667(20)30282-6/fulltext. 


### Week 10

23 March 2021.

- No lecture or lab. In class test administered via Quercus (available for 24 hours).



### Week 11

30 March 2021, 'But it works on my machine'.

- Lecture: Shiny, cloud, and deploying into production.
- Case Study: Alexander, M., Wildeman, C., Roehrkasse, A., and Rudlang-Perman, K., 2020, 'Forecasting child welfare outcomes in the United States', [Shiny app](https://monica-alexander.shinyapps.io/foster_care/); [Technical model summary](https://www.monicaalexander.com/pdf/fc.pdf).
- Lab: 
  - Following the guidance of the TA, and thinking about what we covered in lectures, please read, compare, and discuss:
    - Bendavid, E., Mulaney, B., Sood, N., Shah, S., Ling, E., Bromley-Dulfano, R., …, and Tversky, D, 2020, ‘COVID-19 Antibody Seroprevalence in Santa Clara County, California’, *MedRxiv*, https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf.
    - Gelman, Andrew, 2020, ‘Concerns with that Stanford study of coronavirus prevalence’, Statistical Modeling, Causal Inference, and Social Science, 19 April, https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/. 
    - Eisen, Michael B., and Robert Tibshirani, 2020, 'How to Identify Flawed Research Before It Becomes Dangerous', *New York Times*, 20 July, https://www.nytimes.com/2020/07/20/opinion/coronavirus-preprints.html. 
    - Gelman, Andrew and Bob Carpenter, 2020, 'Bayesian analysis of tests with unknown specificity and sensitivity', 8 July, http://www.stat.columbia.edu/~gelman/research/published/specificity.pdf. 

### Week 12

6 April 2021, 'Lorem ipsum'.

- Lecture: Text-as-data.
- Case Study: Kevin Munger, Patrick Egan, Jonathan Nagler, Jonathan Ronen, and Joshua A. Tucker, 2017, 'Political Knowledge and Misinformation in the Era of Social Media: Evidence From the 2015 UK Election'.
- Lab: 
  - Please form small groups and discuss, 'to what extent do quantitative methods merely project forward the past, and what implications does this have for our conduct as practitioners and consumers?'
  - Following the guidance of the TA, please make an R package that bundles a little data and some code and add it to your GitHub.




## Assessment

### Summary


| Item 								| Weight (%) | Due date |
| ------------- | -------------:| -----:|
| Weekly quiz 						| 10 		 | Weekly before the lecture |
| Professional conduct			| 1 		 | Anytime during the teaching term |
| Paper 1 							| 25 		 | 29 January 2021 |
| Paper 2 							| 25 		 | 12 February 2021 |
| Paper 3 							| 25 		 | 12 March 2021 |
| Test 								| 10 		 | 23 March 2021 |
| Final Paper (initial submission)  | 1 		 | 9 April 2021 |
| Final Paper (peer review) 		| 3 		 | 12 April 2021 |
| Final Paper 						| 25 		 | 19 April 2021 |



### Weekly quizzes

- Due date: Weekly before the lecture.
- Weight: 10 per cent (no quiz in Week 1 or Week 10)
- Task: Please complete a weekly quiz in Quercus.
- Questions: The questions that form the quiz are drawn from those in the course notes.

### Professional conduct

- Due date: Anytime during the teaching term.
- Weight: 1 per cent
- Task: We (optionally) use Slack to interact in this class. At some point during the term, please use Slack to answer another student's question or otherwise similarly be generally helpful in a professional manner. When you do that, copy the link (hover on the comment, click the vertical dots, click 'copy link') and submit the link via Quercus. You'll get the full mark just for one helpful interaction. (If you are opting out of using Slack - which is entirely fine - then instead, at some point in the term send me an email with a link that is relevant to the course materials and that I should add to the course notes. Please be clear that this is your 'professional conduct' submission by stating that in the subject line.)


### Paper #1

**Tentative - finalised on 11 January 2021.**

#### Essentials

- Due date: 29 January 2021.
- Weight: 25 per cent (for Papers #1-#3 the best two of three count).

#### Task

- Working individually, please find a dataset of interest on Open Data Toronto and download it in a reproducible way using the R package `opendatatoronto`. 
- Create a folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using `R Markdown` with these sections: title, author, date, abstract, data, and references. If you'd like, you are welcome to use this starter folder: https://github.com/RohanAlexander/starter_folder.
- In the data section thoroughly and precisely discuss the source of the data and the bias this brings (ethical, statistical, or otherwise). Comprehensively describe and summarize the data using text and at least one graph and one table. Graphs must be made in `ggplot` and tables must be made using `gt.` Make sure to cross-reference both of those in the text. 
- Do not include any R code or raw R output in the PDF.
- Use bibtex to add references. Be sure to reference R and any R packages you use as well as the dataset. Check that you have referenced everything. Strong submissions will draw on related literature and would be sure to also reference those. There are various options in R Markdown for references style, and just pick one that you are used to.
- Go back and write an introduction. This should be two to three paragraphs. The last paragraph should lay-out the remainder of the paper.
- Add an abstract. This should be three or four sentences long. And then add a descriptive title (Hint: 'Paper 1' is not descriptive.)
- Add a link to your GitHub repo via a footnote.
- Check that your GitHub repo is well-organized, and add an informative README. (Hint: Comment. Your. Code.).
- Pull this all together as a PDF and check that the paper is well-written and able to be understood by the average reader of, say, FiveThirtyEight. This means that you are allowed to use mathematical notation, but you must explain all of it in plain language. All statistical concepts and terminology must be explained.
- Check that your graph and discussion are extremely clear, and of comparable quality to those of FiveThirtyEight.
- Check that the date is updated.
- Your entire workflow must be entirely reproducible.
- There should be no evidence that this is a class assignment.
- Via Quercus, submit the PDF.


#### FAQ

- Can I use a dataset from Kaggle instead? No, because too many people use Kaggle datasets so employers are sick of them.
- I can't use code to download my dataset, can I just manually download it? No, because your entire workflow needs to be reproducible. Please fix the download problem or pick a different dataset.
- How much should I write? Most students submit something in the two-to-six-page range, but it's really up to you. Be precise and thorough.
- My data is about apartment blocks/NBA/League of Legends so there's no ethical or bias aspect, what do I do? Please re-read the readings to better understand bias and ethics. If you really can't think of something, then it might be worth picking a different dataset.
- Can I use Python? No. If you already know Python then it doesn't hurt to learn another language.
- Why do I need to cite R, when I don't need to cite Word? R is a free statistical programming language with academic origins so it's appropriate to acknowledge the work of others. It's also important for reproducibility.


### Paper #2

**Tentative - finalised on 29 January 2021.**

#### Essentials

- Due date: 12 February 2021
- Weight: 25 per cent (for Papers #1-#3 the best two of three counts).

#### Task

- Please consider this scenario: 'You are employed as a junior data scientist at Petit Poll - a Canadian polling company. Petit Poll has a contract with a 'client' - an Ontario government department - to provide them with advice. In particular, the client wants to understand the effect of COVID shut-downs on restaurant businesses and has asked Petit Poll to design an experiment where some restaurants are shutdown.'
- Working as part of a team of 1-4 people, prepare a PDF in R Markdown with the following features: title, author/s, date, abstract, introduction, a data section that specifies the intervention and data gathering methodology, discussion, and references. In the discussion section and any other relevant section, please be sure to discuss ethics and bias with reference to relevant literature.
- Decide on an intervention. Some aspects to address include:
  - How will it be designed and implemented?
  - What will be random about it?
  - How will you ensure the separation of treatment and non-treatment?
  - How long will it run?
- Decide on a survey methodology. Some aspects to address include: 
  - What is the population, frame, and sample? 
  - What sampling methods will you use and why? What are some of the statistical properties that the method brings to the table? 
  - How are you going to reach your desired respondents?
  - How much do you estimate this will cost?
  - What steps will you take to deal with non-response and how will non-response affect your survey? 
  - How are you going to protect respondent privacy? 
- Remember to consider all of this in the context of your 'client' - for instance, what are they interested in?
- Develop a survey on a platform that was introduced in class. Be sure to test it yourselves. You will want to test this as much as possible, maybe even swap informally with another group?
- Now release the surveys into the (simulated) 'field'. Please do this by simulating an appropriate number of responses to your survey in R. Don’t forget to simulate in relation to the intervention that you proposed. Do you need two, or even more, surveys? Show the results and discuss your 'findings'. Everything must be entirely reproducible.
- You may wish to scrape some data and/or use open data sources to appropriately parameterize your simulations. Don't forget to cite them when you do this.
- Use R Markdown to write a PDF report about all of this. Discuss your intervention, results and findings, your survey design and motivations, etc - all of it. You are writing a report that will eventually go to the client, so you must set the scene, and use language that demonstrates your command of statistical concepts but brings the reader along with you. Be sure to include graphs and tables and reference them in your discussion. Be sure to be clear about weaknesses and biases, and opportunities for future work. 
- Your report must be well written. You are allowed to, and should, use mathematical notation, but you must explain all of it in plain language. Similarly, you can, and should, use experimental/survey/sampling/observational data terminology, but again, you need to explain it. 
- Your client has stats graduates working for it who need to be impressed by the main content of the report, but also has people who barely know what an average is and these people need to be impressed also. 
- Your graphs must be of an extremely high standard.
- Check that you have referenced everything, including R, R packages, and datasets. Strong submissions will draw on related literature and would be sure to also reference those. The style of references does not matter, provided it is consistent.
- Via Quercus, submit your PDF report. You must provide a link to the GitHub repo where the code that you used for this assignment lives (hint: Comment. Your. Code.). Your entire workflow must be entirely reproducible. Your repo should be clearly organised and a useful README included. And you must include the R Markdown file that produced the PDF in that repo.
- Please be sure to include a link to your survey/s in your report and screenshots of the survey/s in the appendix of your report. 
- Everyone in the team receives the same mark.
- There should be no evidence that this is a class assignment.


#### FAQ

- Can I work by myself? Yes. But I recommend forming a group and the workload for the course assumes you'll work on the second and third paper as part of a group of four.
- Can we switch groups for the third paper? Yes.
- How can I find a group? On 30 January 2021 I will randomly create groups of four in Quercus. You are welcome to shift out of those groups and form your own groups if you'd like.
- Can I get a different mark to the rest of my group? No. Everyone in the group gets the same mark.
- I wrote my paper by myself, so can I be graded on a different scale? No. All papers are graded in the same way.



### Paper #3

**Tentative - finalised on 19 February 2021.**

#### Essentials

- Due date: 12 March 2021
- Weight: 25 per cent (for Papers #1-#3 the best two of three counts).

#### Task

- Working as part of a team of 1-4 people, prepare a PDF in R Markdown with the following features: title, author/s, date, abstract, introduction, data, model, results, discussion, and references. In the discussion section and any other relevant section, please be sure to discuss ethics and bias with reference to relevant literature.
- You should reproduce one of the following papers:
  - Liran Einav, Amy Finkelstein, Tamar Oostrom, Abigail Ostriker, Heidi Williams, 2020, 'Screening and Selection: The Case of Mammograms', *American Economic Review*.
  - Pons, Vincent, 2018, 'Will a Five-Minute Discussion Change Your Mind? A Countrywide Experiment on Voter Choice in France' *American Economic Review*.
  - **Others TBA**
  - If you have a favourite paper and want to reproduce it, then please submit it to me for consideration before Reading Week.
- You should follow the lead of the author/s of the paper you're reproducing, but thoroughly think about, and discuss, what is being done. Regardless of the particular model that you are using, and the (possibly lack of) extent to which this is done in the paper, your model must be well explained, thoroughly justified, explained as appropriate to the task at hand, and the results must be beautifully described.
- You must include a DAG (probably in the model section).
- You must have a discussion of power and experimental design (probably in the data section)
- Your paper must be well-written, draw on relevant literature, and show your statistical skills by explaining all statistical concepts that you draw on. 
- You are welcome to use appendices for supporting, but not critical, material. Your discussion must include sub-sections that focus on three or four interesting points, and also sub-sections on weaknesses and next steps.
- In your report you must provide a link to a GitHub repo that fully contains your analysis. Your code must be entirely reproducible, documented, and readable. Your repo must be well-organised and appropriately use folders.
- Your graphs and tables must be of an incredibly high standard. Graphs and tables should be well formatted and report-ready. They should be clean and digestible. Furthermore, you should label and describe each table/figure.
- When you discuss the dataset (in the data section) you should make sure to discuss (at least): 
  - Its key features, strengths, and weaknesses generally. 
  - A discussion of the questionnaire - what is good and bad about it? 
  - A discussion of the methodology including how they find people to take the survey; what their population, frame, and sample were; what sampling approach they took and what some of the trade-offs may be; what they do about non-response; the cost. 
  - A discussion of the intervention and experimental design.
  - These are just some of the issues strong submissions will consider. Show off your knowledge. If this becomes too detailed then you should push some of this to footnotes or an appendix. 
- When you discuss your model (in the model section), you must be extremely careful to spell out the statistical model that you are using, defining and explaining each aspect and why it is important. (For a Bayesian model, a discussion of priors and regularization is almost always important.) You should mention the software that you used to run the model. You should be clear about model convergence, model checks, and diagnostic issues. How do the sampling and survey aspects that you discussed assert themselves in the modelling decisions that you make? Again, if it becomes too detailed then push some of the details to footnotes or an appendix. You have the original paper to guide you, but you'll likely need to go well-beyond what is included.
- You should present model results, graphs, figures, etc, in the results section. This section should strictly relay results. Interpretation of these results and conclusions drawn from the results should be left for the discussion section.
- Your discussion should focus on your model results. Interpret them and explain what they mean. Put them in context. What do we learn about the world having understood your model and its results? What caveats could apply? To what extent does your model represent the small world and the large world (to use the language of McElreath, Ch 2)? What are some weaknesses and opportunities for future work? Additionally, as this is a reproduction you should include a sub-section on differences you found and difficulties that you had.
- Check that you have referenced everything. Strong submissions will draw on related literature in the discussion (and other sections) and would be sure to also reference those. The style of references does not matter, provided it is consistent.
- As a team, via Quercus, submit a PDF of your paper. Again, in your paper you must have a link to the associated GitHub repo. And you must include the R Markdown file that produced the PDF in that repo. And you must include the R Markdown file that produced the PDF in that repo. The repo must be well-organized and have a detailed README.
- A good way to work as a team would be to split up the work, so that one person is doing each section. The people doing the sections that rely on data (such as the analysis and the graphs) could just simulate it while they are waiting for the person putting together the data to finish.
- It is expected that your submission be well written and able to be understood by the average reader of say 538. This means that you are allowed to use mathematical notation, but you must be able to explain it all in plain English. Similarly, you can (and hint: you should) use survey, sampling, observational, and statistical terminology, but again you need to explain it. Your work should have flow and should be easy to follow and understand. To communicate well, anyone at the university level should be able to read your report once and relay back the methodology, overall results, findings, weaknesses and next steps without confusion. 
- Everyone in the team receives the same mark.
- There should be no evidence that this is a class assignment.




### Test

- Due date: 23 March 2021
- Weight: 10 per cent
- Task: We will have a test during class this week via Quercus. It will be available for 24 hours, but I recommend you complete it during class because I'll be able to help you with any technical issues immediately. There'll be a practice test released a week before this.


### Final Paper

**Tentative - finalised on 12 March 2021.**

#### Essentials

- Due dates: 
  - Initial submission: 9 April 2021
  - Peer review: 12 April 2021
  - Final Paper: 19 April 2021
- Weight: 30 per cent (5 per cent of this is for peer review conducted a week before).
  - Initial submission: 1 per cent
  - Peer review: 3 per cent
  - Final Paper: 25 per cent

#### Task

- Working individually, please conduct original research that applies methods from statistics to a question that involves an experiment. You have various options for topics (pick one):
  - Develop a research question that is of interest to you and obtain or create a relevant dataset. This option involves developing your own research question based on your own interests, background, and expertise. I encourage you to take this option, but please discuss your plans with me. How does one come up with ideas? One way is to be question-driven, where you keep an informal log of small ideas, questions, and puzzles, that you have as you're reading and working. Often, after dwelling on it for a while you can manage to find some questions of interest. Another way is to be data-driven - try to find some interesting dataset and then work backward. Finally, yet another way, is to be methods-driven - let's say that you happen to understand Gaussian processes, then just apply that expertise.
  - Others **TBA**

- You should know the expectations by now. If you need a refresher then review the past problem sets. But essentially: 
  - Everything is entirely reproducible. 
  - Your paper must be written in R Markdown.
  - Your paper must have the following sections:
    - Title, date, author, keywords, abstract, introduction, data, model, results, discussion, appendix (optional, for supporting, but not critical, material), and a reference list. 
  - Your paper must be well-written, draw on relevant literature, and show your statistical skills by explaining all statistical concepts that you draw on. 
  - The discussion needs to be substantial. For instance, if the paper were 10 pages long then a discussion should be at least 2.5 pages. In the discussion, the paper must include subsections on weaknesses and next steps - but these must be in proportion.
  - The report must provide a link to a GitHub repo that contains everything (apart from any raw data that you git ignored if it is not yours to share). The code must be entirely reproducible, documented, and readable. The repo must be well-organised and appropriately use folders and README files. 


#### Peer review submission 

- My expectations for this paper are very high. I'm very excited to read what you submit. To help you achieve this standard, there is an initial 'submission' where you can get comments and feedback and then the final, actual, submission. 
- Submit initial materials for peer-review.
  - As an individual, via Quercus, submit a PDF of your rough draft on Quercus.
  - At a minimum this must include:
  - All top-matter (title, author (you can use a pseudonym if you want), date, keywords, abstract) completely filled out.
  - A fully written Introduction section.
- All other sections must be present in your paper, but don’t have to be filled out (e.g. you must have a 'Data' heading, but you don't need to have content in that section).
- To be clear - it is fine to later change any aspect of what you submit at this check-point.
- You will be awarded two percentage points just for submitting a draft that meets this minimum.
- The point of this is to get feedback on your work (and to make sure you have at least started thinking about this project) so you are more than welcome to include other sections that you wish to get feedback on.
- There will be no extensions granted for this submission since the following submission is dependent on this date.


#### Conduct peer-review

- As an individual, you will randomly be assigned a handful of rough drafts to provide feedback. You have three days to provide feedback to your peers.
- If you provide feedback to one peer you will receive one percentage point, if you provide feedback to two peers you will receive two percentage points, if you provide feedback to three (or more) peers you will receive the full three percentage points.
- Your feedback must include at least five comments (meaningful/useful bullet points). These must be well-written and thoughtful.
- There will be no extensions granted for this submission since the following submission is dependent on this date.
- Please remember that you are providing feedback here to help your colleagues. All comments should be professional and kind. It is challenging to receive criticism. Please remember that your goal here is to help your peers advance their writing/analysis. Any feedback that is inappropriate or not up to standard will receive a 0 and cannot be redeemed later. 


#### FAQ

- Can I work as part of a team? No. It's important that you have some work that is entirely your own.



